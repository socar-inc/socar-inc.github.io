<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.8.6">Jekyll</generator><link href="https://tech.socarcorp.kr/feed.xml" rel="self" type="application/atom+xml" /><link href="https://tech.socarcorp.kr/" rel="alternate" type="text/html" /><updated>2023-01-25T08:10:40+00:00</updated><id>https://tech.socarcorp.kr/feed.xml</id><title type="html">SOCAR Tech Blog</title><subtitle>쏘카 기술 블로그</subtitle><author><name>SOCAR</name></author><entry><title type="html">FMS(차량 관제 시스템) 데이터 파이프라인 구축기 2편. 신뢰성 높은 데이터를 위한 테스트 환경 구축기</title><link href="https://tech.socarcorp.kr/data/2023/01/25/build-fms-data-pipeline-2.html" rel="alternate" type="text/html" title="FMS(차량 관제 시스템) 데이터 파이프라인 구축기 2편. 신뢰성 높은 데이터를 위한 테스트 환경 구축기" /><published>2023-01-25T07:00:00+00:00</published><updated>2023-01-25T07:00:00+00:00</updated><id>https://tech.socarcorp.kr/data/2023/01/25/build-fms-data-pipeline-2</id><content type="html" xml:base="https://tech.socarcorp.kr/data/2023/01/25/build-fms-data-pipeline-2.html">&lt;p&gt;안녕하세요. 데이터 플랫폼 팀의 그랩입니다.&lt;/p&gt;

&lt;p&gt;본 글은 “신사업 FMS 데이터 파이프라인 구축기”의 2편으로 클라이언트에게 신뢰성 높은 데이터를 제공하기 위한 노력들을 다룹니다. PoC 제품 출시까지 시간이 제한된 상황에서도 데이터와 데이터 파이프라인에 대한 신뢰성을 높이기 위해서 테스트 환경 구축도 함께 고려하였습니다. 본 글에서는 안정적인 데이터 파이프라인 구현을 위해 E2E 테스트 및 부하 테스트를 적용하고, 높은 데이터 퀄리티를 보장하기 위해 데이터 검증/모니터링을 구성한 작업을 소개하려고 합니다.
(1편은 &lt;a href=&quot;https://tech.socarcorp.kr/data/2023/01/17/build-fms-data-pipeline-1.html&quot;&gt;링크&lt;/a&gt;를 참고 부탁드립니다.)&lt;/p&gt;

&lt;p&gt;다음과 같은 분들이 읽으면 좋습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;실시간 데이터 파이프라인에 관심이 있는 소프트웨어 엔지니어&lt;/li&gt;
  &lt;li&gt;데이터 파이프라인에 테스트를 도입하고 싶은 소프트웨어 엔지니어&lt;/li&gt;
  &lt;li&gt;데이터 퀄리티를 높이기 위한 시도들이 궁금한 데이터 업계 종사자&lt;/li&gt;
  &lt;li&gt;AWS 기반의 데이터 엔지니어링 환경 구축에 관심이 있는 소프트웨어 엔지니어&lt;/li&gt;
  &lt;li&gt;쏘카의 데이터 엔지니어가 무슨 일을 하는지 궁금한 모든 이들&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;목차는 아래와 같습니다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;#1-데이터-파이프라인-테스트-소개&quot;&gt;데이터 파이프라인 테스트 소개&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#2-소프트웨어-테스트-견고한-파이프라인을-e2e-테스트-환경-구축하기&quot;&gt;소프트웨어 테스트, 견고한 파이프라인을 E2E 테스트 환경 구축하기&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#3-부하-테스트-시뮬레이터를-활용한-실-데이터-기반의-테스트&quot;&gt;부하 테스트, 시뮬레이터를 활용한 실 데이터 기반의 테스트&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#4-데이터-퀄리티-테스트-높은-데이터-퀄리티를-위한-환경-구축하기&quot;&gt;데이터 퀄리티 테스트, 높은 데이터 퀄리티를 위한 환경 구축하기&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#5-마무리&quot;&gt;마무리&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;글을 읽으면서 궁금한 점들에 대해서 편하게 댓글 남겨주시면 답변드리겠습니다.&lt;/p&gt;

&lt;h2 id=&quot;1-데이터-파이프라인-테스트-소개&quot;&gt;1. 데이터 파이프라인 테스트 소개&lt;/h2&gt;

&lt;p&gt;일반적으로 데이터 플랫폼의 주요 클라이언트는 인하우스인 반면 FMS 프로젝트의 경우 B2B 비즈니스 고객을 대상으로 합니다.
따라서 데이터에 대한 SLO(Service Level Objective)를 엄격하게 설정하고 플랫폼을 안정적으로 운영해야 합니다.&lt;/p&gt;

&lt;p&gt;FMS 프로젝트는 실시간, 준-실시간, 배치 처리된 데이터를 모두 필요로 하기 때문에 전체 데이터 파이프라인에 대한 신뢰성과 가시성이 중요합니다.
클라이언트가 사용하는 데이터가 정합성, 무결성이 깨지지 않도록 퀄리티를 높게 유지하는 것도 중요합니다.&lt;/p&gt;

&lt;h3 id=&quot;11-데이터-파이프라인-테스트-종류&quot;&gt;1.1. 데이터 파이프라인 테스트 종류&lt;/h3&gt;

&lt;p&gt;데이터 파이프라인을 구축할 때 적용하는 테스트는 크게 두 가지로 구분할 수 있습니다. 바로 &lt;code class=&quot;highlighter-rouge&quot;&gt;소프트웨어 테스트&lt;/code&gt;와 &lt;code class=&quot;highlighter-rouge&quot;&gt;데이터 퀄리티 테스트&lt;/code&gt;입니다.&lt;/p&gt;

&lt;p&gt;소프트웨어 테스트는 소프트웨어가 기대하는 역할을 잘 수행하는지를 검증하는 과정입니다.
넓게는 하나의 컴포넌트(Kafka Consumer, Lambda 등)가 될 수도 있으며 좁게는 특정 클래스의 함수가 될 수도 있습니다.
데이터 파이프라인에서 특정 컴포넌트가 제대로 동작하지 않는다면 Downstream 컴포넌트는 당연히 동작을 하지 않고 제대로 된 데이터 변형/적재가 힘들어집니다.
즉 각 컴포넌트가 SPoF(Single Point of Failure)가 되기 쉽기 때문에 동작을 충분히 신뢰할 수 있도록 테스트를 작성하는 것이 중요합니다.&lt;/p&gt;

&lt;p&gt;데이터 퀄리티 테스트는 데이터가 요구사항에 맞게 잘 변형/적재되었는지 검증하는 과정입니다.
데이터 파이프라인을 거치면서 데이터는 다양하게 변형되는데 이때 최종적으로 사용자가 조회하는 데이터의 퀄리티가 높은 수준으로 보장되어야 합니다.
만약 특정 레코드가 누락됐거나 칼럼의 값이 이상하다면 데이터를 신뢰할 수 없게 됩니다. 따라서 생성되는 데이터가 정합성, 무결성 등이 잘 지켜졌는지 주기적으로 검사해서 데이터의 퀄리티를 높게 유지해야 합니다.&lt;/p&gt;

&lt;h3 id=&quot;12-소프트웨어-테스트의-종류&quot;&gt;1.2. 소프트웨어 테스트의 종류&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/img/build-fms-data-pipeline/software-test.png&quot; alt=&quot;software-test&quot; /&gt;&lt;/p&gt;

&lt;p&gt;소프트웨어를 테스트할 때 많이 나누는 분류 기준으로 Unit Test(단위 테스트), Integration Test(통합 테스트), E2E Test(종단 간 테스트)가 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Unit Test(단위 테스트)&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;가장 작은 단위(Unit)의 테스트입니다. 단일 기능을 가지는 함수, 클래스의 메서드가 잘 작동하는지 테스트할 때 많이 사용됩니다.&lt;/li&gt;
  &lt;li&gt;가장 간단하고, 직관적이며, 빠르게 실행과 결과를 볼 수 있는 테스트입니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Integration Test(통합 테스트)&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;여러 요소를 통합(Integration) 한 테스트를 말합니다. 데이터베이스와 연동한 코드가 잘 작동하는지, 여러 함수와 클래스가 엮인 로직이 잘 작동하는지 등을 확인합니다.&lt;/li&gt;
  &lt;li&gt;유닛 테스트보다는 복잡하고 느리지만, 소프트웨어는 결국 여러 코드 로직의 통합이라는 점에서 통합 테스트 역시 중요합니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;E2E Test(종단 간 테스트)&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;E2E는 End To End의 약자로, 끝에서 끝, 즉 클라이언트 입장에서 테스트해 보는 것입니다.
예를 들어 Lambda 함수의 Input으로 Event 정보를 넣었을 때 Output으로 S3 객체가 잘 생성되었는지 확인하는 것도 E2E 테스트로 볼 수 있습니다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;테스트하는 대상의 Input과 Output이 명확해졌을 때 작성해야 하며 외부 의존성도 함께 구현해서 테스트하게 됩니다. 예를 들어 Lambda 함수의 E2E 테스트를 할 때 S3라는 외부 의존성이 필요합니다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;테스트 중 가장 신경 써야 할 것이 많지만, 내부의 구현이 변경돼도 검증이 유효하며 있고 시나리오에 맞춰 테스트할 수 있어 검증의 폭이 넓다는 장점이 있습니다.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;13-데이터-퀄리티-정의&quot;&gt;1.3 데이터 퀄리티 정의&lt;/h3&gt;

&lt;p&gt;데이터 퀄리티는 도메인/소프트웨어 요구사항에 맞도록 정확해야 하며 누락/중복 등의 문제가 있어서는 안됩니다. 데이터 퀄리티가 높다는 것은 쉽게 이야기해서 &lt;code class=&quot;highlighter-rouge&quot;&gt;정합성&lt;/code&gt;과 &lt;code class=&quot;highlighter-rouge&quot;&gt;무결성&lt;/code&gt;을 지키고 있는 것을 의미합니다.&lt;/p&gt;

&lt;p&gt;데이터 정합성은 양쪽의 데이터가 모순되지 않고 일치하는 것을 의미합니다. 예를 들어 A 저장소에 있는 원본 데이터를 가공해서 B 저장소로 적재했을 때 가공한 결과 레코드와 B 저장소에 저장된 값 레코드가 정확히 일치하지 않는다면 이는 정합성이 맞지 않음을 의미합니다.&lt;/p&gt;

&lt;p&gt;데이터 무결성은 데이터가 일관되고 정확해야 함을 의미합니다. 예를 들어 A 테이블의 B 칼럼은 Non Null이어야 하며 C 칼럼은 비즈니스 규칙에 따라 값의 범위가 0~100이어야 하는 등의 조건이 있다면, 특정 레코드가 이를 어겼을 때 무결성이 깨졌다고 이야기합니다. 최종적으로 신뢰할 수 있는 데이터는 무결성을 지켜야 합니다.&lt;/p&gt;

&lt;h2 id=&quot;2-소프트웨어-테스트-견고한-파이프라인을-e2e-테스트-환경-구축하기&quot;&gt;2. 소프트웨어 테스트, 견고한 파이프라인을 E2E 테스트 환경 구축하기&lt;/h2&gt;

&lt;p&gt;1편에 소개 드린 주요 컴포넌트(Kafka Connect, Lambda 등)을 신뢰성 높게 유지하기 위해서 테스트 환경을 구성하였습니다.
각 컴포넌트의 주요 기능에 대해서 유닛 테스트, E2E 테스트를 작성하였지만 본 글에서는 E2E 테스트 위주로 설명드리겠습니다.&lt;/p&gt;

&lt;h3 id=&quot;21-테스트-환경-개요&quot;&gt;2.1. 테스트 환경 개요&lt;/h3&gt;

&lt;p&gt;FMS 파이프라인에서 테스트가 필요한 주요 컴포넌트는 Kafka Connect와 Lambda입니다.
다른 컴포넌트의 경우 SaaS나 클라우드 서비스를 사용했기에 어느 정도 신뢰성을 보장할 수 있지만 위 2개 컴포넌트는 요구사항에 맞춰 소프트웨어를 직접 개발했기 때문에
해당 컴포넌트의 신뢰성을 보장하는 테스트 작성이 필요했습니다.&lt;/p&gt;

&lt;p&gt;소프트웨어 테스트 중에서도 E2E 테스트에 중점을 두어 환경을 구성하였습니다. 왜냐하면 PoC 단계에서 내부 구현이 변경될 확률이 높다는 점이 있으며 데이터 파이프라인을 구성하기 위한 명확한 요구사항이 있기 때문입니다.&lt;/p&gt;

&lt;p&gt;E2E 테스트를 하기 위해서 필요한 외부 의존성은 Docker Compose로 구현하였고 별도의 Repository에서 관리하였습니다. 컴포넌트들의 E2E 테스트는 외부 의존성이 컨테이너 형태로 작동한 후 실행됩니다. 마지막으로 Github Action의 빌드, 배포 과정에서 E2E 테스트를 자동화하여 운영하였습니다. 더 자세한 내용은 아래에서 다루겠습니다.&lt;/p&gt;

&lt;h3 id=&quot;22-docker-compose를-통한-e2e-환경-구성&quot;&gt;2.2. Docker Compose를 통한 E2E 환경 구성&lt;/h3&gt;

&lt;p&gt;E2E 테스트를 하기 위해선 테스트할 애플리케이션뿐만 아니라 외부 의존성들도 함께 실행해야 합니다. 기본적으로 애플리케이션의 실행 및 운영은 도커 컨테이너 기반으로 수행되고 있었기에 테스트 환경 구성에 &lt;code class=&quot;highlighter-rouge&quot;&gt;Docker Compose&lt;/code&gt;를 사용하였습니다. Docker Compose는 다중 컨테이너 서비스를 정의하고 실행하기 위해 많이 사용되는 도구입니다. 여러 도커 애플리케이션을 yaml 파일에서 정의/실행할 수 있어 E2E 테스트처럼 여러 의존성들을 직접 띄워야 할 때 유용하게 사용됩니다.&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;na&quot;&gt;version&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;3.8'&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;services&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;zookeeper&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;confluentinc/cp-zookeeper:6.2.0&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;container_name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;zookeeper&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;...&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;broker&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;confluentinc/cp-kafka:6.2.0&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;container_name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;broker&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;depends_on&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;zookeeper&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;...&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;localstack&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;localstack/localstack&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;container_name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;localstack&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;...&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;kafka-ui&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;provectuslabs/kafka-ui&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;container_name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;kafka-ui&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;depends_on&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;broker&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;...&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;kafkacat&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;confluentinc/cp-kafkacat:5.4.9&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;container_name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;kafkacat&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;depends_on&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;broker&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;...&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;networks&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;shared-network&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;shared-network&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;driver&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;bridge&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;위는 현재 파이프라인의 컴포넌트들을 띄우기 위한 &lt;code class=&quot;highlighter-rouge&quot;&gt;docker-compose.yaml&lt;/code&gt; 파일의 일부입니다.
Kafka 환경을 중심으로 모니터링 툴인 &lt;code class=&quot;highlighter-rouge&quot;&gt;kafka-ui&lt;/code&gt;, AWS 서비스를 로컬 환경에서 실행할 수 있도록 Mocking 해주는 &lt;code class=&quot;highlighter-rouge&quot;&gt;localstack&lt;/code&gt; 등이 있습니다. 이를 통해 로컬, CI 환경에서 각 컴포넌트들을 빠르게 띄우게 되며 호스트에서 Localhost를 통해서 접근하거나 각 컨테이너 서비스 사이에 통신이 가능해졌습니다.
또한 외부 Docker Compose로 실행되는 컨테이너와 통신할 수 있도록 하기 위해서 Network를 추가했습니다.&lt;/p&gt;

&lt;h3 id=&quot;23-git-submodule을-통한-컴포넌트-e2e-테스트&quot;&gt;2.3. Git Submodule을 통한 컴포넌트 E2E 테스트&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/img/build-fms-data-pipeline/git-submodule.png&quot; alt=&quot;git-submodule&quot; /&gt;&lt;/p&gt;

&lt;p&gt;파이프라인을 띄우는 Docker Compose 코드는 독립적인 Git Repository에서 관리되고 있습니다. FMS 프로젝트에 여러 컴포넌트들을 테스트해야 하는 것뿐만 아니라 다른 프로젝트에서 사용할 수 있기 때문에 이를 분리하였습니다.&lt;/p&gt;

&lt;p&gt;E2E 테스트 대상이 되는 Kafka Sink Connector, Lambda 같은 컴포넌트도 마찬가지로 독립적인 Git Repository로 관리되고 있습니다. 따라서 테스트할 Repository에서 파이프라인 구성 Repository를 연결할 수 있는 &lt;code class=&quot;highlighter-rouge&quot;&gt;Git Submodule&lt;/code&gt;을 사용하였습니다.&lt;/p&gt;

&lt;p&gt;예시로 Kafka Sink Connector의 E2E 테스트 폴더를 보면 아래와 같습니다. Git Submodule을 통해 Clone된 Repsoitory가 있는 걸 확인할 수 있습니다. 또한 &lt;code class=&quot;highlighter-rouge&quot;&gt;tests/&lt;/code&gt;에 테스트 코드들이 들어있고 해당 테스트를 실행하는 &lt;code class=&quot;highlighter-rouge&quot;&gt;docker-compose.e2e.yaml&lt;/code&gt;이 있습니다.&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;e2e
├── ...
├── docker-compose.e2e.yaml &lt;span class=&quot;c&quot;&gt;# 테스트할 대상들을 띄우기 위한 Docker Compose 파일&lt;/span&gt;
├── socar-fms-pipeline-docker &lt;span class=&quot;c&quot;&gt;# Git Submodule&lt;/span&gt;
│   ├── Makefile
│   ├── README.md
│   ├── docker-compose.yaml
│   └── scripts
└── tests
    ├── messages
    ├── test_ddb_sink_connector.sh
    └── test_s3_sink_connector.sh
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Kafka Sink Connector의 E2E 테스트를 실행하기 위해서 Kafka Connect 애플리케이션과 테스트 스크립트(Bash로 작성)을 실행하는 Docker Compose 파일이 필요합니다. 아래와 같이 Service에 작성하였으며 위에서 다룬 스트리밍 파이프라인 쪽 컨테이너들과 통신하기 위해 External Network로 연결하였습니다.&lt;/p&gt;

&lt;details&gt;
&lt;summary&gt;Docker-compose 코드&lt;/summary&gt;
&lt;div&gt;

    &lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;na&quot;&gt;version&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;3.8'&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;x-connect-test-configs&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nl&quot;&gt;&amp;amp;connect-common&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;environment&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nl&quot;&gt;&amp;amp;connect-common-env&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;...&lt;/span&gt;

&lt;span class=&quot;na&quot;&gt;services&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;kafka-connect&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;*connect-common&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;...&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;build&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;..&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;dockerfile&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;Dockerfile&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;container_name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;kafka-connect&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;networks&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;network&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;default&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;...&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;test-container&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;confluentinc/cp-kafkacat:5.4.9&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;container_name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;test-container&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;volumes&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;./tests:/app/tests&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;command&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;/bin/bash&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;-c&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;pi&quot;&gt;|&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;...&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;for f in /app/tests/*.sh; do&lt;/span&gt;
          &lt;span class=&quot;s&quot;&gt;echo &quot;run $$f...&quot; &amp;amp;&amp;amp; bash $$f&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;done&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;networks&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;network&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;default&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;...&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;networks&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;network&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;external&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;shared-network&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

  &lt;/div&gt;
&lt;/details&gt;

&lt;p&gt;그리고 실제로 컴포넌트가 제대로 동작하는지 검증하기 위한 테스트 코드는 아래와 같습니다. REST API로 테스트할 Kafka Connector를 등록하고 Kafka Topic에 메시지를 보냈을 때 Sink에 제대로 적재가 되었는지 확인합니다. E2E 환경을 Docker Compose를 통해 전부 구축된 상황에서 Input을 넣고 Output을 확인하는 방식임을 알 수 있습니다.&lt;/p&gt;

&lt;details&gt;
&lt;summary&gt;Kafka Sink Connector E2E 테스트 코드&lt;/summary&gt;
&lt;div&gt;

    &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;#!/bin/bash&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;set&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-eo&lt;/span&gt; pipefail

&lt;span class=&quot;nv&quot;&gt;Red&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'\033[0;31m'&lt;/span&gt;          &lt;span class=&quot;c&quot;&gt;# Red&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;Green&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'\033[0;32m'&lt;/span&gt;        &lt;span class=&quot;c&quot;&gt;# Green&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;Yellow&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'\033[0;33m'&lt;/span&gt;       &lt;span class=&quot;c&quot;&gt;# Yellow&lt;/span&gt;

&lt;span class=&quot;nv&quot;&gt;kafkaConnectServer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;kafka-connect:8083
&lt;span class=&quot;nv&quot;&gt;targetTopic&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;s3-topic
&lt;span class=&quot;nv&quot;&gt;deadletterTopic&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;deadletterqueue

&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;=============&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt; 0. Waiting for Kafka Connect to start listening on localhost &lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;=============&quot;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;[[&lt;/span&gt; &lt;span class=&quot;si&quot;&gt;$(&lt;/span&gt;curl &lt;span class=&quot;nt&quot;&gt;-s&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-o&lt;/span&gt; /dev/null &lt;span class=&quot;nt&quot;&gt;-w&lt;/span&gt; %&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;http_code&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$kafkaConnectServer&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-ne&lt;/span&gt; 200 &lt;span class=&quot;o&quot;&gt;]]&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;do
    &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;waiting...&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;sleep &lt;/span&gt;5
&lt;span class=&quot;k&quot;&gt;done&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;=============&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt; 1. test s3 sink connector exists &lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;=============&quot;&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;command&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;$(&lt;/span&gt;curl &lt;span class=&quot;nt&quot;&gt;-s&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$kafkaConnectServer&lt;/span&gt;/connector-plugins | &lt;span class=&quot;nb&quot;&gt;grep&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;kr.socar.fms.connector.s3.S3SinkConnector&quot;&lt;/span&gt; | &lt;span class=&quot;nb&quot;&gt;wc&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-l&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;[[&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;command&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; 0 &lt;span class=&quot;o&quot;&gt;]]&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;then
  &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;Red&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;Fms kafka connect doesn't have S3SinkConnector&quot;&lt;/span&gt;
  &lt;span class=&quot;nb&quot;&gt;exit &lt;/span&gt;1
&lt;span class=&quot;k&quot;&gt;else
  &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;Green&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;passed&quot;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;fi

&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;=============&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt; 2. test s3 sink connector registered &lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;=============&quot;&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;command&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;$(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'
            {
                &quot;connector.class&quot; : &quot;kr.socar.fms.connector.s3.S3SinkConnector&quot;,
                &quot;topics&quot;: &quot;'&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$targetTopic&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'&quot;,
                ...
            }
          '&lt;/span&gt; | curl &lt;span class=&quot;nt&quot;&gt;-X&lt;/span&gt; PUT &lt;span class=&quot;nt&quot;&gt;-d&lt;/span&gt; @- &lt;span class=&quot;nt&quot;&gt;-s&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$kafkaConnectServer&lt;/span&gt;/connectors/s3-sink-connector/config &lt;span class=&quot;nt&quot;&gt;--header&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;content-Type:application/json&quot;&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;)&lt;/span&gt;


&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;[[&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-z&lt;/span&gt; &lt;span class=&quot;si&quot;&gt;$(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$command&lt;/span&gt; | jq &lt;span class=&quot;nt&quot;&gt;-r&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;.error_code&quot;&lt;/span&gt; &lt;span class=&quot;si&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;]]&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;then
  &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;Green&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;passed&quot;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;else
  &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$command&lt;/span&gt;
  &lt;span class=&quot;nb&quot;&gt;exit &lt;/span&gt;1
&lt;span class=&quot;k&quot;&gt;fi

&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;=============&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt; 3. test s3 objects exist after putting messages &lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;=============&quot;&lt;/span&gt;
kafkacat &lt;span class=&quot;nt&quot;&gt;-P&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-b&lt;/span&gt; broker:29092 &lt;span class=&quot;nt&quot;&gt;-t&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$targetTopic&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-l&lt;/span&gt; /app/tests/messages/s3-sink-test.message
&lt;span class=&quot;nb&quot;&gt;sleep &lt;/span&gt;3 &lt;span class=&quot;c&quot;&gt;# wait for a work of s3 connector&lt;/span&gt;

&lt;span class=&quot;nv&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;$(&lt;/span&gt;aws &lt;span class=&quot;nt&quot;&gt;--endpoint-url&lt;/span&gt; http://localstack:4566 s3api list-objects &lt;span class=&quot;nt&quot;&gt;--bucket&lt;/span&gt; test-bucket&lt;span class=&quot;si&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;nv&quot;&gt;s3FileSize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;$(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$result&lt;/span&gt; | jq &lt;span class=&quot;nt&quot;&gt;-r&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'.Contents | length'&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;[[&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$s3FileSize&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; 2 &lt;span class=&quot;o&quot;&gt;]]&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;then
  &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;Green&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;passed&quot;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;else
  &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;Red&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;S3SinkConnector doesn't put messages to s3 (object size : &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$s3FileSize&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;)&quot;&lt;/span&gt;
  &lt;span class=&quot;nb&quot;&gt;exit &lt;/span&gt;1
&lt;span class=&quot;k&quot;&gt;fi

&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;=============&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt; 4. test dlq after putting error messages &lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;=============&quot;&lt;/span&gt;
...

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

  &lt;/div&gt;
&lt;/details&gt;

&lt;p&gt;Kafka Sink Connector Docker Compose 환경에서 전부 실행했지만, Lambda 함수에 대한 E2E 테스트는 아래와 같이 Python + Pytest 환경에서 실행할 수 있습니다. 아래 코드는 Docker Compose의 일부 서비스(LocalStack S3)만 실행하여 E2E 테스트를 구현하였습니다.&lt;/p&gt;

&lt;details&gt;
&lt;summary&gt;Lambda E2E 테스트 코드&lt;/summary&gt;
&lt;div&gt;

    &lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;S3_BUCKET&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;test-bucket&quot;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;S3_PREFIX&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;raw&quot;&lt;/span&gt;


&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;is_port_in_use&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;port&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;bool&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;socket&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;socket&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;socket&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;socket&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;AF_INET&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;socket&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SOCK_STREAM&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;connect_ex&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;localhost&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;port&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;

&lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;

&lt;span class=&quot;o&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pytest&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mark&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;skipif&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;is_port_in_use&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4566&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reason&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;localstack s3 (포트번호 4566)를 실행해야 합니다&quot;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;test_save_to_s3_in_parquet_with_partitions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s3_source_json_key&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s3_parquet_parser&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;awswrangler&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;wr&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;wr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s3_endpoint_url&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;http://localhost:4566&quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;paritition_col&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;partition&quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;s3_prefix&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;formatted&quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;messages&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;object&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;vehicle&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;type&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;kinematic&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;paritition_col&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;0&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;object&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;vehicle&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;type&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;status&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;paritition_col&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;0&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s3_parquet_parser&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;save_to_s3_in_parquet_with_partitions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;messages&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;messages&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;partition_cols&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;paritition_col&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;s3_bucket&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;S3_BUCKET&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;s3_prefix&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s3_prefix&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;assert&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;paths&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;startswith&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;s3://{S3_BUCKET}/{s3_prefix}&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

  &lt;/div&gt;
&lt;/details&gt;

&lt;h3 id=&quot;24-github-action을-통한-e2e-테스트-자동화&quot;&gt;2.4. Github Action을 통한 E2E 테스트 자동화&lt;/h3&gt;

&lt;p&gt;위에서 구성한 E2E 테스트는 사용자가 로컬에서 수행하는 것뿐만 아니라 CI(Continuous Integration) 단계에서도 수행됩니다.
쏘카에서는 CI 도구로 &lt;code class=&quot;highlighter-rouge&quot;&gt;Github Action&lt;/code&gt;을 사용하고 있습니다. 아래는 Github Action에서 E2E Test 관련 워크플로 설정 파일입니다. 보통 Pull Request와 배포하기 전에 해당 워크플로가 실행됩니다.&lt;/p&gt;

&lt;details&gt;
&lt;summary&gt;E2E 테스트 관련 Github Action Worflow 코드&lt;/summary&gt;
&lt;div&gt;

    &lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;E2E Test On Kafka Connect&lt;/span&gt;

&lt;span class=&quot;na&quot;&gt;on&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;pull_request&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;...&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;jobs&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;e2e-test&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;runs-on&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;ubuntu-latest&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;steps&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;uses&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;actions/checkout@v3&lt;/span&gt;
              &lt;span class=&quot;na&quot;&gt;with&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
                  &lt;span class=&quot;na&quot;&gt;persist-credentials&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;false&lt;/span&gt;
            &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;Checkout socar-data-pipeline-docker&lt;/span&gt;
              &lt;span class=&quot;na&quot;&gt;uses&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;actions/checkout@v3&lt;/span&gt;
              &lt;span class=&quot;na&quot;&gt;with&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
                  &lt;span class=&quot;na&quot;&gt;repository&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;socar-inc/socar-data-pipeline-docker&lt;/span&gt;
                  &lt;span class=&quot;na&quot;&gt;ref&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;main&lt;/span&gt;
                  &lt;span class=&quot;na&quot;&gt;token&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;$&lt;/span&gt;
                  &lt;span class=&quot;na&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;socar-data-pipeline-docker&lt;/span&gt;
            &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;Run e2e pipleine&lt;/span&gt;
              &lt;span class=&quot;na&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pi&quot;&gt;|&lt;/span&gt;
                  &lt;span class=&quot;s&quot;&gt;cd socar-data-pipeline-docker&lt;/span&gt;
                  &lt;span class=&quot;s&quot;&gt;docker-compose -p pipeline-docker --project-directory $PWD up  -d --force-recreate&lt;/span&gt;
                  &lt;span class=&quot;s&quot;&gt;cd ..&lt;/span&gt;
            &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;uses&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;actions/checkout@v3&lt;/span&gt;
              &lt;span class=&quot;na&quot;&gt;with&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
                  &lt;span class=&quot;na&quot;&gt;persist-credentials&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;false&lt;/span&gt;
                  &lt;span class=&quot;na&quot;&gt;clean&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;false&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# pipeline-docker를 유지하기 위해서 사용합니다.&lt;/span&gt;
            &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;run e2e test&lt;/span&gt;
              &lt;span class=&quot;na&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pi&quot;&gt;|&lt;/span&gt;
                  &lt;span class=&quot;s&quot;&gt;cd e2e&lt;/span&gt;
                  &lt;span class=&quot;s&quot;&gt;docker-compose --project-directory $PWD -f docker-compose.e2e.yaml up --abort-on-container-exit&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

  &lt;/div&gt;
&lt;/details&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/actions/checkout&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Checkout&lt;/code&gt;&lt;/a&gt; Action을 사용하면 외부의 Github Repostiory를 손쉽게 Checkout 할 수 있습니다.
Github Action에서 하나의 Job은 하나의 격리된 환경에서 동작합니다. 따라서 E2E 환경을 구성하는 Repository로 Checkout 하여 Docker Compose로 실행한 후, 다시 원 Repository로 Checkout 하여 E2E 테스트를 수행합니다.
이때 주의할 점은 checkout 할 때 &lt;code class=&quot;highlighter-rouge&quot;&gt;clean&lt;/code&gt; 속성을 &lt;code class=&quot;highlighter-rouge&quot;&gt;false&lt;/code&gt;로 줘야 기존 볼륨을 유지할 수 있습니다 (기수행된 컨테이너에 마운트 된 볼륨이 갑자기 사라지는 이슈로 꽤 골치가 아팠습니다.)&lt;/p&gt;

&lt;h2 id=&quot;3-부하-테스트-시뮬레이터를-활용한-실-데이터-기반의-테스트&quot;&gt;3. 부하 테스트, 시뮬레이터를 활용한 실 데이터 기반의 테스트&lt;/h2&gt;

&lt;h3 id=&quot;31-부하-테스트-계획&quot;&gt;3.1. 부하 테스트 계획&lt;/h3&gt;

&lt;p&gt;데이터 파이프라인을 구축하면서 주요하게 신경 써야 하는 부분 중 하나는 성능입니다. 위에서 언급한 것처럼 파이프라인의 각 지점은 SPoF가 되기 쉽기 때문에 높은 트래픽으로 인해 서비스가 중단되면 안 됩니다. 따라서 FMS 프로젝트에서 실 차량 데이터가 들어오기 전 부하 테스트를 계획하였습니다.&lt;/p&gt;

&lt;p&gt;IoT Core에 메시지 전송을 시작으로 Kafka → Kafka Connect를 거쳐 DynamoDB, S3로 가는 E2E 부하 테스트를 준비하였습니다. 서비스에 주요하게 사용되는 메시지 위주로 시나리오를 작성하였습니다. 이때 FMS 프로젝트의 내년 목표 차량 대수를 기준으로 부하 기준을 설정하였습니다.&lt;/p&gt;

&lt;p&gt;시뮬레이션을 통해 모니터링해야 하는 주요 대상은 직접 개발하고 관리하고 있는 Kafka Connect, DynamoDB, Lambda으로 정하였습니다.
각 컴포넌트마다 설정했던 주요 지표는 다음과 같습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Kafka Connect: Worker Pod의 시스템 리소스(CPU, Memory, Network IO 등)와 Kafka Sink Connector 별 Lag&lt;/li&gt;
  &lt;li&gt;DynamoDB: 온디맨드 모드 시 WCU/RCU, 쓰로틀링 및 에러 발생 여부&lt;/li&gt;
  &lt;li&gt;Lambda: 이벤트 처리 시간, 메모리 사용량&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;32-실-데이터-기반의-메시지-시뮬레이터&quot;&gt;3.2. 실 데이터 기반의 메시지 시뮬레이터&lt;/h3&gt;

&lt;p&gt;데이터 파이프라인을 구축하는 도중에도 클라이언트(서비스 API 서버, Redshift 등)는 데이터 저장소에 접근해서 데이터를 조회할 수 있어야 개발 속도를 높일 수 있습니다. 이때 차량 단말기에서 실제로 데이터를 전송하는 것처럼 시뮬레이터를 구현하면 여러 팀에서 이를 사용해서 개발하는 과정에서 보틀넥이 발생하진 않을 것이라 판단했습니다.&lt;br /&gt;
실제로 메시지 시뮬레이터는 PoC 런칭 이전까지 프로젝트에 참여한 개발자들이 손쉽고 유연하게 시뮬레이션이 가능하도록 도움을 주었습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/build-fms-data-pipeline/fms-message-simulator-diagram.png&quot; alt=&quot;fms-message-simulator-diagram&quot; /&gt;&lt;/p&gt;

&lt;p&gt;메시지 시뮬레이터는 외부 데이터(S3 Log, Bigquery) 혹은 직접 생성하는 방식으로 메시지를 생성합니다. FMS 프로젝트에서 정의한 프로토콜과 쏘카 차량에서 발생하는 데이터가 유사도가 높았기에 적재된 데이터를 잘 활용하면 손쉽게 메시지를 생성할 수 있습니다. 만일 없는 프로토콜의 경우 fake 데이터를 기반으로 메시지를 생성하였습니다.&lt;/p&gt;

&lt;p&gt;FMS 서비스에서 여러 차량을 관제하는 것을 테스트하기 위해선 동시에 여러 차량이 차량 위치 데이터가 필요하며 차량 별로 일부 다른 데이터가 필요합니다. 이런 요구 사항들은 Simulator 객체를 통해 병렬 처리나 중간 변형 작업 등이 가능하도록 구현하였습니다.&lt;br /&gt;
마지막으로 메시지 브로커의 역할을 하는 IoT Core와 Kafka에 메시지를 전송할 수 있도록 Producer로 추상화하여 사용자가 원하는 환경으로 메시지를 쏠 수 있도록 하였습니다.&lt;/p&gt;

&lt;h3 id=&quot;33-부하-테스트-진행-및-결과&quot;&gt;3.3. 부하 테스트 진행 및 결과&lt;/h3&gt;

&lt;p&gt;부하 테스트를 진행할 때는 각 시나리오 별 스크립트를 미리 작성하였습니다. 병렬로 메시지를 전송하는 스크립트들을 시간에 따라 각각 실행하였으며 주요 컴포넌트들을 모니터링하였습니다.&lt;br /&gt;
동시 차량 대수와 메시지 프로토콜 별로 컴포넌트의 주요 지표들을 측정하였으며 메시지 부하가 선형적으로 늘어났을 때 각 컴포넌트의 스케일 업/아웃이 정상 동작하는지도 확인하였습니다. 결과적으로 예상 비용과 우려되는 부분들도 함께 정리하여 리포트 형태로 공유하였습니다.&lt;/p&gt;

&lt;p&gt;부하 테스트를 하면서 트러블 슈팅이 필요한 부분들도 있었습니다. S3 Sink Connector의 경우 내부적으로 버퍼를 둬서 메시지를 메모리에 저장하는데, 동시 메시지 개수가 늘어날수록 메모리가 빠르게 차서 Out Of Memory가 종종 발생하였습니다.
따라서 S3 Sink Connector의 속성을 튜닝하고 Worker Pod Memory와 Task의 heapOptions를 높여주었습니다. Lambda 또한 메모리 관련 이슈가 있어서 메모리를 높여주고, 내부 처리 로직을 개선하였습니다.&lt;/p&gt;

&lt;h2 id=&quot;4-데이터-퀄리티-테스트-높은-데이터-퀄리티를-위한-환경-구축하기&quot;&gt;4. 데이터 퀄리티 테스트, 높은 데이터 퀄리티를 위한 환경 구축하기&lt;/h2&gt;

&lt;p&gt;이번 장에서는 데이터의 신뢰성을 높이기 위해서 했던 작업들에 대해 알아보도록 하겠습니다. 배치 분석 플랫폼을 통해 분석/집계된 데이터가 정말 유효한지, 차량 단말기에서 이상 데이터가 발생하지 않았는지 같은 검증 작업을 통해서 데이터의 신뢰성을 높이고자 하였습니다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;참고 : 현재 사내에서 진행되고 있는 프로젝트이기 때문에 구체적인 사항들은 의도적으로 생략하였습니다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;41-검사할-대상-정의하기&quot;&gt;4.1. 검사할 대상 정의하기&lt;/h3&gt;

&lt;p&gt;FMS 프로젝트에서 데이터 퀄리티를 높게 유지하기 위해서 크게 아래와 같이 검사 유형들을 나눴습니다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;원본 데이터에 대한 이상 여부 검사&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;차량 단말기에서 전송되는 메시지의 이상 여부를 검사합니다.
 예를 들어 GPS 상태 관련하여 에러가 발생하거나 특정 필드가 누락되는 등의 이상 현상을 모니터링합니다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;데이터 마트 테이블의 정합성 검사&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;Redshift를 통해 원본 데이터를 분석/집계된 데이터가 데이터 마트(Mysql)에 잘 적재되었는지 검사합니다. 쿼리 결과가 MySQL에 저장되는 과정에서 값의 변화가 없는지, 특정 시간이 지난 후 쿼리 해도 동일한 결과를 가지는지 등의 정합성 여부를 확인합니다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;데이터 마트 테이블의 무결성 검사&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;데이터 마트 테이블 별로 도메인에 맞는 칼럼 값을 가지고 있는지 확인합니다. 예를 들어 연료량이 0~100 사이에 존재하는지, 운행한 차량들은 전부 집계가 되었는지 같은 무결성 여부를 확인합니다.
 도메인 전문가와 개발자가 분리되어 있는 경우도 많고 데이터 파이프라인의 특성상 여러 이해관계자들이 관여하기 때문에 각 이해관계자 들이 모여 주기적으로 데이터 신뢰성을 높이기 위한 회의를 진행하였습니다. 아래와 같이 템플릿을 통해 신뢰성을 검증하는 대상들을 문서화하고 함께 논의하였습니다.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;/img/build-fms-data-pipeline/data-reliability-database.png&quot; alt=&quot;data-reliability-database&quot; /&gt;&lt;em&gt;검증 대상이 되는 마트 테이블을 정의하여 기록하였습니다.&lt;/em&gt;
…&lt;/p&gt;

&lt;h3 id=&quot;42-데이터-퀄리티-검사-파이프라인-소개&quot;&gt;4.2. 데이터 퀄리티 검사 파이프라인 소개&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/img/build-fms-data-pipeline/data-quality-test-pipeline.png&quot; alt=&quot;data-quality-test-pipeline&quot; /&gt;
데이터 퀄리티 검사를 구현하기 위해서 아래와 같은 기술들을 선택하였습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;데이터 무결성 검사 : SQLColumnCheckOperator&lt;/li&gt;
  &lt;li&gt;데이터 정합성 검사 : Pandas (Redshift, Mysql Connection)&lt;/li&gt;
  &lt;li&gt;검사 스케줄링 : Airflow&lt;/li&gt;
  &lt;li&gt;데이터베이스 : RDS(MySQL)&lt;/li&gt;
  &lt;li&gt;모니터링 : Grafana&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;저희는 데이터 무결성을 검사하기 위해 선택지로 서드파티 툴인 &lt;a href=&quot;https://greatexpectations.io/&quot;&gt;great_expections&lt;/a&gt;나 &lt;a href=&quot;https://www.getdbt.com/&quot;&gt;dbt(+ dbt expectations)&lt;/a&gt;이 있고 Airflow에서 간단하게 사용할 수 있는 &lt;a href=&quot;https://airflow.apache.org/docs/apache-airflow-providers-common-sql/stable/operators.html&quot;&gt;SQL Operator&lt;/a&gt; 등을 고려했습니다. 결과적으로 가볍게 사용할 수 있는 Airflow SQL Operator를 선택하였습니다.&lt;br /&gt;
데이터 정합성 검사는 SQL의 &lt;code class=&quot;highlighter-rouge&quot;&gt;Except&lt;/code&gt; 구문을 활용하여 데이터 마트(MySQL)와 Redshift 쿼리 결과를 비교하였습니다. 그리고 쿼리 실행 및 결과 처리는 &lt;code class=&quot;highlighter-rouge&quot;&gt;Pandas&lt;/code&gt;를 사용하였습니다.&lt;/p&gt;

&lt;p&gt;검사는 크게 아래와 같은 순서로 진행됩니다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;정합성/무결성 검사는 매일 새벽에 수행되며 무결성 검사는 전날 생성된 마트 데이터, 정합성 검사는 이틀 전 데이터를 기준으로 합니다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;수행된 검사 결과(성공, 실패)는 데이터베이스(RDS)에 저장됩니다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Grafana를 통해 데이터베이스에 저장된 결과를 대시보드에서 확인하며, &lt;code class=&quot;highlighter-rouge&quot;&gt;Grafana Alert&lt;/code&gt;를 통해 검사가 실패한 경우 슬랙으로 메시지를 전송합니다&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;43-monitoring-operator-구현&quot;&gt;4.3. Monitoring Operator 구현&lt;/h3&gt;

&lt;p&gt;데이터 퀄리티 검사를 진행한 후 검사 결과를 데이터베이스에 저장하는 과정이 필요합니다. 무결성 검사 도구인 SQLColumnCheckOperator의 경우 검사 실패 시 Exception을 발생시키지만 데이터베이스에 결과를 저장하는 기능은 존재하지 않았습니다.
따라서 SQLColumnCheckOperator에 새로운 기능을 적용하기 위해서 상속(Inheritance)이나 구성(Composition) 방식을 통해서 새로운 Operator를 생성하였습니다.&lt;/p&gt;

&lt;p&gt;따라서 아래와 같이 &lt;code class=&quot;highlighter-rouge&quot;&gt;MonitoringValidationOperator&lt;/code&gt;를 구현하였습니다.&lt;/p&gt;

&lt;details&gt;
&lt;summary&gt;MonitoringValidationOperator 코드&lt;/summary&gt;
&lt;div&gt;

    &lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;MonitoringValidationOperator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;BaseOperator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
        정합성/무결성 검사 결과를 Database에 저장하는 Operator입니다
        :param operator_constructor: 검사를 진행하는 Operator를 생성 함수 형태로 입력합니다 (Airflow DAG에서 Operator 생성 감지 이슈로 인해 함수 형태로 작성)
        :param conn_id: Database에 연결할 connection id를 입력합니다
        :param table: 검사 결과를 저장할 table을 &quot;{database}.{table}&quot; 형식으로 입력합니다
        :param database: 검사 결과를 저장할 database를 입력합니다
        :param target_table: 검사를 진행한 table을 입력합니다 (data_mart, redshift 등)
        &quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;target_fields&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;result&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;target_table&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;result_content&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;dag_id&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;task_id&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;owner&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;execution_date&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
            &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;operator_constructor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Callable&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BaseOperator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;conn_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;target_table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;database&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Optional&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;nb&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MonitoringValidationOperator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;

    &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cached_property&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;_hook&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;get_db_hook&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DbApiHook&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;execute&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;any&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;operator&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;operator_constructor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_render_operator_template&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;operator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;k&quot;&gt;try&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;info&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Execute a wrapped operator&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;operator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;execute&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_load_result_in_table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;except&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;AirflowFailException&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Validation 과정에서 실패한 경우 AirflowFailException을 발생한다
&lt;/span&gt;            &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Exception Occurred during validation&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_load_result_in_table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;raise&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;except&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;Exception&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Exception Occurred&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;raise&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;_load_result_in_table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;records&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;List&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Tuple&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;target_fields&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;List&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]):&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;_render_operator_template&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;operator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BaseOperator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

  &lt;/div&gt;
&lt;/details&gt;

&lt;p&gt;SQLColumnCheckOperator가 검증에 실패하면 &lt;code class=&quot;highlighter-rouge&quot;&gt;AirflowFailExcpetion&lt;/code&gt;을 발생시키기 때문에 공통 인터페이스로 다른 검사 로직에서 실패 시 AirflowFailException을 발생시키도록 통일하였습니다. 그리고 Operator의 &lt;code class=&quot;highlighter-rouge&quot;&gt;execute&lt;/code&gt; 메서드에서 &lt;code class=&quot;highlighter-rouge&quot;&gt;try/catch&lt;/code&gt; 형태로 이를 감지하여 검사 결과를 저장하도록 구현하였습니다.&lt;/p&gt;

&lt;p&gt;실제로 아래와 같은 구조로 데이터 퀄리티 검사가 진행되고 있으며 매일 결과가 적재되고 있습니다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;validate_mysql&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MonitoringValidationOperator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;task_id&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;monitoring_operator&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;conn_id&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;mysql_write_conn&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;database&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;fms_monitoring&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;table&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;validation_result&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;target_table&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;fms_data_mart.battery_fleet_daily&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;operator_constructor&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;lambda&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;SQLColumnCheckOperator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;partition_clause&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;std_date = ''&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;column_mapping&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
                &lt;span class=&quot;s&quot;&gt;&quot;fleet_intg_id&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
                    &lt;span class=&quot;s&quot;&gt;&quot;max&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;leq_to&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
                &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;44-검사-결과-모니터링&quot;&gt;4.4. 검사 결과 모니터링&lt;/h3&gt;

&lt;p&gt;데이터베이스에 적재된 테스트 결과는 Grafana를 통해 시각화하였습니다. 각 테스트하는 DAG 별로 날짜별 테스트 수행 개수를 통해 데이터 퀄리티 테스트가 잘 수행되는지 확인 가능하며, 실패한 테스트의 개수를 통해 실패한 테스트를 확인할 수 있습니다.&lt;/p&gt;

&lt;p&gt;만약 실패한 테스트가 발견되는 경우 아래와 같이 슬랙 알림을 통해 확인할 수 있도록 하였습니다.
&lt;img src=&quot;/img/build-fms-data-pipeline/data-quality-test-slack.png&quot; alt=&quot;data-quality-test-slack&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;5-마무리&quot;&gt;5. 마무리&lt;/h2&gt;

&lt;p&gt;안정적으로 데이터를 사용자에게 제공하기 위해서 많은 노력이 필요합니다. 짧은 PoC 개발 기간에 꼭 필요하다고 생각이 들었던 데이터 파이프라인의 테스트와 데이터 품질 검사를 먼저 개발하였습니다. 앞으로 더 체계적으로 테스트 환경을 구축하고 데이터 퀄리티를 높이는 동시에 가시화할 수 있도록 노력하려고 합니다.&lt;/p&gt;

&lt;p&gt;파이프라인을 개발하면서 동시에 소프트웨어의 안정성과 데이터 퀄리티를 함께 챙겨야 하는 과정은 힘들었지만 정말 배운 점들이 많았습니다. 안정적인 데이터 파이프라인 구축을 위해 함께 힘써주고 계신 피글렛, 누즈, 루디, 삐약, 파스모에게 감사의 말을 전합니다.&lt;/p&gt;</content><author><name>그랩</name></author><category term="data" /><category term="data" /><category term="data engineering" /><category term="iot streaming" /><category term="data platform" /><category term="data reliability" /><category term="data quality" /><summary type="html">안녕하세요. 데이터 플랫폼 팀의 그랩입니다.</summary></entry><entry><title type="html">FMS(차량 관제 시스템) 데이터 파이프라인 구축기 1편. 스트리밍/배치 파이프라인 개발기</title><link href="https://tech.socarcorp.kr/data/2023/01/17/build-fms-data-pipeline-1.html" rel="alternate" type="text/html" title="FMS(차량 관제 시스템) 데이터 파이프라인 구축기 1편. 스트리밍/배치 파이프라인 개발기" /><published>2023-01-17T00:00:00+00:00</published><updated>2023-01-17T00:00:00+00:00</updated><id>https://tech.socarcorp.kr/data/2023/01/17/build-fms-data-pipeline-1</id><content type="html" xml:base="https://tech.socarcorp.kr/data/2023/01/17/build-fms-data-pipeline-1.html">&lt;p&gt;안녕하세요. 데이터 플랫폼 팀의 그랩입니다.&lt;/p&gt;

&lt;p&gt;데이터 플랫폼팀은 &lt;strong&gt;“쏘카 내부의 데이터 이용자가 비즈니스에 임팩트를 낼 수 있도록 소프트웨어 엔지니어링에 기반하여 문제를 해결합니다”&lt;/strong&gt;라는 미션을 기반으로 인프라, 데이터 파이프라인 개발, 운영, 모니터링, 데이터 애플리케이션 개발, MLOps 등의 업무를 맡고 있습니다.
팀 구성원들은 모두가 소프트웨어 엔지니어라는 사명감을 가지고 개발뿐만 아니라 Ops에 대한 이해와 책임감을 가지고 업무에 임하고 있습니다.&lt;/p&gt;

&lt;p&gt;본 글은 “신사업 FMS 데이터 파이프라인 구축기”의 1편으로 쏘카의 신사업 FMS(Fleet Management System) 서비스의 PoC 데이터 파이프라인을 구축한 경험을 소개하려고 합니다. PoC 제품 출시까지 시간이 제한된 상황에서 간결하고 관리 비용을 최소화할 수 있는 방향으로 아키텍처를 설계하였습니다. 본 글에서는 IoT 데이터 파이프라인을 구성하는 주요 요소들과 기술 스택을 선택한 이유들도 함께 소개 드리겠습니다.&lt;/p&gt;

&lt;p&gt;다음과 같은 분들이 읽으면 좋습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;실시간 데이터 파이프라인에 관심이 있는 소프트웨어 엔지니어&lt;/li&gt;
  &lt;li&gt;AWS 기반의 데이터 엔지니어링 환경 구축에 관심이 있는 소프트웨어 엔지니어&lt;/li&gt;
  &lt;li&gt;Kafka Connect를 활용한 메시지 소비에 관심이 있는 소프트웨어 엔지니어&lt;/li&gt;
  &lt;li&gt;쏘카의 데이터 엔지니어가 무슨 일을 하는지 궁금한 모든 이들&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;목차는 아래와 같습니다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;#1-fms-데이터-파이프라인-소개&quot;&gt;FMS 데이터 파이프라인 소개&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#2-스트리밍-파이프라인--iot-core에서-kafka로&quot;&gt;스트리밍 파이프라인 : IoT Core에서 Kafka로&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#3-스트리밍-파이프라인--kafka-sink-connector로-변형적재하기&quot;&gt;스트리밍 파이프라인 : Kafka Sink Connector로 변형/적재하기&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#4-배치-처리-플랫폼--반정형-데이터가-분석집계-되어-적재되기까지&quot;&gt;배치 처리 플랫폼 : 반정형 데이터가 분석/집계 되어 적재되기까지&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#5-마무리&quot;&gt;마무리&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;분량 관계상 Kafka에 대한 기본적인 설명이나 주요 컴포넌트들의 상세한 구현 설명 및 코드는 생략하겠습니다.
글을 읽으시면서 궁금한 점에 대해 편하게 댓글 남겨주시면 확인 후 답변드리겠습니다.&lt;/p&gt;

&lt;h2 id=&quot;1-fms-데이터-파이프라인-소개&quot;&gt;1. FMS 데이터 파이프라인 소개&lt;/h2&gt;

&lt;h3 id=&quot;11-fms-서비스-소개&quot;&gt;1.1. FMS 서비스 소개&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/img/build-fms-data-pipeline/socar.jpeg&quot; alt=&quot;socar.jpeg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;FMS는 Fleet Management System의 약자로, IoT 단말기를 차량에 부착해 데이터 기반으로 차량을 관제하고 운행 정보들을 분석하여 차량의 관리 및 운영을 효율화하는 차량 관제 플랫폼입니다.
FMS 서비스를 통해 고객사는 데이터 수집/분석된 차량들의 운영을 효율화하고 비용 절감, 안전 강화 등의 기대효과를 취할 수 있습니다.
2022년 6월부터 PoC 개발을 시작으로, 현재 주요 고객사들을 대상으로 PoC 서비스를 성공적으로 런칭하여 운영 중에 있습니다. 더 자세한 내용은 &lt;a href=&quot;https://platum.kr/archives/200744&quot;&gt;해당 기사&lt;/a&gt;를 참고해 주세요.&lt;/p&gt;

&lt;h3 id=&quot;12-fms-스트리밍배치-파이프라인-소개&quot;&gt;1.2. FMS 스트리밍/배치 파이프라인 소개&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/img/build-fms-data-pipeline/batch-and-streaming.png&quot; alt=&quot;batch-streaming.png&quot; /&gt;&lt;em&gt;배치 파이프라인과 스트리밍 파이프라인&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;보통 비즈니스/분석 요구사항에 맞게 데이터 파이프라인을 구축하다 보면 배치와 스트리밍에 대한 고민을 자연스럽게 하게 됩니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;배치&lt;/strong&gt;는 특정 시간 범위의 데이터를 일괄로 처리하는 기술을 뜻합니다. 배치로 데이터를 처리하기 위해선 보통 배치 잡을 오케스트레이션을 해주는 툴과 대용량 데이터를 처리하기 위한 환경을 구성합니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;스트리밍&lt;/strong&gt;은 생성되는 데이터를 실시간으로 처리하는 기술을 뜻합니다. 실시간으로 생성되는 데이터(메시지)를 일시적으로 저장하는 데이터베이스로 메시지 큐를 많이 활용합니다. 이는 대표적으로 Kafka, Redis, RabbitMQ 등의 오픈소스와 클라우드 서비스인 Kinesis, SQS, PubSub 등이 있습니다.&lt;/p&gt;

&lt;p&gt;FMS 프로젝트는 기본적으로 실시간 차량 관제와 같이 실시간 데이터에 대한 요구사항과 차량 운영을 위한 분석/집계된 배치 데이터의 요구사항이 모두 존재하였습니다. 따라서 스트리밍과 배치 파이프라인을 모두 구축해야 했습니다.
스트리밍 파이프라인은 MSK(Kafka)를 중심으로 Kafka Connect on EKS(Kubernetes)를 데이터 처리/적재 컴포넌트로 구성하였으며 차량 단말기의 메시지를 수신하기 위한 브로커로 IoT Core를 채택하였습니다.
배치 파이프라인은 MWAA(Airflow)와 데이터 레이크(S3 + Glue Catalog + Redshift Spectrum) 환경으로 구성하였습니다.&lt;/p&gt;

&lt;h3 id=&quot;13-주요-컴포넌트-소개&quot;&gt;1.3. 주요 컴포넌트 소개&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/img/build-fms-data-pipeline/fms-pipeline-batch-streaming.png&quot; alt=&quot;batch-streaming.png&quot; /&gt;&lt;em&gt;FMS 데이터 파이프라인 아키텍처 (배치/스트리밍)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;이번 챕터에서는 FMS 데이터 파이프라인을 구성하는 주요 컴포넌트들을 가볍게 소개 드리려고 합니다.
FMS 데이터 파이프라인은 크게 스트리밍 파이프라인과 배치 파이프라인으로 나눠집니다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;참고: 본 글에서는 실시간 조회에 사용되는 Redis와 관련 서비스(Consumer, Backend API 등)은 따로 다루지 않습니다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&quot;스트리밍-파이프라인&quot;&gt;스트리밍 파이프라인&lt;/h4&gt;

&lt;p&gt;실시간 파이프라인을 구성하는 주요 컴포넌트는 다음과 같습니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;IoT Core&lt;/strong&gt;&lt;br /&gt;
AWS IoT Core는 IoT 단말기의 메시지를 송/수신하는 메시지 브로커로 내부는 MQTT 프로토콜로 구현되어 있습니다. Fully Managed Service로 인프라 관리가 필요 없고 보안이나 단말기 관리 등의 이점이 있어 현재 쏘카 서비스와 FMS 모두 IoT Core를 차량 데이터의 매개체로 사용하고 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;MSK(Managed Streaming for Kafka Service)&lt;/strong&gt;&lt;br /&gt;
보통 실시간 데이터 파이프라인 아키텍처를 설계할 때 메시지 브로커인 Kafka를 많이 선택합니다. Kafka는 분산 스트리밍 플랫폼으로 실시간으로 들어오는 데이터를 확장성 있게 처리할 수 있어 많은 기업들이 메시지 브로커로 사용하고 있습니다.
AWS에서 제공하는 MSK(Managed Streaming for Kafka Service)는 Kafka를 완전 관리형으로 제공해 주고 보안, 모니터링 등을 폭넓게 지원해 줘서 사용자 측에서 관리 비용을 아끼고 애플리케이션 개발에 집중할 수 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Kafka Connect&lt;/strong&gt;&lt;br /&gt;
Kafka Topic에 저장된 메시지들을 데이터베이스/스토리지에 적재하기 위해서는 이를 처리하는 애플리케이션이 필요합니다. 일반적으로 각 프로그래밍 언어에서 이를 구현할 수 있도록 Consumer 라이브러리가 있습니다.&lt;br /&gt;
Kafka Connect는 Consumer를 메시지 추출(Source)과 적재(Sink)에 적절하게 추상화한 프레임워크입니다. 실제로 작업을 수행하는 Kafka Connector들을 Kafka Connect에 등록하여 관리하게 되는 구조라고 보시면 됩니다. 사용자는 이를 이용해 손쉽게 Kafka의 메시지를 추출/적재할 수 있습니다.&lt;/p&gt;

&lt;p&gt;이 외에도 실시간 집계 및 준 실시간 데이터 조회 목적으로 데이터베이스로는 DynamoDB를, 데이터 레이크 목적으로는 S3을 사용하고 있습니다.&lt;/p&gt;

&lt;h4 id=&quot;배치-파이프라인&quot;&gt;배치 파이프라인&lt;/h4&gt;

&lt;p&gt;다음은 배치 처리를 위한 컴포넌트입니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Lambda&lt;/strong&gt;&lt;br /&gt;
Lambda는 AWS의 서버리스 컴퓨팅 플랫폼으로 API 서버 형태로 활용이 가능할 뿐만 아니라 AWS 리소스(S3, Kafka, Kinesis 등)의 이벤트 기반으로 동작시킬 수 있어 활용 범위가 굉장히 넓습니다.&lt;br /&gt;
현재 배치 분석 집계를 할 때 S3의 적재된 Raw 파일을 타입에 맞게 분리하여 Parquet로 변환하는 용도로 Lambda를 사용하고 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Redshift&lt;/strong&gt;&lt;br /&gt;
Redshift는 AWS의 데이터 웨어하우스 서비스입니다. 표준 SQL(ANSI)를 따르며 대용량 데이터 처리를 빠르게 처리할 수 있어 데이터 웨어하우스 솔루션으로 AWS Athena(Presto 기반)와 함께 많이 사용되고 있습니다.&lt;br /&gt;
저희는 Redshift 운영 비용을 낮추기 위해 Serverless를 사용하고 S3에 적재된 Parquet를 읽을 수 있도록 Redshift Spectrum 기능을 도입하였습니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Glue Data Catalog&lt;/strong&gt;&lt;br /&gt;
Glue는 AWS의 완전 관리형 ETL 도구입니다. Glue는 크게 &lt;code class=&quot;highlighter-rouge&quot;&gt;Data Catalog&lt;/code&gt;와 &lt;code class=&quot;highlighter-rouge&quot;&gt;Data Integration and ETL&lt;/code&gt;로 나뉘는데, 이번에 저희가 주로 사용한 서비스는 Data Catalog입니다. Data Catalog는 비정형/반정형 데이터들을 SQL 형태로 조회할 수 있도록 메타 정보들(테이블, 파티션 등)을 저장하는 메타 스토어로 활용됩니다.&lt;br /&gt;
현재 S3에 Parquet로 데이터를 저장할 때 스키마를 추론하는 용도와 Redshift Spectrum에서 외부 테이블 형태로 사용할 때 Glue Catalog를 활용하고 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Airflow&lt;/strong&gt;&lt;br /&gt;
Airflow는 Airbnb에서 개발한 워크플로 관리 오픈소스로 현재 많은 기업에서 데이터 파이프라인을 자동화할 때 사용하는 툴입니다. 스케줄링, 재처리 기능, 외부와 연동해 주는 다양한 3rd Party 라이브러리, 직관적인 UI 등을 제공해 줘서 많은 기업들이 배치 처리를 할 때 사용하고 있습니다.&lt;br /&gt;
현재 &lt;a href=&quot;https://airflow.apache.org/docs/apache-airflow-providers-amazon/2.4.0/operators/redshift.html&quot;&gt;RedshiftSQLOperator&lt;/a&gt;를 활용해서 데이터 마트 데이터 집계를 스케줄링하는 데 사용하고 있습니다.&lt;/p&gt;

&lt;h3 id=&quot;14-데이터가-흐르는-순서&quot;&gt;1.4. 데이터가 흐르는 순서&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/img/build-fms-data-pipeline/fms-data-pipeline-all.png&quot; alt=&quot;overall-architecture.png&quot; /&gt;&lt;em&gt;FMS 데이터 파이프라인 아키텍처&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;차량에서 최초로 수집되는 여러 상태 데이터들은 최종적으로 데이터베이스/스토리지에 적재됩니다.
결과적으로는 데이터가 아래와 같은 흐름을 거쳐 FMS 서비스에 필요한 형태로 저장됩니다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;차량에서 다양한 상태의 데이터를 수집합니다.&lt;/li&gt;
  &lt;li&gt;수집되는 데이터는 발송 주기에 맞춰 IoT Core로 전송합니다.&lt;/li&gt;
  &lt;li&gt;IoT Core 메시지 브로커에 저장된 메시지는 라우팅 규칙에 따라 상위 주제별로 Kafka Topic으로 라우팅 됩니다.&lt;/li&gt;
  &lt;li&gt;Kafka Topic의 각 파티션에 저장된 메시지는 Kafka Connect를 통해 데이터 싱크(DynamoDB, S3)로 적재됩니다. (Redis는 필터링을 하는 Kafka Consumer를 통해 적재됩니다)&lt;/li&gt;
  &lt;li&gt;S3에 적재된 Json 포맷의 객체는 Lambda를 통해 분류/변형 후 S3에 적재됩니다 (Redshift, Athena 쿼리에 적합한 형태로 적재됩니다)&lt;/li&gt;
  &lt;li&gt;Airflow로 스케줄링된 Redshift 쿼리를 통해 데이터를 집계하여 RDS(데이터 마트)에 저장됩니다.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;2-스트리밍-파이프라인--iot-core에서-kafka로&quot;&gt;2. 스트리밍 파이프라인 : IoT Core에서 Kafka로&lt;/h2&gt;

&lt;h3 id=&quot;21-차량-iot-데이터의-특징&quot;&gt;2.1. 차량 IoT 데이터의 특징&lt;/h3&gt;

&lt;p&gt;FMS 서비스로 관리하는 차량들은 IoT 단말기 내에서 차량의 상태 정보를 수집한 뒤 서버(AWS IoT Core)로 전송합니다. 해당 메시지는 가공/적재 과정을 거쳐 서비스에서 활용됩니다.&lt;/p&gt;

&lt;p&gt;쏘카의 차량에서 수집되는 상태 메시지는 다음과 같은 특징들이 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;보고하는 유형의 메세지와 제어 응답 유형의 메시지가 있습니다.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;일반적으로 차량을 관제하기 위해선 차량 단말기에서 차량의 상태를 주기적으로 수집해서 보고하는 것이 필요합니다. 실제로 특정 프로토콜은 차량의 위치(위도, 경도)와 속도 같은 이동 정보를 주기적으로 보고하는 역할을 합니다.
이와는 다른 유형으로 제어 응답 메시지의 경우는, 서버에서 차량 단말기를 제어하기 위해 전송한 명령에 대해 단말기가 해당 명령을 수행하고 결과를 응답하는 용도로 사용합니다.
예를 들어 블랙박스에 녹화되고 있는 영상을 업로드하라는 명령이 있으면 단말기는 이를 수행한 후 결과를 메시지로 수집 서버에 전송합니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;차량의 상태를 표현하기 위한 다양한 프로토콜이 존재해 스키마 설계에 신경을 써야 합니다.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;FMS 서비스에서 차량 관제, 운전 효율화 등의 기능을 제공하기 위해선 다양한 수집 데이터를 필요로 합니다.
차량 운행 상태, 화물 차량의 온도 상태, 블랙박스 상태 등 각 역할 별로 프로토콜을 나눠서 수집해야 합니다. 실제로 현재 수집되는 수십여 개의 메시지 프로토콜은 특성과 목적에 맞게 분류되어 있습니다.&lt;/p&gt;

&lt;p&gt;위처럼 메시지 프로토콜이 다양하다 보니 쏘카에서는 프로토콜별로 스키마를 설계할 때 프로젝트에 참여하는 주요 팀들과 함께 논의를 진행했습니다. 덕분에 스키마 간의 통일성과 규칙이 생겼으며 데이터를 처리하는 쪽에서는 예측 가능하게 소프트웨어 개발이 가능했습니다. 개인적으로 스키마 설계를 할 때 이해관계자들이 함께 참여하는 것이 정말 중요하다고 느껴졌습니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;주기적으로 보고하는 유형은 보통 배치로 묶어서 전송하기에 적재할 때 다시 풀어줘야 합니다&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;단말기에서 수집하는 상태 정보들은 프로토콜 별로 설정된 Hz 수집 주기에 따라 수집됩니다. 이때 메시지를 수집 서버로 전송한다면 통신비나 클라우드 리소스(IoT Core, Kafka 등)의 비용이 더 비싸집니다. 따라서 비용 효율화를 위해 상태 정보를 배치 형태로 묶어서 전송 주기에 따라 전송됩니다. 그래서 주기 보고의 메시지는 아래와 같은 형태로 구성됩니다. 최종적으로 데이터베이스에서 레코드 별로 조회하기 위해선 배치 형태를 풀어줘야 합니다.&lt;/p&gt;

&lt;details&gt;
 &lt;summary&gt;주기 보고 메시지 형태&lt;/summary&gt;
 &lt;div&gt;

    &lt;div class=&quot;language-json highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
     &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;object&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;vehicle&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
     &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;type&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;kinematic&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
     &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;messaged_at&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;2023-01-01T12:00:00+09:00&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
     &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;measurements&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
         &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
             &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;timestamp_iso&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;2023-01-01T11:59:00+09:00&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
             &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;speed&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;30&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
             &lt;/span&gt;&lt;span class=&quot;err&quot;&gt;...&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
         &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
         &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
             &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;timestamp_iso&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;2022-01-01T11:59:01+09:00&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
             &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;speed&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;30&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
             &lt;/span&gt;&lt;span class=&quot;err&quot;&gt;...&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
         &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
         &lt;/span&gt;&lt;span class=&quot;err&quot;&gt;...&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
     &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
     &lt;/span&gt;&lt;span class=&quot;err&quot;&gt;...&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
 &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

  &lt;/div&gt;
 &lt;/details&gt;

&lt;h3 id=&quot;22-iot-core에서-kafka로&quot;&gt;2.2. IoT Core에서 Kafka로&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/img/build-fms-data-pipeline/iot-to-msk.png&quot; alt=&quot;iot-to-msk.jpeg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;차량에서 수집된 데이터는 IoT Core의 &lt;code class=&quot;highlighter-rouge&quot;&gt;메시지 라우팅&lt;/code&gt; 규칙에 따라 Kafka로 전송됩니다. 위 메시지에서 분류 목적으로 사용하고 있는 &lt;code class=&quot;highlighter-rouge&quot;&gt;object&lt;/code&gt; 필드에 대응되는 각 Kafka topic으로 라우팅 됩니다.&lt;/p&gt;

&lt;p&gt;여기서 한 가지 중요한 점은 하나의 topic에 여러 프로토콜의 메시지가 들어올 수 있다는 점입니다. 메시지 프로토콜에 1:1 대응되도록 topic을 만든다면 수많은 토픽을 관리해야 하며 관리에 대한 부담이 늘어나게 됩니다.&lt;br /&gt;
보통 Kafka를 운영하면 메시지 스키마에 대한 검증을 하기 위해 사용하는 Schema Registry를 사용하는 경우가 많습니다. 쏘카의 유즈케이스에서는 하나의 토픽에 여러 메시지가 들어오다 보니 Schema Registry를 도입하기가 쉽지 않았기에 우선 장애 없이 메시지를 적재하고 이후에 스키마를 검증하는 &lt;code class=&quot;highlighter-rouge&quot;&gt;fail safe&lt;/code&gt; 방식으로 아키텍처를 설계하였습니다.&lt;/p&gt;

&lt;h3 id=&quot;23-kafka-관리&quot;&gt;2.3. Kafka 관리&lt;/h3&gt;

&lt;p&gt;FMS 파이프라인에서는 MSK를 통해 Kafka를 운영하고 있습니다. 모니터링은 MSK의 &lt;a href=&quot;https://docs.aws.amazon.com/msk/latest/developerguide/metrics-details.html#topic-partition-metrics&quot;&gt;향상된 파티션 수준 모니터링&lt;/a&gt; 설정으로 Kafka 운영에 필요한 주요 메트릭을 cloudwatch에서 확인하고 있습니다. 이를 통해 기본 메트릭뿐만 아니라 Consumer Group 별로 Lag 확인이 가능해서 모니터링하는데 큰 도움이 되고 있습니다.&lt;/p&gt;

&lt;p&gt;토픽의 경우 메시지의 분류 필드인 &lt;code class=&quot;highlighter-rouge&quot;&gt;object&lt;/code&gt; 별로 생성하여 관리하고 있으며, 실패한 메시지들을 저장하는 deadletter 전용 토픽이나 일부 유즈케이스에 사용되는 토픽 등이 있습니다. 주요 topic들은 partition과 replication factor를 설정해서 처리 성능과 가용성을 높게 유지하고 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/build-fms-data-pipeline/kafka-ui.png&quot; alt=&quot;kafka-ui&quot; /&gt;&lt;em&gt;UI For Apache Kafka&lt;/em&gt;
저장되는 메시지는 실시간으로 &lt;strong&gt;UI for Apache Kafka&lt;/strong&gt;를 통해 확인하고 있습니다. UI for Apache Kafka는 직관적인 UI로 kafka 관리를 위한 많은 기능들을 제공해 줍니다. 특히 토픽에 쌓이는 메시지를 실시간으로 조회가 가능하며 여러 검색 방식을 지원해 줘서 초기에 Kafka 관리 툴로 사용하기에 적합합니다.&lt;/p&gt;

&lt;h2 id=&quot;3-스트리밍-파이프라인--kafka-sink-connector로-변형적재하기&quot;&gt;3. 스트리밍 파이프라인 : Kafka Sink Connector로 변형/적재하기&lt;/h2&gt;

&lt;p&gt;Kafka 토픽에 저장된 메시지를 외부 데이터 싱크(DynamoDB, S3)로 적재하는 Kafka Sink Connector를 개발하게 된 배경과 구현 사항, 장단점 등에 대해 알아보도록 하겠습니다.&lt;/p&gt;

&lt;h3 id=&quot;31-kafka-connect란&quot;&gt;3.1. Kafka Connect란?&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/img/build-fms-data-pipeline/kafka-connect.jpeg&quot; alt=&quot;kafka-connect.jpeg&quot; /&gt;&lt;em&gt;Kafka Connect의 역할 (출처: https://developer.confluent.io/learn-kafka/kafka-connect/intro)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;보통 Kafka 토픽의 메시지를 적재하기 위해선 크게 아래 2가지 방식을 활용합니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;프로그래밍 언어 별 존재하는 Kafka SDK를 사용해서 Kafka Consumer를 구현하는 방법&lt;/li&gt;
  &lt;li&gt;Kafka Connect를 활용하여 적재하는 방법&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Kafka Consumer는 높은 자유도로 개발이 가능하며, 다양한 프로그래밍 언어(JVM 계열 언어, Python, Javascript 등)로 개발할 수 있도록 SDK를 지원합니다. 일반적으로 Kafka 토픽의 메시지를 처리할 때 광범위하게 사용됩니다.&lt;/p&gt;

&lt;p&gt;Kafka Connect는 Consumer를 한 단계 추상화하여 제공하는 Confluent에서 개발한 프레임워크입니다. 데이터 소스에서 Kafka로 데이터를 옮기거나 Kafka에서 데이터 싱크로 적재하는 목적으로 주로 사용됩니다. 대중적인 데이터 소스/싱크에 대한 Connector(Mysql, MongoDB, S3, ElasticSearch 등)는 이미 오픈소스로 나와있어 손쉽게 사용이 가능합니다 (&lt;a href=&quot;https://www.confluent.io/hub&quot;&gt;Confluent Hub&lt;/a&gt;에서 확인이 가능합니다)
Kafka Connect에 대한 자세한 내용은 아래 토글을 눌러서 확인 부탁드립니다.&lt;/p&gt;

&lt;details&gt;
&lt;summary&gt;Kafka Connect의 장단점&lt;/summary&gt;
&lt;div&gt;

    &lt;ul&gt;
      &lt;li&gt;다양한 데이터 소스, 싱크에 대한 오픈소스를 활용하면 손쉽게 데이터 이동이 가능합니다.&lt;/li&gt;
      &lt;li&gt;프레임워크의 가이드를 따라 Connector를 손쉽게 개발하여 사용할 수 있습니다.&lt;/li&gt;
      &lt;li&gt;REST API를 통해 Kafka Connect의 운영이 가능합니다.&lt;/li&gt;
      &lt;li&gt;Worker와 Task 개수 조정을 통해 손쉽게 스케일 아웃이 가능합니다.&lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Property 기반으로 Kafka Connector 설정을 할 수 있어 선언적인(declarative) 소프트웨어 운영이 가능해집니다. 아래는 S3 Sink Connector를 배포할 때 API에 요청하는 스크립트 예시입니다.&lt;/p&gt;

        &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'
{
    &quot;connector.class&quot;: &quot;kr.socar.fms.connector.s3.S3SinkConnector&quot;,
    &quot;topics&quot;: &quot;OOO&quot;,
    &quot;tasks.max&quot;: &quot;1&quot;,
    &quot;key.converter.schemas.enable&quot;: &quot;false&quot;,
    &quot;value.converter.schemas.enable&quot;: &quot;false&quot;,
    &quot;value.converter&quot;: &quot;org.apache.kafka.connect.json.JsonConverter&quot;,
    &quot;key.converter&quot;: &quot;org.apache.kafka.connect.json.JsonConverter&quot;,
    &quot;flush.size&quot;: &quot;60000&quot;,
    &quot;rotate.interval.ms&quot;: &quot;300000&quot;,
    &quot;s3.part.size&quot;: &quot;60000000&quot;,
    &quot;partition.duration.ms&quot;: &quot;3600000&quot;,
    &quot;s3.region&quot;: &quot;ap-northeast-2&quot;,
    ...
}
'&lt;/span&gt; | curl &lt;span class=&quot;nt&quot;&gt;-X&lt;/span&gt; PUT &lt;span class=&quot;nt&quot;&gt;-d&lt;/span&gt; @- &lt;span class=&quot;nt&quot;&gt;-s&lt;/span&gt; localhost:8083/connectors/vehicle-to-s3/config &lt;span class=&quot;nt&quot;&gt;--header&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;content-Type:application/json&quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;

        &lt;p&gt;하지만 꼭 장점만 있는 것은 아닙니다.&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;Kafka Connect 프레임워크의 동작 방식을 기본적으로 이해하고 있어야 합니다.&lt;/li&gt;
      &lt;li&gt;Kafka Consumer에 비해 상대적으로 테스트하기나 디버깅하기가 불편합니다.&lt;/li&gt;
      &lt;li&gt;Java로 개발되어 있어 JVM 계열 언어로만 개발이 가능합니다.&lt;/li&gt;
      &lt;li&gt;간단한 변형 후 적재가 아닌 비즈니스 요구사항이나 복잡한 처리가 포함된 작업을 구현할 경우 Kafka Consumer로 구현하는 것이 수월합니다.&lt;/li&gt;
    &lt;/ul&gt;

    &lt;blockquote&gt;
      &lt;p&gt;Kafka Connect에 대한 더 자세한 설명은 &lt;a href=&quot;https://docs.confluent.io/platform/current/connect/index.html&quot;&gt;공식 문서&lt;/a&gt;를 참고해 주세요.&lt;/p&gt;
    &lt;/blockquote&gt;

  &lt;/div&gt;
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;Kafka Connect의 동작 방식&lt;/summary&gt;
&lt;div&gt;

    &lt;p&gt;Kafka Connect는 Kafka와 외부 데이터 소스/싱크를 연결해 주는 프레임워크입니다. Kafka Connector는 Kafka Connect에서 실제로 동작하는 구현체이며 Kafka Connect에 의해 관리됩니다. Kafka Connect를 사용하기 위해선 Kafka Connector를 jar 형태로 Kafka Connect 내부(보통 Docker Image)에 포함시킨 후, Kafka Conenct를 실행한 후 제공되는 API로 Kafka Connector를 등록하는 과정을 거치게 됩니다.&lt;/p&gt;

    &lt;p&gt;Kafka Connector는 Source와 Sink 2가지 방식을 제공합니다. Source Connector는 데이터 소스에서 Kafka 토픽으로 메시지를 전달하고 Sink Connector는 Kafka 토픽에서 데이터 싱크로 메시지를 전달합니다. 실제로 Kafka Connector를 구현하기 위해서 Source, Sink에 따라 나누어진 인터페이스를 따르게 됩니다.&lt;/p&gt;

    &lt;p&gt;Kafka Connect를 관리하기 위해선 &lt;code class=&quot;highlighter-rouge&quot;&gt;Worker&lt;/code&gt;와 &lt;code class=&quot;highlighter-rouge&quot;&gt;Task&lt;/code&gt;의 개념을 알고 있어야 합니다. Task는 Kafka Connector의 논리적인 실행 단위이며 JVM으로 실행되는 Process라고 보시면 됩니다. 보통 하나의 Task는 Kafka 토픽의 한 개 이상의 파티션을 담당합니다 (보통 1개의 Task가 1개의 파티션을 맡도록 운영합니다).&lt;/p&gt;

    &lt;p&gt;Worker는 Task를 운영하는 물리적인 프로세스로 Task의 라이프 사이클을 담당합니다. 즉 하나의 Worker에는 여러 개의 Task를 실행하고 있으며, Worker끼리 서로 통신하면서 Task를 재할당해 주기도 합니다. FMS 프로젝트에서는 Kubernetes 환경에서 Kafka Connect를 운영하며 이때 Worker는 &lt;code class=&quot;highlighter-rouge&quot;&gt;Pod&lt;/code&gt;이 됩니다.&lt;/p&gt;

    &lt;p&gt;Kafka Connect는 &lt;code class=&quot;highlighter-rouge&quot;&gt;Standalone Mode&lt;/code&gt;와 &lt;code class=&quot;highlighter-rouge&quot;&gt;Distributed Mode&lt;/code&gt;가 있는데, Standalone은 Worker를 1개, Distributed Mode는 Worker를 여러 개 사용할 수 있습니다. 주로 운영 환경에서 Kafka Connect는 Distributed Mode로 사용하며 여러 개의 Worker와 Task를 상황에 맞게 조정하며 변화되는 트래픽에 유연하게 대응합니다.&lt;/p&gt;

    &lt;blockquote&gt;
      &lt;p&gt;Kafka Connect의 동작 방식에 대한 더 자세한 내용은 &lt;a href=&quot;https://docs.confluent.io/platform/current/connect/concepts.html&quot;&gt;공식 문서의 Kafka Connect Concepts 부분&lt;/a&gt;을 참고해 주세요.&lt;/p&gt;
    &lt;/blockquote&gt;

  &lt;/div&gt;
&lt;/details&gt;

&lt;h3 id=&quot;32-요구-사항-및-결정-이유&quot;&gt;3.2. 요구 사항 및 결정 이유&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/img/build-fms-data-pipeline/msk-to-storage.png&quot; alt=&quot;msk-to-storage.jpeg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Kakfa 메시지 처리 방법을 선택할 때는 비즈니스 요구 사항을 고려하는 것이 중요합니다.
Kafka 토픽의 메시지를 단순하게 적재하는 경우라면 오픈소스 Kafka Connector를 사용하는 게 낫습니다.
하지만 FMS 프로젝트에는 아래와 같은 요구사항들이 있어서 Kafka Connector를 직접 개발하여 하나의 Kafka Connect로 메시지 적재를 관리하자는 결정을 내렸습니다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Kafka 토픽 별 메시지들이 S3와 DynamoDB에 적재되어야 합니다.&lt;/strong&gt;&lt;br /&gt;
Kafka에서 S3로 데이터를 적재하는 S3 Sink Connector는 오픈소스로 존재하여 많은 곳에서 사용하고 있습니다. 하지만 DynamoDB의 경우 Sink Connector가 오픈소스로 존재하지 않아 직접 구현이 필요한 상황이었습니다 (Confluenent에서 제공하는 Sink Connector가 있지만 유료 라이선스입니다) 이미 제공되는 S3 Sink Connector를 사용하면서 DynamoDB도 Connector 형태로 개발한다면 하나의 플랫폼으로 빌드, 운영할 수 있게 되어 이점이 있을 것이라고 판단하였습니다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;일부 요구사항에 맞게 가벼운 변형 작업이 필요합니다.&lt;/strong&gt;&lt;br /&gt;
 DynamoDB는 레코드를 추가할 때 Partition Key를 필수적으로 입력해야 합니다. FMS 프로젝트에서 DynamoDB 테이블은 비용/성능 효율화를 위해 &lt;a href=&quot;https://aws.amazon.com/ko/blogs/compute/creating-a-single-table-design-with-amazon-dynamodb/&quot;&gt;Single Table Design&lt;/a&gt; 기법으로 디자인했고 이에 맞는 Partition Key가 적재되기 전에 메시지에 추가되어야 합니다. 이외에도 비용 절감을 위해 불필요한 칼럼을 삭제하는 것도 고려가 필요합니다.&lt;/p&gt;

    &lt;p&gt;여기서 Kafka Connect에는 &lt;a href=&quot;https://docs.confluent.io/platform/current/connect/transforms/overview.html&quot;&gt;SMT(Single Message Transformation)&lt;/a&gt; 가 있어 Property 기반으로 손쉽게 메시지의 변형이 가능합니다. 물론 SMT 특성상 제약 사항이 존재하지만 필요하면 직접 Transfrom 을 구현하여 사용이 가능합니다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;스트리밍 환경에서 신뢰성과 확장성이 보장되어야 합니다.&lt;/strong&gt;&lt;br /&gt;
스트리밍 환경에서는 메시지를 빠르게 처리 후 적재하는 것이 중요합니다. 따라서 Kafka의 메시지가 빠르게 쌓여도 Transformation &amp;amp; Load 레이어에서는 일관성 있게 처리할 수 있어야 합니다.&lt;br /&gt;
Kafka Connect는 &lt;code class=&quot;highlighter-rouge&quot;&gt;Distributed Mode&lt;/code&gt;를 통해 Worker 개수를 조정하여 Scale Out/In을 쉽게 할 수 있으며, Worker가 만약 실패하더라도 기존 Worker 들에 Task들을 리밸런싱 해줘서 안전하게 운영이 가능합니다.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;결과적으로 DynamoDB Sink Connector를 직접 개발하였으며, S3 Sink Connector도 추가 요구사항을 위해 Class를 Override 하여 커스터마이징 하였습니다.&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&quot;34-kafka-connector-레포-구성-및-구현&quot;&gt;3.4. Kafka Connector 레포 구성 및 구현&lt;/h3&gt;

&lt;p&gt;Kafka Connector의 레포 구성 및 구현에 대해 알아보도록 하겠습니다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;...
.
├── ...
├── build.gradle.kts
├── Dockerfile
├── e2e
│   ├── Makefile
│   ├── docker-compose.e2e.yaml
│   ├── socar-fms-pipeline-docker
│   └── tests
└── subprojects
    ├── core
    │  ├── main/...
    │  |   ├── converters
    │  │   │   ├── SplitListConverter.kt
    │  │   │   └── UpdateFieldsConverter.kt
    │  │   └── transforms
    │  │       ├── InsertFieldInStringTemplate.kt
    │  │       └── SplitArrayField.kt
    │  └── test/...
    ├── dynamodb
    │   ├── main/...
    │   │   ├── DynamoDbDao.kt
    │   │   ├── DynamoDbSinkConnector.kt
    │   │   ├── DynamoDbSinkConnectorConfig.kt
    │   │   └── DynamoDbSinkTask.kt
    │   └── test/...
    └── s3
        ├── main/...
        │   ├── S3SinkConnector.kt
        │   ├── S3SinkConnectorConfig.kt
        │   └── S3SinkTask.kt
        └── test/...

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Kafka Connector를 구현하는 레포지토리는 Kotlin으로 작성되었으며 위와 같이 구성되어 있습니다. S3, DyanmoDB Sink Connector가 멀티 모듈 형태로 구성되어 있으며 공통 기능(변형)을 하는 모듈을 별도로 의존하고 있습니다.&lt;br /&gt;
DynamoDB의 경우 유일하게 Confluent에서 제공하는 Connector가 존재했지만 유료 라이선스이기에 직접 구현하는 것을 선택했습니다. 직접 구현하기 위해선 &lt;a href=&quot;https://mvnrepository.com/artifact/org.apache.kafka/connect-api&quot;&gt;connect-api&lt;/a&gt; 의존성을 추가해 줬습니다.&lt;br /&gt;
S3의 경우 Maven Repo에 올라와 있는 &lt;a href=&quot;https://mvnrepository.com/artifact/io.confluent/kafka-connect-s3&quot;&gt;kafka-connect-s3&lt;/a&gt;를 상속받아 구현하였습니다.&lt;/p&gt;

&lt;div class=&quot;language-gradle highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;implementation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;io.confluent:kafka-connect-s3:10.0.11&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;implementation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;org.apache.kafka:connect-api:$kafkaVersion&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;implementation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;org.apache.kafka:connect-transforms:$kafkaConnectTransformVersion&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;기본적으로 Sink Connector를 구현하기 위해선 &lt;code class=&quot;highlighter-rouge&quot;&gt;SinkConnector&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;SinkTask&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;AbstractConfig&lt;/code&gt; 3가지 추상 클래스를 구현해야 합니다.&lt;/p&gt;

&lt;p&gt;AbstractConfig는 Kafka Connector에 대한 설정 Config들을 작성합니다. 위에서 언급했듯이 Kafka Connector를 실행할 때 Property 기반으로 설정값을 입력하게 됩니다. 아래는 DynamoDB Sink Connector 설정값을 정의한 것으로 Table, Partition Key, Sort Key 등에 대한 입력이 있음을 확인할 수 있습니다.&lt;/p&gt;

&lt;div class=&quot;language-kotlin highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kd&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;DynamoDbSinkConnectorConfig&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;AbstractConfig&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;CONFIG&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;internal&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;companion&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;object&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;DYNAMODB_TABLE&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;dynamodb.table&quot;&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;DYNAMODB_TABLE_NAME_DOC&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;DynamoDB Target Table&quot;&lt;/span&gt;

        &lt;span class=&quot;k&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;DYNAMODB_TABLE_PARTITION_KEY&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;dynamodb.partition.key&quot;&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;DYNAMODB_TABLE_PARTITION_KEY_DOC&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;DynamoDB Partition Key&quot;&lt;/span&gt;

        &lt;span class=&quot;k&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;DYNAMODB_TABLE_SORT_KEY&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;dynamodb.sort.key&quot;&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;DYNAMODB_TABLE_SORT_KEY_DOC&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;DynamoDB Sort Key&quot;&lt;/span&gt;

        &lt;span class=&quot;k&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;CONVERTER_SPLIT_LIST_KEY&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;converter.split.list.key&quot;&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;CONVERTER_SPLIT_LIST_KEY_DOC&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Key for splitting record to array of record&quot;&lt;/span&gt;

        &lt;span class=&quot;k&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;CONVERTER_UPDATE_FIELDS_TEMPLATE&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;converter.update.fields.template&quot;&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;CONVERTER_UPDATE_FIELDS_TEMPLATE_DOC&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;fields template for update&quot;&lt;/span&gt;

        &lt;span class=&quot;o&quot;&gt;..&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;SinkConnector는 Task가 실행될 때 필요한 기능들을 작성합니다. Task가 실행, 중단될 때 동작이나 SinkTask, Config에 대한 정의를 합니다.&lt;/p&gt;

&lt;div class=&quot;language-kotlin highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kd&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;DynamoDbSinkConnector&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;SinkConnector&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;logger&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;LoggerFactory&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;getLogger&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;DynamoDbSinkConnector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;java&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;lateinit&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;sinkConfig&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;DynamoDbSinkConnectorConfig&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;..&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;override&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;fun&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;version&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;..&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;override&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;fun&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;start&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;props&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;MutableMap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;..&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.}&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;override&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;fun&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;stop&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;..&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.}&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;override&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;fun&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;taskClass&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Class&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;out&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Task&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;DynamoDbSinkTask&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;java&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;override&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;fun&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;taskConfigs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;maxTasks&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;MutableList&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;MutableMap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;..&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.}&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;override&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;fun&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;DynamoDbSinkConnectorConfig&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;CONFIG&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;SinkTask는 실제로 메시지를 처리하는 Task의 구현합니다. 메시지를 DynamoDB 적재하기 위해 필요한 의존성들을 초기화하여 사용하게 됩니다. 대표적으로 DynamoDB와 통신하는 역할을 하는 &lt;code class=&quot;highlighter-rouge&quot;&gt;DynamoDBDao&lt;/code&gt;이나 변형을 담당하는 Converter 등이 있습니다(Converter의 역할은 아래에서 다룹니다). 그리고 실제 메시지를 처리하는 부분은 &lt;code class=&quot;highlighter-rouge&quot;&gt;put&lt;/code&gt; 메서드에서 작성하게 됩니다.&lt;/p&gt;

&lt;div class=&quot;language-kotlin highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;open&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;DynamoDbSinkTask&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;SinkTask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;logger&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;LoggerFactory&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;getLogger&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;DynamoDbSinkTask&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;java&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;reporter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ErrantRecordReporter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;?&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;null&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;lateinit&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;DynamoDbSinkConnectorConfig&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;lateinit&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;dao&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;DynamoDbDao&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;lateinit&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;splitArrayConverter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;SplitListConverter&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;lateinit&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;updateFieldsConverter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;UpdateFieldsConverter&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;override&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;fun&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;version&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;..&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;override&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;fun&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;start&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;props&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;MutableMap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;gt;?)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;..&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.}&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;override&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;fun&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;stop&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(){&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;..&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.}&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;override&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;fun&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;put&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;records&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;MutableCollection&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;SinkRecord&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;gt;?)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;// 메시지 변형&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;// 예외 메시지 방어 처리 및 DeadletterQueue 전송&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;..&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;// DynamoDb 적재&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;logger&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;info&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;dynamodb request item size : ${passed.size}&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;kd&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;response&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dao&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;batchWrite&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;passed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;partition&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;it&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;unprocessedItems&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;isEmpty&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;..&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;위에서 Sink Connector를 직접 구현한 DynamoDB Connector의 구현부에 대해 알아보았습니다. S3 Sink Connector 같은 경우 기존 구현체(kafka-connect-s3)를 상속받아서 변형 작업만 일부 추가하였습니다.&lt;/p&gt;

&lt;div class=&quot;language-kotlin highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;open&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;S3SinkTask&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ConfluentS3SinkTask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;logger&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;LoggerFactory&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;getLogger&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;S3SinkTask&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;java&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;reporter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ErrantRecordReporter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;?&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;null&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;lateinit&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;S3SinkConnectorConfig&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;lateinit&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;splitArrayConverter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;SplitListConverter&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;lateinit&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;updateFieldsConverter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;UpdateFieldsConverter&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;override&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;fun&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;version&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;..&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;override&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;fun&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;start&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;props&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;MutableMap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;gt;?)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;..&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.}&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;override&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;fun&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;stop&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(){&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;..&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.}&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;override&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;fun&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;put&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;records&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;MutableCollection&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;SinkRecord&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;gt;?)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;// 변형 및 예외 방어 로직&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;..&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;put&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;newRecords&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;직접 Kafka Connector를 개발하면서 &lt;a href=&quot;https://docs.confluent.io/platform/current/connect/devguide.html#developing-a-simple-connector&quot;&gt;공식 가이드&lt;/a&gt;를 참고하였고 구현 코드는 S3 Sink Connector의 구현체인 &lt;a href=&quot;https://github.com/confluentinc/kafka-connect-storage-cloud&quot;&gt;kafka-connect-storage-cloud&lt;/a&gt; 소스코드를 보면서 빠르게 코드 작성을 할 수 있었습니다. 직접 Kafka Connector를 구현하시는 분들께 도움이 되었으면 합니다.&lt;/p&gt;

&lt;h3 id=&quot;35-kafka-connector-변형transformation&quot;&gt;3.5. Kafka Connector 변형(Transformation)&lt;/h3&gt;

&lt;p&gt;이번에는 Kafka Connector에서 구현한 변형 기능에 대해 알아보도록 하겠습니다. 위에서 언급한 것처럼 Kafka Connector는 Propery 기반으로 Configuration 설정을 할 수 있어 Connector Task를 선언적으로 관리할 수 있는 장점이 있습니다.&lt;br /&gt;
따라서 메시지 변형 관련 설정도 최대한 Property 기반으로 관리할 수 있도록 하였으며, 이를 위해서 비즈니스 로직은 최대한 제외하고 Property로 설정할 수 있도록 추상화하였습니다. 이를 통해 Kafka Connector가 새로 추가되는 토픽이나 다른 프로젝트에서 사용돼도 문제가 없도록 하였습니다.&lt;/p&gt;

&lt;p&gt;DynamoDB는 레코드를 추가할 때 Partition Key를 필수적으로 입력해야 합니다. FMS 프로젝트에서 DynamoDB 테이블은 비용/성능 효율화를 위해 &lt;a href=&quot;https://aws.amazon.com/ko/blogs/compute/creating-a-single-table-design-with-amazon-dynamodb/&quot;&gt;Single Table Design&lt;/a&gt; 기법으로 디자인했고 이에 맞는 Partition Key를 추가해 줘야 했습니다. Kafka Connect에는 &lt;a href=&quot;https://docs.confluent.io/platform/current/connect/transforms/overview.html&quot;&gt;SMT(Single Message Transformation)&lt;/a&gt; 가 있어 Property 기반으로 손쉽게 메시지의 변형이 가능합니다. 물론 SMT 특성상 제약 사항이 존재하지만 필요하면 직접 Transfrom 을 구현하여 사용이 가능합니다.&lt;/p&gt;

&lt;p&gt;아래는 메시지를 템플릿 언어 기반으로 변경할 수 있도록 구현한 Transform입니다.&lt;/p&gt;

&lt;div class=&quot;language-json highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;transforms&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;InsertFieldInStringTemplate&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;transforms.InsertFieldInStringTemplate.field&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;pk&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;transforms.InsertFieldInStringTemplate.value&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;${id}#${object}#${type}&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;as-is&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-json highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;object&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;vehicle&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;type&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;kinematic&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;id&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;350&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;to-be&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-json highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;object&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;vehicle&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;type&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;kinematic&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;id&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;350&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;pk&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;350#vehicle#kinematic&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;또한 위에서 언급했듯이 FMS 프로젝트의 차량 IoT 데이터는 보통 배치로 묶여서 메시지들이 들어옵니다. 만약 클라이언트가 nested된 형태의 데이터를 쿼리 하는 경우 전처리를 진행해야 하는 불편함이 생기기에 적재하기 전에 데이터를 풀어서 적재해 주는 것이 좋습니다.&lt;br /&gt;
보통 메시지를 전처리하기 위해서 적재 전에 별도의 Consumer를 두곤 하지만, PoC 단계에서 관리 포인트를 높이고 싶지 않았습니다. 그래서 Kafka Connector에서 Property 기반으로 배치 메시지를 풀어줄 수 있도록 Converter를 구현하고 Property를 통해 조작이 가능하도록 했습니다(Kafka Connector의 Converter API와는 다릅니다).&lt;/p&gt;

&lt;div class=&quot;language-json highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;converter.split.list.key&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;measurements&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;배치 메시지를 풀어낼 필드를 입력하면 아래와 같이 해당 필드의 배열을 메시지를 쪼갭니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;as-is&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-json highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;object&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;vehicle&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;type&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;kinematic&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;messaged_at&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;2023-01-01T12:00:00+09:00&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;measurements&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
            &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;timestamp_iso&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;2023-01-01T11:59:00+09:00&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
            &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;speed&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;30&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
            &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;timestamp_iso&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;2022-01-01T11:59:01+09:00&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
            &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;speed&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;40&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;to-be&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-json highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;object&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;vehicle&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;type&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;kinematic&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;messaged_at&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;2023-01-01T12:00:00+09:00&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;timestamp_iso&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;2023-01-01T11:59:00+09:00&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;speed&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;30&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;object&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;vehicle&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;type&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;kinematic&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;messaged_at&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;2023-01-01T12:00:00+09:00&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;timestamp_iso&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;2023-01-01T11:59:01+09:00&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;speed&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;45&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;36-kafka-connect-배포-및-운영&quot;&gt;3.6. Kafka Connect 배포 및 운영&lt;/h3&gt;

&lt;p&gt;이제 Kafka Connect 배포 및 운영에 대해 알아보도록 하겠습니다. FMS 프로젝트에서 Kafka Connect는 Kubernetes(AWS EKS)에서 프로비저닝하고 있습니다. 아래 Dockerfile에서 보시는 것처럼 Kubernetes에서 배포하기 위해 Kafka Connect 이미지가 필요합니다. 이에 DynamoDB, S3 Sink Connector를 jar로 빌드 한 후 Kafka Connect 이미지에 파일을 마운트 합니다. 만약 Connector가 추가되면 여기서 마운트를 시켜줍니다.&lt;/p&gt;

&lt;div class=&quot;language-dockerfile highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; openjdk:17-jdk-slim-buster AS builder&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;WORKDIR&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; /usr/src/app&lt;/span&gt;
...
&lt;span class=&quot;k&quot;&gt;COPY&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; subprojects subprojects&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;RUN &lt;/span&gt;./gradlew :s3:uberjar &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; ./gradlew :dynamodb:uberjar

&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; confluentinc/cp-kafka-connect:$KAKFA_CONNECT_VERSION&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;ARG&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; FMS_CONNECTOR_PATH=&quot;/usr/share/fms-connectors&quot;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;ENV&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; CONNECT_PLUGIN_PATH $CONNECT_PLUGIN_PATH,$FMS_CONNECTOR_PATH&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;ENV&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; JAVA_OPTS=&quot;-XX:+UseG1GC -XX:MaxGCPauseMillis=100 -XX:+ExitOnOutOfMemoryError -Xmx1024m -Xms1024m&quot;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;COPY&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; --from=builder /usr/src/app/subprojects/dynamodb/build/libs $FMS_CONNECTOR_PATH&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;COPY&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; --from=builder /usr/src/app/subprojects/s3/build/libs $FMS_CONNECTOR_PATH&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;CI 파이프라인에서는 Github Action을 사용합니다. Github Action에서는 &lt;code class=&quot;highlighter-rouge&quot;&gt;main&lt;/code&gt; 브랜치의 Tag Push가 발생했을 때 각 Connector 별 유닛 테스트와 Kafka Connect의 E2E 테스트 (Docker Compose 기반)을 수행합니다. 만약 통과했을 시 AWS ECR로 이미지를 빌드 후 배포합니다.&lt;/p&gt;

&lt;p&gt;Kubernetes 프로비저닝을 위해서는 Helm chart을 사용합니다. &lt;a href=&quot;https://github.com/confluentinc/cp-helm-charts&quot;&gt;cp-kafka-connect 차트&lt;/a&gt;를 Clone 해서 사용하고 있으며 추후 &lt;a href=&quot;https://strimzi.io/&quot;&gt;strimizi&lt;/a&gt;로 환경을 옮길 계획입니다. Helm Chart의 배포는 ArgoCD를 사용하고 있습니다.&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;na&quot;&gt;replicaCount&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;3&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# Worker 개수를 설정합니다 (k8s Deployment로 관리됩니다)&lt;/span&gt;

&lt;span class=&quot;na&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;...&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;imageTag&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;...&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;imagePullPolicy&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;...&lt;/span&gt;

&lt;span class=&quot;na&quot;&gt;heapOptions&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;-Xms512M&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;-Xmx1024M&quot;&lt;/span&gt;

&lt;span class=&quot;na&quot;&gt;kafka&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;bootstrapServers&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;...&lt;/span&gt;

&lt;span class=&quot;na&quot;&gt;configurationOverrides&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# Worker Configuration를 입력합니다.&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;plugin.path&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;/usr/share/java,/usr/share/confluent-hub-components,/usr/share/fms-connectors&quot;&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;key.converter&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;org.apache.kafka.connect.storage.StringConverter&quot;&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;value.converter&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;org.apache.kafka.connect.storage.StringConverter&quot;&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;key.converter.schemas.enable&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;false&quot;&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;value.converter.schemas.enable&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;false&quot;&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;...&lt;/span&gt;
&lt;span class=&quot;nn&quot;&gt;...&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Kafka Connect는 &lt;a href=&quot;https://docs.confluent.io/platform/current/connect/references/restapi.html#kconnect-rest-interface&quot;&gt;REST API&lt;/a&gt;를 통해 Kafka Connector 운영이 가능합니다. 따라서 Shell Script 파일을 실행해 API를 호출하게 되며 Kafka Connector는 여기서 Task 단위로 실행됩니다.&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;for &lt;/span&gt;obj &lt;span class=&quot;k&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;vehicle&quot;&lt;/span&gt; ... &lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;do&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;# topic 별로 Kafka Connector를 배포합니다&lt;/span&gt;
  &lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'
  {
      &quot;connector.class&quot;: &quot;kr.socar.fms.connector.s3.S3SinkConnector&quot;,
      &quot;topics&quot;: &quot;fms.'&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;obj&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'.real.msk&quot;,
      &quot;tasks.max&quot; : &quot;1&quot;,
      &quot;converter.split.list.key&quot;: &quot;measurements&quot;,
      ...
  }
  '&lt;/span&gt; | curl &lt;span class=&quot;nt&quot;&gt;-X&lt;/span&gt; PUT &lt;span class=&quot;nt&quot;&gt;-d&lt;/span&gt; @- &lt;span class=&quot;nt&quot;&gt;-s&lt;/span&gt; localhost:8083/connectors/&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;obj&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;-to-s3&lt;/span&gt;/config &lt;span class=&quot;nt&quot;&gt;--header&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;content-Type:application/json&quot;&lt;/span&gt;

  &lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'
  {
        &quot;connector.class&quot; : &quot;kr.socar.fms.connector.dynamodb.DynamoDbSinkConnector&quot;,
        &quot;topics&quot;: &quot;fms.'&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;obj&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'.real.msk&quot;,
        &quot;tasks.max&quot; : &quot;1&quot;,
        &quot;converter.split.list.key&quot;: &quot;measurements&quot;,
        ...
        ...
  }
  '&lt;/span&gt; | curl &lt;span class=&quot;nt&quot;&gt;-X&lt;/span&gt; PUT &lt;span class=&quot;nt&quot;&gt;-d&lt;/span&gt; @- &lt;span class=&quot;nt&quot;&gt;-s&lt;/span&gt; localhost:8083/connectors/&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;obj&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;-to-dynamodb&lt;/span&gt;/config &lt;span class=&quot;nt&quot;&gt;--header&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;content-Type:application/json&quot;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;done&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;37-kafka-connect-운영-시-고려할-점&quot;&gt;3.7. Kafka Connect 운영 시 고려할 점&lt;/h3&gt;

&lt;p&gt;Kafka Connector를 운영하면서 신경 썼던 지점들도 말씀드리겠습니다.&lt;/p&gt;

&lt;h4 id=&quot;371-메시지-중복-처리&quot;&gt;3.7.1. 메시지 중복 처리&lt;/h4&gt;

&lt;p&gt;실시간 데이터가 저장소에 저장될 때 데이터가 중복되거나 손실되지 않아야 합니다. 만약 특정 Offset의 메시지를 적재하는 과정에서 Kafka Connector가 문제가 생겨 리밸런싱이 발생한다면 메시지의 누락이나 중복이 발생할 수도 있습니다. 중복은 저장소에서 후처리를 할 수 있지만, 누락은 복구하기가 힘들어 더 조심해야 합니다.&lt;/p&gt;

&lt;p&gt;이때 메시지를 처리하는 영역(Producer, Consumer)에서는 &lt;code class=&quot;highlighter-rouge&quot;&gt;Message Delivery Semantics&lt;/code&gt;라고 해서 메시지를 전송하는 전략을 결정합니다. 대표적으로 &lt;code class=&quot;highlighter-rouge&quot;&gt;At Least Once&lt;/code&gt;는 적어도 한 번 이상의 메시지를 다시 보내겠다는 의미로 메시지의 누락은 발생하지 않지만 중복이 발생할 수 있습니다. 반면 &lt;code class=&quot;highlighter-rouge&quot;&gt;Exactly Once&lt;/code&gt;는 메시지를 정확히 한 번씩만 보내겠다는 의미로 누락과 중복이 발생하지 않습니다. 이는 다운타임이 있더라도 정확하게 처리했던 메시지의 Offset을 기억해서 동작함을 의미합니다.&lt;/p&gt;

&lt;p&gt;S3 Sink Connector는 특정 조건에서 Exactly Once를 지원합니다(&lt;a href=&quot;https://docs.confluent.io/kafka-connectors/s3-sink/current/overview.html#exactly-once-delivery-on-top-of-eventual-consistency&quot;&gt;공식 문서의 S3 Object Uploads 부분&lt;/a&gt; 참고). DynamoDB Sink Connector의 경우 At Least Once 방식으로 구현을 했습니다. 이유는 DynamoDB의 경우 같은 메시지(Primiary Key가 같은 경우)는 Upsert 하기 때문에 중복 이슈는 발생하지 않을 것이라 판단하였습니다.&lt;/p&gt;

&lt;h4 id=&quot;372-에러-핸들링&quot;&gt;3.7.2. 에러 핸들링&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;/img/build-fms-data-pipeline/inside-kafka-connect.jpeg&quot; alt=&quot;inside-kafka-connect&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Kafka Sink Connector는 실행될 때 앞단에서 메시지를 검증/전처리하는 &lt;code class=&quot;highlighter-rouge&quot;&gt;Converter&lt;/code&gt;와 &lt;code class=&quot;highlighter-rouge&quot;&gt;Transform&lt;/code&gt;이 위치합니다. 만약 메시지가 해당 Converter나 Transform 조건에 맞지 않는 경우 Error Message로 간주하게 됩니다. 이때 &lt;code class=&quot;highlighter-rouge&quot;&gt;errors.tolerance&lt;/code&gt;를 적용해서 &lt;code class=&quot;highlighter-rouge&quot;&gt;None&lt;/code&gt;(기본값)일 경우 Task를 실패시키고, &lt;code class=&quot;highlighter-rouge&quot;&gt;all&lt;/code&gt;일 경우 메시지를 생략하고 다음 메시지를 처리하게 됩니다.&lt;/p&gt;

&lt;p&gt;FMS 프로젝트에서는 &lt;code class=&quot;highlighter-rouge&quot;&gt;all&lt;/code&gt;을 설정해 생략되는 메시지는 Deadletter Queue로 보내도록 해 모니터링 및 재처리가 가능하도록 하였습니다. Deadletter Queue로 사용될 Topic을 생성하고 운영하는 Task 들에서 문제가 발생한 메시지는 해당 Topic으로 보내도록 설정하였습니다.&lt;/p&gt;

&lt;div class=&quot;language-json highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;errors.tolerance&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;all&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;errors.deadletterqueue.topic.name&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;fms.all.deadletter.msk&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;errors.deadletterqueue.topic.replication.factor&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;errors.deadletterqueue.context.headers.enable&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;true&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;errors.log.include.messages&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;true&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;만약 Connector Instance에서 메시지 처리에 실패하는 경우 에러로 인해 Task가 실패할 수 있습니다. 이 경우 모니터링한 후 다시 Task를 실행해 줘야 합니다.&lt;br /&gt;
만약 Kafka Connector를 직접 개발하시는 경우 Connector Instance에서 발생한 에러 메시지를 Deadletter Queue로 보내도록 돕는&lt;a href=&quot;https://cwiki.apache.org/confluence/display/KAFKA/KIP-610%3A+Error+Reporting+in+Sink+Connectors&quot;&gt;ErrantRecordReporter&lt;/a&gt;를 사용해 보시는 걸 추천드립니다.&lt;/p&gt;

&lt;p&gt;Kafka Connector의 에러 핸들링에 대해 더 자세하게 알고 싶다면 &lt;a href=&quot;https://www.confluent.io/blog/kafka-connect-deep-dive-error-handling-dead-letter-queues/&quot;&gt;여기&lt;/a&gt;를 확인해 보세요.&lt;/p&gt;

&lt;h3 id=&quot;38-kafka-connect-모니터링하기&quot;&gt;3.8. Kafka Connect 모니터링하기&lt;/h3&gt;

&lt;p&gt;Kafka Connect는 기본적으로 jmx를 통해 운영에 필요한 메트릭들을 제공합니다. FMS 프로젝트에서 모니터링 툴로 Prometheus와 Grafana를 사용하고 있으므로, prometheus에서 jmx의 메트릭을 수집할 수 있도록 돕는 &lt;a href=&quot;https://github.com/prometheus/jmx_exporter&quot;&gt;jmx_exporter&lt;/a&gt;를 사용하여 prometheus와 연동하였습니다.&lt;br /&gt;
(Kafka Connect 메트릭과 관련해 더 자세한 내용은 &lt;a href=&quot;https://docs.confluent.io/kafka-connectors/self-managed/monitoring.html#using-jmx-to-monitor-kconnect&quot;&gt;여기&lt;/a&gt;를 확인해 보세요)&lt;/p&gt;

&lt;p&gt;Kafka 토픽의 메시지가 잘 처리되고 있는지를 나타내는 &lt;code class=&quot;highlighter-rouge&quot;&gt;Consumer Lag&lt;/code&gt;도 꼭 확인해야 할 메트릭 중 하나입니다. AWS MSK의 모니터링 설정을 통해 Cloud Watch에서 Consumer Lag을 확인할 수 있기에 Grafana Dashboard에서 Cloud Watch를 연동해 함께 확인하고 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/build-fms-data-pipeline/grafana-slack-alert.png&quot; alt=&quot;grafana-slack-alert&quot; /&gt;
만약 모니터링 중 이상이 발생하는 경우 &lt;code class=&quot;highlighter-rouge&quot;&gt;Grafana Alert&lt;/code&gt;를 사용해 슬랙 모니터링 채널로 메시지를 보내고 있습니다.&lt;/p&gt;

&lt;h2 id=&quot;4-배치-처리-플랫폼--반정형-데이터가-분석집계되어-적재되기까지&quot;&gt;4. 배치 처리 플랫폼 : 반정형 데이터가 분석/집계되어 적재되기까지&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/img/build-fms-data-pipeline/batch-platform.png&quot; alt=&quot;batch-platform.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이번 장에서는 FMS 프로젝트에서 구축한 배치 처리 플랫폼에 대해 소개 드리겠습니다. 위에서 말씀드린 것처럼 차량의 이동 정보와 같은 실시간 조회의 경우 Redis를, 실시간 집계 및 준 실시간 데이터 조회에는 DynamoDB를 사용하였습니다. 배치로 처리되는 데이터는 본 플랫폼을 거쳐 데이터 마트(RDS)에 적재됩니다.&lt;br /&gt;
이번 장에서는 Lambda, Glue Catalog, Redshift를 중심으로 배치 처리 플랫폼을 설명드리겠습니다.&lt;/p&gt;

&lt;h3 id=&quot;41-요구사항-및-결정-사항&quot;&gt;4.1. 요구사항 및 결정 사항&lt;/h3&gt;

&lt;p&gt;배치 처리 플랫폼 환경을 구축하기 위해 아래와 같은 요구사항들을 고려하였습니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;분석가들이 쿼리를 작성할 수 있는 형태의 시스템이 필요합니다&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;고객사에게 운영 인사이트를 제공하기 위해 데이터 분석/집계 과정이 꼭 필요합니다. 데이터를 다루는 팀원들에게 익숙한 SQL 환경을 제공해 주는 것이 초기 비용 대비 생산성이 높다고 판단하였습니다. 따라서 Spark 같은 대용량 처리 엔진이 아닌 ANSI SQL에 호환되는 Athena나 Redshift로 선택지를 좁혔습니다.
Athena는 AWS에서 제공하는 대화형 쿼리 서비스로 내부적으로 Presto 엔진을 사용하고 있습니다.
프로젝트 개발 초기에 Athena를 사용하다가 일부 윈도우 함수의 지원이 되지 않는 이슈가 확인되어, 윈도우 함수가 지원되고 퍼포먼스 측면에서도 이점이 있는 Redshift로 선택하였습니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;S3에 적재된 데이터는 Redshift의 조회에 최적화되어야 합니다&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;또한 Column 기반 저장 포맷과 높은 압축률이 특징인 Parquet로 파일 포맷을 가져가는 것도 좋은 선택지입니다.
Redshift Spectrum을 통해 S3에서 데이터를 조회할 때 탐색 시간과 비용을 줄이기 위해선 대표적으로 해야 하는 Practice들이 존재합니다 (더 자세한 내용은 &lt;a href=&quot;https://aws.amazon.com/ko/blogs/big-data/10-best-practices-for-amazon-redshift-spectrum/&quot;&gt;여기&lt;/a&gt;를 확인해 주세요). 이 중에서 필수적으로 해야 할 것 중 하나는 쿼리의 풀 스캔을 막기 위해서 S3 객체들을 파티션에 따라 적재하는 것입니다(S3 Partititon 개념은 &lt;a href=&quot;https://docs.aws.amazon.com/ko_kr/athena/latest/ug/partitions.html&quot;&gt;여기&lt;/a&gt;를 참고해 주세요)&lt;/p&gt;

&lt;p&gt;S3 Sink Connector에 적재된 원본 Json 데이터는 여러 타입의 메시지들이 함께 포함되어 있습니다(위에서 언급했듯이 하나의 Kafka 토픽에 여러 메시지 프로토콜이 존재합니다). 따라서 Redshft에서 테이블 단위로 조회하기 때문에 메시지들로 같은 타입으로 분류되어 있어야 합니다.
위 방식들을 적용하기 위해서 원본 데이터를 전처리하여 S3에 적재하는 도구로 &lt;code class=&quot;highlighter-rouge&quot;&gt;Lambda&lt;/code&gt;를 선택하였습니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;주기적으로 분석/집계하는 쿼리를 실행하고 적재할 수 있어야 합니다&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;일, 주 단위 집계를 위해서는 주기적으로 Redshift 쿼리를 실행하고 중간 과정을 거쳐 데이터 마트에 적재해야 합니다. 집계 데이터 적재를 위한 데이터 마트는 조회가 용이한 &lt;code class=&quot;highlighter-rouge&quot;&gt;RDS(Mysql)&lt;/code&gt;를 선택하였습니다. 또한 Redshift 쿼리 실행 및 적재를 위한 스케줄링 도구로 &lt;code class=&quot;highlighter-rouge&quot;&gt;MWAA(Managed Worflow Apache Airflow)&lt;/code&gt;를 선택하였습니다. 데이터 본부에서는 Airflow 사용이 익숙하기도 하고 팀 내에서 Airflow 운영에 대한 전문성이 높기에 자연스럽게 결정하였습니다.&lt;/p&gt;

&lt;h3 id=&quot;42-배치-처리-플랫폼의-흐름&quot;&gt;4.2. 배치 처리 플랫폼의 흐름&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/img/build-fms-data-pipeline/analytics-platform.png&quot; alt=&quot;analytics-platform&quot; /&gt;&lt;/p&gt;

&lt;p&gt;위 이미지를 통해 배치로 데이터가 처리되는 흐름을 파악할 수 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;1. S3 Sink Connector를 통해 차량 단말기의 데이터가 S3에 Json 포맷으로 적재됩니다.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;5분 주기로 각 Kafka 토픽의 메시지들이 S3에 &lt;a href=&quot;https://docs.aws.amazon.com/ko_kr/athena/latest/ug/partitions.html&quot;&gt;파티셔닝(Hive Partition)&lt;/a&gt; 되어 적재됩니다. 예를 들어 &lt;code class=&quot;highlighter-rouge&quot;&gt;object=vehicle/type=kinematic/year=2022/month=12/day=25/hour=11&lt;/code&gt;과 같이 시간 분류를 위한 년, 월, 일, 시간과 메시지 프로토콜 별로 분류를 위한 파티션들로 각각 분류되어 데이터가 적재됩니다. 이렇게 파티션으로 분류된 데이터는 Athena, Redshift 같은 쿼리 엔진에서 데이터를 효율적으로 조회할 수 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;2. Lambda의 이벤트 트리거를 통해 원본 JSON의 타입별로 분류하여 Parquet로 형 변환하여 적재합니다&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;위 요구사항에서 언급한 것처럼, Redshift에서 효율적으로 조회하기 위해서 원본 데이터의 전처리 작업이 필요합니다. Lambda 함수는 타입별로 메시지를 분류하며 Parquet로 적재합니다. 이때 Redshift의 분석 패턴에 맞게 Range 스캔이 쉽도록 &lt;code class=&quot;highlighter-rouge&quot;&gt;.../ymd=2022-12-25/hour=11&lt;/code&gt; 다음과 같은 파티션으로 변경해서 적재합니다.&lt;br /&gt;
적재하는 과정에서 Glue Table을 통한 메시지 Schema에 대한 검증을 진행하며 문제가 있다면 AWS SQS로 실패한 이벤트 정보를 전송합니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;3. Airflow로 Redshift 집계 쿼리를 스케줄링하여 데이터 마트(RDS)에 적재합니다.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Airflow에서 Redshift 조회 결과를 Mysql(RDS)에 적재하기 위해서 Custom Operator를 구현해서 사용하고 있습니다. 또한 Airflow는 AWS 관련 Provider를 제공해 주기에 저희는 &lt;code class=&quot;highlighter-rouge&quot;&gt;RedshiftSQLOperator&lt;/code&gt;를 사용하여 Redshift 조회 결과를 임시로 저장할 때 사용할 수 있었습니다.&lt;/p&gt;

&lt;h3 id=&quot;43-glue-data-catalog-활용&quot;&gt;4.3. Glue Data Catalog 활용&lt;/h3&gt;

&lt;p&gt;AWS Glue Data Catalog는 S3 데이터 레이크에 저장된 데이터들을 SQL 형태로 조회할 수 있도록 메타 스토어를 제공해 줍니다. 현재 S3에 저장되어 있는 프로토콜 별 경로에 맞춰 Glue Table을 생성하여 관리하고 있습니다.&lt;/p&gt;

&lt;p&gt;Redshift에서 S3의 반정형 데이터에 접근하기 위해서는 External Table이라는 개념이 필요합니다. 실질적으로 External Table은 Glue Data Catalog의 Table과 동일하기에 Redshift의 S3 조회를 위해서는 Glue의 Table이 꼭 필요합니다. 따라서 각 프로토콜 별로 Glue Table을 생성해서 관리해 줘야 하며 처음부터 스키마를 일일이 만들어주는 것보단 Glue Crawler를 활용하면 자동화된 추론을 통해 손쉽게 스키마를 생성할 수 있습니다. 물론 정확하지 않기에 한 번 생성 후 수동으로 스키마를 다시 조정해 주는 작업은 필요합니다.&lt;br /&gt;
생성된 Glue Table은 Redshift뿐만 아니라 Lambda에서 S3 원본 객체를 전처리할 때 스키마를 검증하는 용도로도 수용되고 있습니다.&lt;/p&gt;

&lt;p&gt;Glue Table은 AWS의 분석 환경에서 SoT(Source Of Truth)로 간주되며 이를 위해서는 스키마의 변경이 합의 없이 이뤄지면 안 됩니다. 따라서 Glue Crawler의 설정이나 외부 환경에서 Glue Table의 Schema 변경을 막는 방향으로 설정하는 것을 추천드립니다.&lt;/p&gt;

&lt;h3 id=&quot;44-lambda-함수의-주요-동작-및-구현&quot;&gt;4.4. Lambda 함수의 주요 동작 및 구현&lt;/h3&gt;

&lt;p&gt;FMS 프로젝트에서 Lambda 함수는 원본 S3에 적재된 객체(Json 포맷)를 메시지 프로토콜 별로 분류하고 Parquet로 포맷을 형 변환하여 저장하는 역할을 합니다. 지정된 S3 Bucket의 객체가 생성되는 Put Event가 발생할 때 Lambda 함수가 트리거 되어 동작합니다. S3 객체가 생성되는 주기와 Lambda의 이벤트 처리 비용을 고려했을 때 경제적으로 가장 저렴하다고 판단하였습니다.&lt;/p&gt;

&lt;p&gt;S3 Sink Connector에서는 Parquet로 적재를 지원해 주지만 Schema Registry가 필수적으로 필요하며, 원본 메시지도 Avro, Protobuf 같은 바이너리 포맷의 경우에만 지원을 합니다. 현재 차량 단말기에서 Json 포맷으로 메시지를 전송하고 있고 하나의 토픽에 여러 메시지 타입이 들어오는 경우 S3 Sink Connector에서 분류/형 변환 과정이 어렵습니다.&lt;/p&gt;

&lt;p&gt;Lambda 함수를 구성하는 주요 라이브러리로 &lt;code class=&quot;highlighter-rouge&quot;&gt;AWS Data Wrangler&lt;/code&gt;가 있습니다. AWS Data Wrangler는 Pandas를 기반으로 해서 AWS의 데이터 레이크 관련 서비스들을 연결하는 기능을 제공합니다. 대표적으로 AWS Glue, S3, Redshift, Athena 등을 쉽게 연결하여 사용할 수 있습니다. 특히 S3에서 Parquet 형식의 데이터 처리가 가능해서 형 변환을 손쉽게 할 수 있습니다 (더 자세한 내용은 &lt;a href=&quot;https://aws.amazon.com/ko/blogs/korea/using-aws-lake-formation-governed-table-with-aws-data-wrangler/&quot;&gt;여기&lt;/a&gt;를 참고해 주세요)&lt;/p&gt;

&lt;p&gt;Lambda 함수의 구현부는 아래와 같습니다. 크게 다음과 같은 순서로 함수가 동작합니다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;S3 Key에서 파티션 추출&lt;/li&gt;
  &lt;li&gt;파티션 요구사항에 맞게 새로운 파티션 생성&lt;/li&gt;
  &lt;li&gt;메시지 분류 작업&lt;/li&gt;
  &lt;li&gt;메시지 적재&lt;/li&gt;
&lt;/ol&gt;

&lt;details&gt;
&lt;summary&gt;Lambda 구현 코드&lt;/summary&gt;
&lt;div&gt;

    &lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;json&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;urllib.parse&lt;/span&gt;

&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;awswrangler&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;wr&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;s3_format.s3_parquet_parser&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;S3ParquetParser&lt;/span&gt;


&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;lambda_handler&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;event&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;parser&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;S3ParquetParser&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;bucket&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;event&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Records&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;s3&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;bucket&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;name&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;s3_key&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;urllib&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parse&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;unquote_plus&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;event&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Records&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;s3&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;object&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;key&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;encoding&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;utf-8&quot;&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# 1. s3 key를 통해 파티션 추출
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;partitions&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parser&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;extract_partitions_from_s3_key&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;s3_key&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s3_key&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;nb&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;topics//year=/month=/day=/hour=/&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# 파티션 삭제 및 추가 작업
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;partitions&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pop&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;topic&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;partitions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;&quot;ymd&quot;&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;{partitions.get('year', '1972')}-{partitions.get('month', '1')}-{partitions.get('day', '1')}&quot;&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# 2. 메시지 분류하기
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;fields&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;object&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;type&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;command&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;classified&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parser&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;classify_s3_json_into_field&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;s3_bucket&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bucket&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s3_key&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s3_key&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fields&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fields&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;partitions&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;partitions&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;


    &lt;span class=&quot;c1&quot;&gt;# 3. 메시지 타입 별 S3에 적재하기
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;target_bucket&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;glue_database&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;messages&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;classified&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;items&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;_object&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_type&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_command&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;split&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;#&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;glue_table&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;{_object}_{_type}_{_command}&quot;&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;

        &lt;span class=&quot;k&quot;&gt;try&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parser&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;save_to_s3_in_parquet_with_partitions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;messages&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;messages&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;partition_cols&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;
                    &lt;span class=&quot;s&quot;&gt;&quot;ymd&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;s&quot;&gt;&quot;hour&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                &lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;s3_bucket&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;target_bucket&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;s3_prefix&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;formatted/object={_object}/type={_type}/command={_command}&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;extra&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;extra_args&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Successful in loading  {result}&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;except&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;Exception&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;raise&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# wr.lakeformation.commit_transaction(transaction_id=transaction)
&lt;/span&gt;    &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

  &lt;/div&gt;
&lt;/details&gt;

&lt;p&gt;S3 Parquet 적재 관련 책임은 &lt;code class=&quot;highlighter-rouge&quot;&gt;S3ParquetParser&lt;/code&gt;라는 모듈이 담당하고 있습니다. &lt;code class=&quot;highlighter-rouge&quot;&gt;Lambda Layer&lt;/code&gt;로 배포되며 Lambda 함수에서 Import가 가능합니다. S3ParquetParser는 아래와 같이 구성됩니다.&lt;/p&gt;

&lt;details&gt;
&lt;summary&gt;S3ParquetParser 구현 코드&lt;/summary&gt;
&lt;div&gt;

    &lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;json&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;logging&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;collections&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;defaultdict&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;typing&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Any&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;List&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Optional&lt;/span&gt;

&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;awswrangler&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;wr&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;boto3&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pandas&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;ttp&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ttp&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;logging&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;getLogger&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;setLevel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;logging&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;INFO&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;


&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;S3ParquetParser&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;boto3_session&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;boto3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Session&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;boto3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Session&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;region_name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;ap-northeast-2&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;endpoint_url&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;extract_partitions_from_s3_key&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s3_key&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;parser&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ttp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s3_key&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;parser&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parse&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parser&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;raise&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;ValueError&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;해당 s3_key({s3_key})에 올바른 포맷({format})인지 확인해 주세요&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;classify_s3_json_into_field&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;s3_bucket&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;s3_key&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;fields&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;List&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;partitions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Optional&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Any&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;s3&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;session&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;client&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;s3&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;endpoint_url&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;endpoint_url&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;defaultdict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;response&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_object&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Bucket&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s3_bucket&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Key&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s3_key&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;messages&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;response&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Body&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;decode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;utf-8&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;splitlines&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;messages&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;field_concat_key&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;obj&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;save_to_s3_in_parquet_with_partitions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;messages&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;List&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;partition_cols&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;List&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;s3_bucket&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;s3_prefix&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;extra&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;dict&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{},&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DataFrame&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;from_records&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;messages&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;wr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to_parquet&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;s3://{s3_bucket}/{s3_prefix}&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;boto3_session&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;session&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;partition_cols&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;partition_cols&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;extra&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

  &lt;/div&gt;
&lt;/details&gt;

&lt;p&gt;메시지를 적재해 주는 &lt;code class=&quot;highlighter-rouge&quot;&gt;save_to_s3_in_parquet_with_partitions&lt;/code&gt;에서는 AWS Data Wrangler의 s3.to_parquet를 사용합니다. Pandas Dataframe을 s3에 Parquet 형태로 저장해 주는데 이 과정에서 Glue Table과 연동이 가능합니다. 이를 통해 적재할 메시지들의 스키마가 Glue Table의 스키마와 일치하는지를 검증할 수 있으며, 파티션을 Glue Table에 추가해 줄 수 있습니다(이를 통해 Glue Crawler를 사용하지 않아도 되는 이점이 있습니다)&lt;/p&gt;

&lt;p&gt;또한 메시지를 분류하기 위해서는 원본 Json 포맷을 Serialization 해야 합니다. 먼저 Pandas의 &lt;code class=&quot;highlighter-rouge&quot;&gt;read_json&lt;/code&gt;으로 Dataframe 화해서 메시지를 분류하려고 했지만 처리 시간 및 메모리 사용량이 높은 이슈가 있었습니다. 따라서 &lt;code class=&quot;highlighter-rouge&quot;&gt;str&lt;/code&gt; 객체의 &lt;code class=&quot;highlighter-rouge&quot;&gt;splitLines&lt;/code&gt;와 &lt;code class=&quot;highlighter-rouge&quot;&gt;json&lt;/code&gt; 모듈의 &lt;code class=&quot;highlighter-rouge&quot;&gt;loads&lt;/code&gt;로 Serialization을 대체하였고 이를 통해 메모리 할당량을 절반 이하로 낮추고 처리 속도를 2배 이상 개선하였습니다.&lt;/p&gt;

&lt;h3 id=&quot;45-lambda-모니터링-및-fallback-처리&quot;&gt;4.5. Lambda 모니터링 및 Fallback 처리&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/img/build-fms-data-pipeline/grafana-lambda.png&quot; alt=&quot;grafana-lambda&quot; /&gt;&lt;em&gt;Grafana Alert와 연동한 Slack 메시지&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;배치 처리 플랫폼의 모니터링은 마찬가지로 Grafana를 사용하고 있습니다. 현재는 주로 Lambda 함수에 대한 모니터링을 하고 있지만, Airflow의 데이터 신뢰성 검사 결과나 다른 리소스에 대한 지표들도 시각화할 계획을 하고 있습니다.&lt;/p&gt;

&lt;p&gt;Lambda 함수가 실패하는 경우 Redshift에서 누락된 데이터를 조회하게 됩니다. 정합성을 보장해 주기 위해선 재처리를 할 수 있도록 Fallback 처리가 중요합니다. 따라서 Lambda에서는 이벤트가 실패할 때 SQS로 이벤트 정보를 보내도록 설정하였으며 문제 원인 파악 후 다른 Lambda 함수에서 SQS의 메시지를 소비할 수 있도록 하였습니다.&lt;/p&gt;

&lt;h2 id=&quot;5-마무리&quot;&gt;5. 마무리&lt;/h2&gt;

&lt;p&gt;비즈니스 요구사항에 따라 데이터 파이프라인, 더 나아가 소프트웨어는 매번 변화합니다. FMS 프로젝트도 마찬가지로 IoT라는 도메인, 차량 비즈니스라는 특징과 제약 사항에 따라 위와 같이 PoC 데이터 파이프라인을 구축하였습니다. 현재는 비용 경제적 관점을 우선시하여 기술 스택을 결정하고 개발하였지만, 추후 서비스가 안정화되고 더 많은 사용자들이 사용하게 된다면 운영 관점에서 새로운 선택 및 고도화를 진행하게 될 것 같습니다.&lt;/p&gt;

&lt;p&gt;짧은 PoC 개발 기간에 다양한 팀들과 빠르게 커뮤니케이션하면서 일련의 데이터 파이프라인을 구축한 경험은 힘들었지만 정말 즐거웠습니다. 함께 파이프라인을 구축한 토마스, 루디, 피글렛과 차량 단말 파이프라인을 구축해 주신 라네 그리고 전체적인 AWS 인프라 환경을 구축해 주신 인프라팀 로원, 제이든에게 감사의 말을 전합니다.&lt;/p&gt;

&lt;p&gt;1부에서는 주로 데이터 파이프라인의 구성요소에 대해 소개 드렸다면 다음 2부에서 데이터 파이프라인의 안정성을 높이고 데이터의 신뢰성을 위한 시도들을 풀어보겠습니다.&lt;/p&gt;</content><author><name>그랩</name></author><category term="data" /><category term="data" /><category term="data engineering" /><category term="iot streaming" /><category term="data platform" /><category term="kafka connect" /><category term="aws" /><summary type="html">안녕하세요. 데이터 플랫폼 팀의 그랩입니다.</summary></entry><entry><title type="html">DBA의 AWS re:Invent 2022 참석 후기</title><link href="https://tech.socarcorp.kr/data/2023/01/16/aws-reinvent.html" rel="alternate" type="text/html" title="DBA의 AWS re:Invent 2022 참석 후기" /><published>2023-01-16T00:00:00+00:00</published><updated>2023-01-16T00:00:00+00:00</updated><id>https://tech.socarcorp.kr/data/2023/01/16/aws-reinvent</id><content type="html" xml:base="https://tech.socarcorp.kr/data/2023/01/16/aws-reinvent.html">&lt;p&gt;안녕하세요! 서비스 엔지니어링 본부 Cloud DB 팀의 알티입니다.&lt;/p&gt;

&lt;p&gt;Cloud DB 팀은 Data Architect(DA)의 역할과 Database Administrator(DBA) 역할을 수행합니다.
DA로서는 전사 데이터의 표준화와 데이터 거버넌스를 맡고 있으며, DBA로서는 쿼리 검수, 물리 데이터 모델링, 트러블 슈팅, 장애 대응, 신규 기술, 업무 자동화 등의 다양한 업무를 맡고 있습니다.&lt;/p&gt;

&lt;p&gt;AWS re:Invent는 글로벌 클라우드 시장에서 가장 큰 사업자인 AWS(Amazon Web Service)가 매년 신규 서비스와 그 활용 사례를 발표하는 행사입니다.
쏘카에서 DBA 업무를 수행할 때 AWS에서 제공하는 다양한 서비스를 사용하고 있는데, 좋은 기회로 이번 2022년 AWS re:Invent에 참석을 하여 다음 내용을 배울 수 있었습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;DB와 관련된 AWS 서비스의 Best Practice는 무엇인가?&lt;/li&gt;
  &lt;li&gt;각각의 서비스를 어떻게 유기적으로 연결하여 사용할 수 있는가?&lt;/li&gt;
  &lt;li&gt;글로벌 기업들은 대량의 트랜잭션을 다루기 위해 AWS 서비스를 어떻게 이용하였는가?&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이 글에서는 AWS re:Invent의 세션 중 DB와 관련된 세션들과 저의 후기를 소개해 보려고 합니다. 다음과 같은 분들이 읽어보시면 좋습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;AWS re:Invent 및 AWS의 신기능에 관심 있는 독자&lt;/li&gt;
  &lt;li&gt;데이터베이스 관리자(DBA)&lt;/li&gt;
  &lt;li&gt;데이터베이스에 관심이 있는 개발자&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;목차는 다음과 같습니다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;#1-aws-reinvent-2022-소개&quot;&gt;AWS Re:Invent 소개&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;#2-db와-관련된-세션-소개&quot;&gt;DB와 관련된 세션 소개&lt;/a&gt;&lt;/p&gt;

    &lt;p&gt;2.1. 목적에 맞는 데이터베이스&lt;/p&gt;

    &lt;p&gt;2.2 MemoryDB For Redis와 쿠버네틱스를 활용한 초고속 애플리케이션 구축&lt;/p&gt;

    &lt;p&gt;2.3. SQL에서 NoSQL로 점진적으로 마이그레이션&lt;/p&gt;

    &lt;p&gt;2.4. 데이터베이스의 블루/그린 최적화된 배포&lt;/p&gt;

    &lt;p&gt;2.5. 오픈소스(Trino)를 사용하여 AWS S3 데이터 조회&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#3-참석-후기&quot;&gt;참석 후기&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;1-aws-reinvent-2022-소개&quot;&gt;1. AWS re:Invent 2022 소개&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/img/aws-reinvent/aws-reinvent-intro.jpg&quot; alt=&quot;aws-reinvent-intro&quot; /&gt;&lt;em&gt;AWS re:Invent&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;AWS re:Invent는 아마존 웹 서비스(Amazon Web Service)가 개최하는 최대 규모의 행사이며, 매년 AWS의 신규 서비스와 기존 서비스의 새로운 기능을 발표하는 자리입니다. 
각 분야의 전문가 및 관계자들이 모여 Best Pratice를 발표하고 공유하며, AWS 외에도 다양한 솔루션 업체(GitLab, Redis, Docker, MariaDB 등등)의 서비스 소개를 들을 수 있는 컨퍼런스 입니다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;2-db와-관련된-세션-소개&quot;&gt;2. DB와 관련된 세션 소개&lt;/h2&gt;

&lt;p&gt;AWS re:Invent에서는 DB와 관련하여 글로벌 기업들의 아키텍처 구성,
데이터베이스와 결합한 서비스를 제공한 사례 등에 대한 다양한 세션이 있었습니다.
DB와 관련된 총 10개의 세션 중 인상 깊었던 5개의 세션들을 아래에 소개합니다.&lt;/p&gt;

&lt;h3 id=&quot;21-목적에-맞는-데이터베이스&quot;&gt;2.1. 목적에 맞는 데이터베이스&lt;/h3&gt;

&lt;p&gt;이 세션에서는 현대 MSA(Microservice Architecture) 환경에서 목적에 맞는 데이터베이스 선택(Purpoose-built database apporach)의 중요성과 실제 기업의 데이터베이스 컨설팅 사례를 살펴봅니다.&lt;/p&gt;

&lt;p&gt;MSA를 구성하는 각 서비스들은 확장성, 고가용성, 보안성, 성능 측면에서 각자 필요한 스펙이 다르기 때문에 그 목적에 맞는 데이터베이스를 선택하는 게 중요합니다. 
예를 들면 목적에 따라서 Relational / Key-value / Caching / Time-series 등 여러 형태의 Database Portfolio에서 적절한 DB를 선택하고 성능을 개선할 수 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/aws-reinvent/database-portfolio.png&quot; alt=&quot;AWS 가 제공하는 다양한 Database&quot; /&gt;&lt;em&gt;AWS 가 제공하는 다양한 Database&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;구체적인 사례로는 Twilio라는 기업이 Postflight에서 Amazon DynamoDB로 이관하여 Data Delay 와 비용을 줄인 케이스와, ADP가 Amazon Neptune 을 사용하여 성능을 10배 이상 개선한 케이스 등을 살펴보았습니다.&lt;/p&gt;

&lt;p&gt;개인적으로는 데이터도 사람처럼 성격과 성향이 있다고 생각합니다. 특히 데이터 모델링 시 이러한 데이터의 특성을 고려하여 알맞은 데이터베이스를 사용하는 것이 필수적입니다. 
추후에 데이터가 방대하게 쌓이고 난 후에는 간단한 작업이 큰 작업이 되거나 성능에 큰 영향을 미칠 수도 있기 때문입니다. 구체적으로는 단순 조회 작업에 오랜 시간이 소요되거나 CPU 부하가 발생할 수도 있습니다.&lt;/p&gt;

&lt;p&gt;목적에 맞는 데이터베이스 선택의 예는 다음이 있습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;실시간 위치를 조회하는 데이터의 경우 지속적으로 RDBMS에 UPDATE 작업을 진행해야 하는데, 이 경우 RDBMS에 대량의 데이터를 적재하기보다는 DynamoDB를 활용하는 것이 좋을 수 있습니다.&lt;/li&gt;
  &lt;li&gt;실시간 데이터가 필요하다면 Redis를 활용하고 데이터 손실을 줄이기 위해서는 MemoryDB for Redis를 사용할 수 있습니다.&lt;/li&gt;
  &lt;li&gt;추가로 데이터 손실을 감수하더라도 조금 더 빠른 조회를 원한다면 Memcached를 이용하면 안정적인 서비스를 제공할 수 있습니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이 세션을 통해 다시금  “목적에 맞는 데이터베이스 선택”의 중요성을 깨닫고, 개발자와 모델링 협업 과정에서 해당 부분에 대해 어떻게 잘 커뮤니케이션할 수 있을지에 대해 고민해 볼 수 있었습니다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;슬라이드 출처 : &lt;a href=&quot;https://d1.awsstatic.com/events/Summits/reinvent2022/DAT212_How-ADP-and-Twilio-realize-business-vision-with-purpose-built-databases-.pdf&quot;&gt;How-ADP-and-Twilio-realize-business-vision-with-purpose-built-databases&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;22-memorydb-for-redis와-쿠버네틱스를-활용한-초고속-애플리케이션-구축&quot;&gt;2.2 MemoryDB for Redis와 쿠버네틱스를 활용한 초고속 애플리케이션 구축&lt;/h3&gt;

&lt;p&gt;해당 세션에서는 Kubernetes와 MemoryDB for Redis 결합을 통한 애플리케이션 구축의 Best Pratice를 소개했습니다.
세션 마지막에는 소개한 구성을 실제로 구현하는 데모도 진행되었는데, 실습 내용을 포함한 전체 발표 자료는 &lt;a href=&quot;https://d1.awsstatic.com/events/Summits/reinvent2022/DAT313-R_Build-stateful-K8s-applications-with-ultra-fast-Amazon-MemoryDB-for-Redis.pdf&quot;&gt;링크&lt;/a&gt;에서 보실 수 있습니다.&lt;/p&gt;

&lt;p&gt;구체적으로는 AWS EKS를 통해 Kubernetes 환경에서 MicroService Architecture(MSA) application 을 구성하는 방법과, MSA에 Memory DB for Redis가 적합한 이유를 소개하였습니다.&lt;/p&gt;

&lt;p&gt;전체적인 구성은 아래와 같습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/aws-reinvent/ack.png&quot; alt=&quot;ACK&quot; /&gt;&lt;em&gt;ACK(AWS Controllers for Kubernetes)를 활용한 전체적인 아키텍처&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;세션 초반부에는 MSA의 정의와 Managed Service 로서의 AWS EKS의 장점, AWS Controller for Kuberenetes를 통해 리소스를 관리하는 방법들을 설명합니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/aws-reinvent/memorydb.png&quot; alt=&quot;memorydb-durability&quot; /&gt;&lt;em&gt;Memory DB For Redis 스토리지는 WRITE 작업 시 Log를 남겨 데이터 유실을 방지합니다.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;해당 세션을 들으면서 빠른 응답속도를 보장하기 위해 쿠버네틱스와 함께 데이터의 손실을 방지하고자 Memory DB for Redis를 사용하는 이유를 알아볼 수 있었습니다.
MemoryDB for Redis는 Aurora와 동일한 스토리지 구성을 가지고 있는데 이것은 데이터 안정성 면에서 큰 장점입니다.
Memory 기반의 데이터베이스인 Redis는 빠른 Return을 보장하지만 데이터에 대한 내구성이 떨어질 수 있는데
관계형 데이터베이스와 동일한 스토리지 구성을 가지면 데이터의 손실이 발생하지 않도록 보장됩니다.&lt;/p&gt;

&lt;p&gt;해당 세션에서는 DB뿐만 아니라 전반적인 인프라 지식도 얻을 수 있었니다. 
쏘카의 DB 팀은 각종 데이터베이스 구성과 네트워크 설정 작업 시 인프라팀과 긴밀하게 협업을 하고 있는데, 
이런 업무 시 인프라팀과 커뮤니케이션에 도움이 되는 세션이었습니다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;슬라이드 출처 : &lt;a href=&quot;https://d1.awsstatic.com/events/Summits/reinvent2022/DAT313-R_Build-stateful-K8s-applications-with-ultra-fast-Amazon-MemoryDB-for-Redis.pdf&quot;&gt;Build-stateful-K8s-applications-with-ultra-fast-Amazon-MemoryDB-for-Redis&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;23-sql에서-nosql로-점진적으로-마이그레이션&quot;&gt;2.3. SQL에서 NoSQL로 점진적으로 마이그레이션&lt;/h3&gt;

&lt;p&gt;이 세션은 관계형 데이터베이스에 적재된 데이터를 In-Memory 기반의 데이터베이스에 데이터를 이관하는 방법을 소개합니다.&lt;/p&gt;

&lt;p&gt;이기종 간의 데이터베이스 동기화 및 이관작업은 상대적으로 동일한 데이터베이스로 이관하는 것보다 버전, 호환성 측면에서 신경쓸 부분이 많습니다.
사용되는 모든 쿼리의 결과를 메모리형 데이터베이스에 적재하면서 동시에 운영 중인 데이터를 동기화해야 하기 때문입니다.&lt;/p&gt;

&lt;h4 id=&quot;마이그레이션-패턴-순서rdbms--nosql&quot;&gt;마이그레이션 패턴 순서(RDBMS → NoSQL)&lt;/h4&gt;

&lt;p&gt;운영중인 데이터베이스를 중단하지 않고 (다운타임을 발생시키지 않고) NoSQL로 이관하기 위해서는 RDBMS에서 NoSQL로 마이그레이션을 위해서는 아래와 같은 순서로 작업이 진행됩니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/aws-reinvent/mechanisms.png&quot; alt=&quot;Migration Mechanism&quot; /&gt;&lt;em&gt;마이그레이션 시 Cold Data 와 Hot Data를 나눠 작업합니다.&lt;/em&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Lift and Shifts 방식으로 OS, 데이터, 애플리케이션을 그대로 옮기는 작업을 진행&lt;/li&gt;
  &lt;li&gt;요구사항에 맞는 구성으로 설계 (Ex. On-promise 환경 → Cloud 환경)&lt;/li&gt;
  &lt;li&gt;RDBMS의 쿼리 결과를 Key-value로 변환&lt;/li&gt;
  &lt;li&gt;Cold / Hot Data의 적재 및 조회 방안 구성&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Data는 사용 빈도에 따라 크게 Cold Data와 Hot Data로 분류됩니다. 
Cold Data란 자주 사용되지 않는 데이터를 지칭하며, 
Hot Data는 자주 사용되며 즉시 액세스해야 하는 데이터 (SELECT/UPDATE/DELETE 작업이 발생하는 데이터)를 지칭합니다.&lt;br /&gt;
마이그레이션 시 이런 데이터의 특성을 이해하고 각 특성에 맞게 마이그레이션 방안을 구성하는 것이 매우 중요합니다.&lt;/p&gt;

&lt;h3 id=&quot;cold-data-migration&quot;&gt;Cold Data Migration&lt;/h3&gt;

&lt;p&gt;Cold Data의 경우 Access 요청이 발생하지 않기 때문에 이관작업의 Key-value 변환 외에는 크게 복잡하지 않습니다.
다만, 트랜잭션이 많이 발생하는 시간대를 피해서 Cold Data의 이관작업을 진행해야합니다.&lt;/p&gt;

&lt;h3 id=&quot;hot-data-migration&quot;&gt;Hot Data Migration&lt;/h3&gt;

&lt;p&gt;Hot Data의 경우 실시간으로 변경이 일어나기 때문에 Cold Data 보다 작업이 복잡합니다.
운영 중인 데이터베이스에서 어떤 데이터 요청이 발생하는지 정확히 파악하기에는 한계가 존재하기 때문에 READ / WRITE / 변경 요청의 분류에 따라서
아래 Mechanism 을 따라 마이그레이션을 진행합니다.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Mechanism&lt;/th&gt;
      &lt;th&gt;설명&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Read 요청&lt;/td&gt;
      &lt;td&gt;- NoSQL 데이터베이스에 READ Request 요청 &lt;br /&gt; - NoSQL에서 데이터가 없어 Return을 못하는 경우, RDBMS에 READ Request 요청  &lt;br /&gt; - RDBMS Return 과 함께 해당 데이터를 NoSQL로 Write 작업 진행&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Write 요청&lt;/td&gt;
      &lt;td&gt;- NoSQL 데이터베이스로 Write 요청 &lt;br /&gt; - RDBMS에 해당 Write 작업 결과가 존재하는지 확인 &lt;br /&gt; - NoSQL에 데이터가 적재되지 않았다면, RDBMS → NoSQL로 데이터 적재&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;변경 요청&lt;/td&gt;
      &lt;td&gt;- RDBMS와 변경 건에 대한 DMS(Data Migration Service)를 이용하여 진행 &lt;br /&gt;- 실시간 데이터 스트림 서비스인 Kinesis로 DMS로 연결 &lt;br /&gt; - Lambda를 이용하여 변경 건에 대한 Trigger 진행&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;해당 세션에서는 실제 마이그레이션 작업에 못지않게 작업 대상에 대한 데이터의 전수조사가 중요하다는 것을 배웠습니다. 
실제로 데이터가 어떻게 요청되고 있는지를 알아야 정확한 마이그레이션을 정확하게 진행할 수 있었습니다.&lt;/p&gt;

&lt;p&gt;또한 일반적으로 마이그레이션은 &lt;code class=&quot;highlighter-rouge&quot;&gt;Mysqldump&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;Orcale datapump&lt;/code&gt; 등 마이그레이션 툴을 이용하여 작업을 진행하는데,
해당 세션에서는 Python Script를 이용하여 운영 중 요청이 들어오는 쿼리를 확인하고 그 결과를 NoSQL으로 적재하는 방법을 소개했습니다. 
결과적으로 좀 더 섬세하고 복잡한 마이그레이션을 안정적으로 진행하는 법을 배울 수 있었던 의미 있는 세션이었습니다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;슬라이드 출처 : &lt;a href=&quot;https://d1.awsstatic.com/events/Summits/reinvent2022/BOA321_Modernize-and-gradually-migrate-your-data-model-from-SQL-to-NoSQL.pdf&quot;&gt;Modernize-and-gradually-migrate-your-data-model-from-SQL-to-NoSQL&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;24-데이터베이스의-블루그린-최적화된-배포&quot;&gt;2.4. 데이터베이스의 블루/그린 최적화된 배포&lt;/h3&gt;

&lt;p&gt;Blue/Green Optimized 세션은 Aurora의 버전 업그레이드와 관련하여 AWS 발표한 새로운 기능에 대해 소개하는 세션입니다.
데이터베이스의 버전 업그레이드와 그 과정에서 발생하는 다운타임을 고려하는 것은 DBA 입장에서 매우 중요한 부분이라 개인적으로도 가장 듣고 싶었던 세션이었습니다.&lt;/p&gt;

&lt;p&gt;이 세션에서는 기존의 방식보다 안전하게 최대 1분 이내로 업그레이드 작업을 진행할 수 있다고 발표하였습니다.&lt;/p&gt;

&lt;p&gt;Blue/Green Deployment는 보통 서버에서 자주 이용되는 무중단 배포 기법 중 하나이며, 구 버전과 새 버전을 동시에 운영 환경에 띄워놓고 구 버전에서 새 버전으로 트래픽을 서서히 이동시키는 방법입니다.
DB의 Blue/Green Deployment는 다음 순서로 진행됩니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/aws-reinvent/blue-green.png&quot; alt=&quot;Blue-green&quot; /&gt;&lt;em&gt;Blue-Green Deployment&lt;/em&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Blue → Green 간의 Logical Replication
    &lt;ul&gt;
      &lt;li&gt;Blue에서 발생하는 모든 변경 사항을 Green에서 미러링하도록 설정&lt;/li&gt;
      &lt;li&gt;변경 복제를 이용한 여러 수준의 Replication 지원(One-Level 복제)&lt;/li&gt;
      &lt;li&gt;메트릭을 모니터링하여 Replication이 최신 상태인지 확인&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;RDS 인스턴스 버전 업그레이드 완료 및 데이터 검증&lt;/li&gt;
  &lt;li&gt;Blue(업그레이드 이전) 인스턴스 삭제&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;해당 세션을 듣고 정말 1분 이내에 업그레이드 Switch Over를 완료할 수 있을지에 대해 의문이 들었습니다.
개발 계정에서 신규 Aurora MySQL RDS Instance를 생성하여 Blue/Green Deployment 테스트를 진행했습니다.&lt;/p&gt;

&lt;h4 id=&quot;테스트-진행-절차&quot;&gt;테스트 진행 절차&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;테스트 세팅&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;신규 RDS Instance 생성(Aurora MySQL 5.7)&lt;/li&gt;
  &lt;li&gt;더미 데이터 Import 수행 (5GB 데이터 적재)&lt;/li&gt;
  &lt;li&gt;Blue/Green 설정
    &lt;ul&gt;
      &lt;li&gt;Blue - Aurora MySQL 5.7&lt;/li&gt;
      &lt;li&gt;Green - Aurora MySQL. 8.0&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/img/aws-reinvent/test-blue-green.png&quot; alt=&quot;Blue-green-test&quot; /&gt;&lt;em&gt;Blue-Green Deployment Test&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;테스트 과정&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Blue/Green 커넥션 확인
    &lt;ul&gt;
      &lt;li&gt;작업 중 New Connection 연결 시 Connection Error 미발생&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;db.t3.medium&lt;/code&gt; 기준 약 21분 소요&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Logical Replication 확인
    &lt;ul&gt;
      &lt;li&gt;Blue의 데이터 변경 작업(DML/DDL) 진행 시 Green에도 정상적으로 반영 확인&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Switch Over를 이용하여 Green → Blue 배포 진행
    &lt;ul&gt;
      &lt;li&gt;읽기 작업은 Blue(운영) 쪽에서 진행 가능&lt;/li&gt;
      &lt;li&gt;내부적으로 Bin Log를 기준으로 미러링 확인&lt;/li&gt;
      &lt;li&gt;Major/Minor 버전 업그레이드 포함&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이때 Switch Over 시 Timeout Setting 을 1분으로 설정했을 때, 실제 배포 과정이 1분이 초과되어 자동으로 Rollback이 되었습니다. 
Timeout Setting을 3분으로 늘려 재실행 했을 때는 정상적으로 Blue/Green Deployment이 완료되었습니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Switch Over 결과&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/aws-reinvent/test-result.png&quot; alt=&quot;Blue-green-test-result&quot; /&gt;&lt;em&gt;Blue/Green Deployment 완료 후 위와 같이 분리&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;실제 작업은 위와 같은 방법으로 작업이 수행되며 &lt;code class=&quot;highlighter-rouge&quot;&gt;db.t3.medium&lt;/code&gt; 기준으로 약 $91의 비용이 소요됩니다.&lt;/p&gt;

&lt;p&gt;세션에서 들었던 것과 달리 Timeout을 1분으로 설정했을 때 Switchover 작업이 실패하였는데 정확한 원인은 파악하지 못하였습니다. 혹시 1분 기준으로 테스트를 성공하신 분이 있다면 댓글 부탁드립니다.&lt;/p&gt;

&lt;p&gt;세션에서 소개된 내용은 빠르고 안정적이나 추가로 인스턴스가 생성되기 때문에 추가 비용이 발생할 우려가 있습니다.
또한 새로운 기능을 운영에 적용하기에는 보수적으로 생각해야 하기에 실제 적용에는 여러 고민이 되는 점이 있었습니다.
하지만 이러한 새로운 기능을 접할 수 있어 좋았으며 AWS의 RDS가 점점 발전하고 있다는 것을 느꼈습니다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;슬라이드 출처 : &lt;a href=&quot;https://d1.awsstatic.com/events/Summits/reinvent2022/DAT222_Amazon-RDS-Blue-Green-Deployments-Optimized-Writes-and-Optimized-Reads.pdf&quot;&gt;Amazon-RDS-Blue-Green-Deployments-Optimized-Writes-and-Optimized-Reads&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;25-오픈소스trino를-사용하여-aws-s3-데이터-조회&quot;&gt;2.5. 오픈소스(Trino)를 사용하여 AWS S3 데이터 조회&lt;/h3&gt;

&lt;p&gt;해당 세션은 Open-source인 Trino를 이용한 S3 데이터 접근 방법에 관련된 세션입니다.
S3의 데이터를 조회하기 위해서는 기존에는 AWS가 제공하는 서비스인 Athena를 이용하여 데이터를 조회하여 쿼리 결과를 얻을 수 있습니다.&lt;/p&gt;

&lt;p&gt;다만, Athena를 이용하여 쿼리 결과를 얻기 위해서는 서울 리전을 기준으로 1TB 당 $5의 비용이 발생합니다. 
하지만 이번 세션에서는 Trino를 이용하여 Athena의 조회 비용을 제거하고 쿼리 성능을 개선하는 방법을 소개하고 있습니다.
단, EMR(Elastic MapReduce)의 Computing 비용을 지불합니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/aws-reinvent/trino.png&quot; alt=&quot;trino&quot; /&gt;&lt;em&gt;Trino와 AWS S3 Select&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;이러한 속도를 낼 수 있는 것은 Pushdown이라는 기능 때문입니다.
그 이유는 MySQL에서도 비슷한 기능이 존재하며 Index Condition Pushdown 과 유사하기 때문입니다.
스토리지에 Index를 밀어 넣어 필요한 데이터만을 그대로 가지고 메모리에 올려놓고 결과를 반환하는 과정과 유사합니다.&lt;/p&gt;

&lt;p&gt;마찬가지로 S3 Select는 지정된 바이트 수만큼 CSV 파일에서 Range Scan(범위)을 전체 객체 스캐닝을 병렬로 처리하여 속도가 빠릅니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/aws-reinvent/trino-result.png&quot; alt=&quot;trino-result&quot; /&gt;&lt;em&gt;AWS S3 Select를 사용했을 때의 조희 성능 차이&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;위 그림은 S3 내 CSV 파일 데이터를 조회하는 속도를 보여 줄 수 있는 성능 그래프입니다. 
S3 내 압축되어 있지 않은 3TB의 CSV 데이터를 조회할 때 S3 Select를 이용했을 때와 아닐 때의 RunTime 차이를 알 수 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/aws-reinvent/data-lake-architecture.png&quot; alt=&quot;data-lake-architecture&quot; /&gt;&lt;em&gt;데이터 레이크 구조&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;위 그림은 데이터 레이크 아키텍처를 소개한 것으로, 
Amazon EMR(Elastic MapReduce)에 Trino를 설치하여 S3를 연동하여 쿼리를 실행할 수 있는 SQL 쿼리 엔진을 보여줍니다.&lt;/p&gt;

&lt;p&gt;일반적으로 데이터베이스에서 더 이상 사용되지 않는 정적 데이터는 S3로 이관하는 것을 지향합니다.
불필요한 데이터는 테이블을 무겁게 하고 성능에도 영향을 미치며, 대량의 테이블에서는 ALTER 작업에도 CPU 부하를 유발할 수 있기 때문입니다.&lt;/p&gt;

&lt;p&gt;테이블의 경량화를 위해 S3로 이관하고 사용 빈도가 적은 데이터를 빠르게 조회할 수 있는 방법에 대해 알아볼 수 있었던 세션이었습니다.
또한 쏘카에서는 S3에 적재된 데이터를 Athena를 이용하여 조회를 하고 있는데, Athena 외에도 대체 방안을 알 수 있어서 좋았습니다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;슬라이드 출처 : &lt;a href=&quot;https://d1.awsstatic.com/events/Summits/reinvent2022/OPN209-R_Accessing-data-lakes-in-Amazon-S3-using-open-source-projects.pdf&quot;&gt;Accessing-data-lakes-in-Amazon-S3-using-open-source-projects.&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;3-참석-후기&quot;&gt;3. 참석 후기&lt;/h2&gt;

&lt;p&gt;업무에 AWS 툴을 다양하게 활용하고 있는 입장에서 AWS re:Invent를 통해 AWS에서 직접 진행하는 발표와 데모를 들어볼 수 있어 좋았습니다. 
특히 관심 있는 DB 툴에 대해 Deep Dive 하고 Insight를 가져볼 수 있는 값진 시간이었습니다.&lt;/p&gt;

&lt;p&gt;세션 뿐만 아니라 수백개의 파트너 사가 AWS와 관련된 솔루션을 홍보하는 자리기도 해서, 
re:Invent 행사가 단순히 콘퍼런스의 개념만 가지고 있는 것이 아니라 클라우드 기술을 통합하는 장소라는 것을 느꼈습니다.&lt;/p&gt;

&lt;p&gt;마지막으로 AWS re:Invent를 참석할 수 있는 기회를 주신 본부장님 아나킨과 그룹장님 제이든, 인프라 팀장님 로원께 감사드리며, 값진 시간을 보낼 수 있도록 도움을 주신 서비스 엔지니어링 본부 및 오퍼레이션 그룹 구성원분께 감사 인사를 드립니다. 긴 글 읽어주셔서 감사합니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/aws-reinvent/aws-reinvent-outro.jpg&quot; alt=&quot;aws-reinvent-outro&quot; /&gt;&lt;/p&gt;</content><author><name>알티</name></author><category term="data" /><category term="aws" /><category term="dba" /><category term="database" /><summary type="html">안녕하세요! 서비스 엔지니어링 본부 Cloud DB 팀의 알티입니다.</summary></entry><entry><title type="html">전사 구성원들이 사용하는 배치 데이터 플랫폼 만들기 - Airflow Advanced</title><link href="https://tech.socarcorp.kr/data/2022/11/09/advanced-airflow-for-databiz.html" rel="alternate" type="text/html" title="전사 구성원들이 사용하는 배치 데이터 플랫폼 만들기 - Airflow Advanced" /><published>2022-11-09T01:00:00+00:00</published><updated>2022-11-09T01:00:00+00:00</updated><id>https://tech.socarcorp.kr/data/2022/11/09/advanced-airflow-for-databiz</id><content type="html" xml:base="https://tech.socarcorp.kr/data/2022/11/09/advanced-airflow-for-databiz.html">&lt;p&gt;안녕하세요. 데이터 플랫폼 팀의 그랩입니다.&lt;/p&gt;

&lt;p&gt;데이터 플랫폼팀은 &lt;strong&gt;“쏘카 내부의 데이터 이용자가 비즈니스에 임팩트를 낼 수 있도록 소프트웨어 엔지니어링에 기반하여 문제를 해결합니다”&lt;/strong&gt;라는 미션을 기반으로 인프라, 데이터 파이프라인 개발, 운영, 모니터링, 데이터 애플리케이션 개발, MLOps 등의 업무를 맡고 있습니다. 팀 구성원들은 모두가 소프트웨어 엔지니어라는 사명감을 가지고 개발뿐만 아니라 Ops에 대한 이해와 책임감을 가지고 업무에 임하고 있습니다.&lt;/p&gt;

&lt;p&gt;본 글에서는 데이터 플랫폼 팀에서 운영하는 Airflow에 대해 소개하려고 합니다. 
데이터 엔지니어 위주로 사용하던 초기와 달리 현재는 데이터 비즈니스 본부 구성원 모두가 Airflow를 활용하여 직접 파이프라인을 구축할 수 있습니다. 
이런 변화에 따른 문제들과 어떻게 해결하였는지 풀어보도록 하겠습니다.&lt;/p&gt;

&lt;p&gt;다음과 같은 분들이 읽으면 좋습니다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;운영하고 있는 Airflow를 고도화하고 싶은 소프트웨어 엔지니어&lt;/li&gt;
  &lt;li&gt;Kubernetes 환경에서 Airflow를 운영하고 있는 소프트웨어 엔지니어&lt;/li&gt;
  &lt;li&gt;사용자가 다양한 Airflow의 개발 환경을 개선하고 싶은 소프트웨어 엔지니어&lt;/li&gt;
  &lt;li&gt;데이터 플랫폼에 관심이 있는 소프트웨어 엔지니어&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;목차는 아래와 같습니다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;#1-쏘카의-airflow-현황과-문제점&quot;&gt;쏘카의 Airflow 현황과 문제점&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#2-개발-환경-개선-및-개발-주기-단축하기&quot;&gt;개발 환경 개선 및 개발 주기 단축하기&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#3-지속적으로-airflow-안정화하기&quot;&gt;지속적으로 Airflow 안정화하기&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#4-보안-강화하기&quot;&gt;보안 강화하기&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#5-모니터링-고도화하기&quot;&gt;모니터링 고도화하기&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#6-되돌아보기&quot;&gt;되돌아보기&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;blockquote&gt;
  &lt;p&gt;Airflow에 대한 히스토리가 길고 다루는 내용들이 많다 보니 모든 과정을 상세하게 적지는 못했습니다. 댓글로 질문 편하게 남겨주시면 답변드리겠습니다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;1-쏘카의-airflow-현황과-문제점&quot;&gt;1. 쏘카의 Airflow 현황과 문제점&lt;/h2&gt;

&lt;p&gt;데이터 파이프라인을 구축할 때 꼭 빠지지 않는 구성요소가 있습니다. 바로 &lt;code class=&quot;highlighter-rouge&quot;&gt;Airflow&lt;/code&gt;입니다. Airflow는 Airbnb에서 개발한 워크플로우 관리 오픈소스로 현재 많은 기업에서 데이터 파이프라인을 자동화할 때 사용하는 툴입니다.&lt;/p&gt;

&lt;h3 id=&quot;11-airflow-in-socar&quot;&gt;1.1. Airflow in Socar&lt;/h3&gt;

&lt;p&gt;쏘카에서는 데이터 분석가, 데이터 사이언티스트, AI 엔지니어 등 다양한 사용자들이 Airflow DAG을 통하여 파이프라인을 직접 구축할 수 있습니다. 
대신 다양한 사용자가 Airflow를 불편함 없이 이용하기 위해서 관리자가 Airflow의 사용 범주와 개발 방식을 잘 정의하는 것이 중요합니다.&lt;/p&gt;

&lt;p&gt;쏘카에서는 데이터 통합 저장소(데이터 레이크, 웨어하우스)로 &lt;code class=&quot;highlighter-rouge&quot;&gt;BigQuery&lt;/code&gt;를 사용하고 있습니다.
기본적으로 외부 데이터 소스(Open API, RDBMS, S3 등)와 BigQuery 원본 데이터 셋을 BigQuery로 가공/적재하는 작업에 Airflow를 사용할 것을 권장하고 있습니다.
또한 DAG는 Data Lake, Data Mart, Monitoring, Crawling 등 각 용도에 맞게 분류하여 관리되고 있습니다. 
(단순 스케줄링을 필요로 하는 작업은 Airflow의 사용을 지양하고 K8s(Kubernetes) Cronjob이나 Github Action 등을 활용하는 것을 권장하고 있습니다)&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/advanced-airflow-for-databiz/airflow-k8s-workflow.png&quot; alt=&quot;airflow-k8s-workflow.png&quot; /&gt;&lt;em&gt;Airflow on Kubernetes Workflow&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;쏘카의 데이터 플랫폼/애플리케이션들은 대부분 GKE(Google Kubernetes Engine) 환경에서 동작하고 있습니다. 개발 편의성을 위해서 운영/개발 환경 별로 클러스터를 분리하여 사용하고 있으며, Airflow도 운영 환경과 개발 환경이 분리되어 있습니다. 
Airflow Github Repository의 Branch 이름이 특정 조건을 만족하면 CI/CD 파이프라인을 거쳐서 개발 클러스터에 Branch 별로 Airflow 서비스가 독립적으로 생성됩니다.&lt;/p&gt;

&lt;p&gt;과거 Airflow 사용자는 DAG을 생성/변경하기 위해서 기본적으로 &lt;code class=&quot;highlighter-rouge&quot;&gt;feature&lt;/code&gt; Branch를 생성하여 변경 커밋을 원격 Branch에 푸시 하였습니다. 그러면 Git Sync를 통해 Airflow에 DAG이 동기화되어 테스트가 가능했습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/advanced-airflow-for-databiz/airflow-dev-env-as-is.png&quot; alt=&quot;airflow-dev-env-as-is.png&quot; /&gt;&lt;em&gt;Airflow 기존 개발 환경&lt;/em&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;쏘카의 Airflow On K8s 운영에 대해 더 궁금하시다면 &lt;a href=&quot;https://tech.socarcorp.kr/data/2021/06/01/data-engineering-with-airflow.html&quot;&gt;쏘카 데이터 그룹 - Airflow와 함께한 데이터 환경 구축기&lt;/a&gt;를 읽어보세요.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;12-문제점&quot;&gt;1.2. 문제점&lt;/h3&gt;

&lt;p&gt;사용자가 독립된 Airflow 개발 환경을 쓸 수 있는 것은 큰 장점입니다. 운영과 분리된 환경에서 테스트가 가능하였으며 Github을 SoT(Source of Truth)로 삼아 코드 퀄리티 관리가 용이하였습니다.
하지만 기존 방식의 Airflow는 아래와 같은 문제점들이 있었습니다.&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;개발 환경의 Airflow의 에러 발생 및 관리자/컴퓨팅 리소스 낭비&lt;/li&gt;
  &lt;li&gt;많은 사용자들이 사용하기엔 불친절한 개발 환경, 긴 피드백 루프&lt;/li&gt;
  &lt;li&gt;Airflow 1 버전의 고질적인 문제들&lt;/li&gt;
  &lt;li&gt;코드 보안에 취약하고, 사용자 개인에 대한 권한 체계 부족&lt;/li&gt;
  &lt;li&gt;체계적이지 않은 오류 대응 프로세스 및 모니터링 환경&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;문제점 1 - 개발 환경의 Airflow의 에러 발생 및 관리자/컴퓨팅 리소스 낭비&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;개발 환경의 Airflow는 Github Branch를 기반으로 생애 주기가 결정됩니다. 따라서 사용자가 작업을 완료하고 Branch를 삭제하면 개발 환경의 Airflow는 함께 내려가게 됩니다. 그러나 사용자는 Branch를 만들고 작업하다가 중간에 다른 작업을 하는 경우들이 많았고, 이에 Airflow는 계속 유휴 상태로 남아있어 K8s Node의 자원을 차지하였습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/advanced-airflow-for-databiz/argocd-many-airflows.png&quot; alt=&quot;argocd-many-airflows.png&quot; /&gt;&lt;em&gt;다수의 사용자가 개발 환경에서 만든 Airflow가 남아있는 모습&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;더불어 당시 Airflow를 K8s에 배포하기 위해 사용한 Helm Chart(Community 버전)도 간헐적으로 원인 모를 에러가 발생하였습니다. 
이에 따라 관리자는 Airflow 에러를 수정하고 사용자와 커뮤니케이션 하는 과정에서 피로도가 높았습니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;문제점 2 - 많은 사용자들이 사용하기엔 불친절한 개발 환경, 긴 피드백 루프&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;개발 환경의 Airflow는 Git Sync를 통해 Github Repository의 코드를 동기화합니다. 
사용자가 DAG의 변경 사항을 개발 클러스터에 반영하기 위해 매번 Commit를 해야 하는 것도 불편했으며
운영하는 DAG의 개수들이 많다 보니 Push 때마다 동기화 시간이 1분 이상 걸리기도 했습니다. 
이런 상황에서 사용자가 코드를 작성하면서 계속해서 동작 확인을 하기 위해선 Commit당 매번 1분 이상 기다려야 했습니다. 이는 피드백 루프와 개발 시간이 길어진다는 것을 의미합니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/advanced-airflow-for-databiz/git-sync-many-commits.png&quot; alt=&quot;git-sync-many-commits.png&quot; /&gt;&lt;em&gt;Airflow 커밋 히스토리가 불필요하게 길어지기도 합니다.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;또한 개인 노트북 환경에서 코드를 작성하기 위해선 Airflow 관련 구성 의존성들을 설치해야 하고 기본 개발 환경을 설정해야 합니다. 하지만 이에 관한 가이드 문서들이 부족하였으며 일부 Mac OS 버전에서는 의존성이 제대로 설치되지 않는 문제들도 있었습니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;문제점 3 - Airflow 1 버전의 고질적인 문제들&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;기존 1 버전 대 Airflow는 DAG 개수가 늘어나면 DAG Parsing 시간이 오래 걸리는 치명적인 문제가 있었습니다. 그때 당시 쏘카에서 운영하는 DAG은 수백 개였고 점점 DAG이 늘어날 때마다 Task Instance들의 스케줄링이 점점 밀리게 되었습니다.
그리고 DAG Parsing 프로세스가 백그라운드에서 동작하고 있다 보니 웹에 접근했을 때 속도가 느렸습니다.
그때 당시 K8s Node의 자원을 스케일 업해봤지만 크게 개선되는 부분은 없었고 단순 스케일 업보다는 조금 더 근본적인 해결책이 필요했습니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;문제점 4 - 코드 보안에 취약하고, 사용자 개인에 대한 권한 체계 부족&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;다수의 사용자들이 Airflow를 사용하면서 Api Key나 Secret 정보들을 그대로 하드코딩하는 경우들이 있었습니다. 
특히 Airflow 사용 목적 상 외부 데이터 소스/저장소와 통신해야 하는 경우들이 많아 위 문제들이 빈번하게 발생했습니다.&lt;/p&gt;

&lt;p&gt;또한 팀 별로 공용 계정을 사용했기 때문에 간혹 Connection, Variable이 지워지거나 실행되던 Task가 갑자기 종료되는 문제들이 발생했었으며, 정확한 히스토리 추적이 힘들어지는 문제가 있었습니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;문제점 5 - 체계적이지 않은 오류 대응 프로세스 및 모니터링 환경&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;기존에는 Airflow DAG가 실패했을 때 알림을 보내는 슬랙 채널이 존재했습니다. 보통 메시지가 오면 관리자 혹은 히스토리를 잘 알고 있는 사용자가 해당 DAG의 책임자에게 라우팅을 해주는 방식이었습니다. 하지만 담당자를 제대로 파악하고 대응하기까지 시간이 걸리는 경우들이 있었고, 담당자를 제때 파악하지 못하는 경우들도 있었습니다.&lt;/p&gt;

&lt;p&gt;또한 Airflow가 동작하는 K8s 환경에 대한 체계적인 모니터링 환경을 구축하고 있지 못했습니다.&lt;/p&gt;

&lt;h3 id=&quot;13-해결-방안-모색&quot;&gt;1.3. 해결 방안 모색&lt;/h3&gt;

&lt;p&gt;Airflow를 운영하면서 드러난 문제들을 개선하기 위해 아래와 같은 해결 방안들을 세웠습니다. 구체적인 내용들은 밑에서 더 상세하게 풀어내도록 하겠습니다.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;문제점&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;해결 방안&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;개발 환경의 Airflow의 에러 발생 및 리소스 낭비 &lt;br /&gt; 불친절한 개발 환경, 긴 피드백 루프&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;개발 환경 개선 및 개발 주기 단축하기&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Airflow 1 버전의 고질적인 문제들&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Airflow 2 버전 마이그레이션 및 스케일 업&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;코드 보안에 취약하고, 사용자 개인에 대한 권한 체계 부족&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;보안 강화 및 RBAC 적용&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;체계적이지 않은 오류 대응 프로세스 및 모니터링 환경&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;체계적인 모니터링 환경 구축&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&quot;2-개발-환경-개선-및-개발-주기-단축하기&quot;&gt;2. 개발 환경 개선 및 개발 주기 단축하기&lt;/h2&gt;

&lt;h3 id=&quot;21-목적&quot;&gt;2.1. 목적&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;사용자들이 빠르게 개발할 수 있도록 지원하고 DAG 개발 이외의 관심사를 최대한 분리할 수 있도록 합니다.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;데이터 플랫폼을 운영하기 위해선 시스템을 개발/유지 보수하는 것을 넘어서 고객을 이해하고 플랫폼을 지속해서 개선해나가는 것이 중요합니다. 
특히 쏘카의 데이터 분석가, 데이터 사이언티스트 등 프로그래밍에 익숙하지 않은 팀원들에게 Airflow 사용의 러닝 커브를 낮춰주는 것이 중요합니다.&lt;/p&gt;

&lt;p&gt;또한 Airflow를 사용하기 위해서 사용자가 Airflow 구성요소와 인프라 등을 전부 이해할 필요는 없습니다. 
사용자가 DAG을 개발하는 것에 집중할 수 있도록 나머지는 잘 추상화하여 관심사를 분리하여야 합니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;사용자의 개발 및 피드백 주기를 단축합니다.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;소프트웨어는 지속적인 개선을 위해서 피드백 루프를 짧게 가져가는 것이 중요합니다.
일반적으로 로컬 환경에서 Airflow DAG 개발/수행에 대한 피드백 시간이 가장 빠릅니다(LocalExecutor, SequentialExecutor). 다만 로컬에서 개발하기 위해선 외부 환경에 대한 Mocking과 인증에 대한 고민을 함께 해야 합니다.&lt;/p&gt;

&lt;h3 id=&quot;22-로컬-개발-환경-구축&quot;&gt;2.2. 로컬 개발 환경 구축&lt;/h3&gt;

&lt;p&gt;기존 Airflow 개발 환경은 Airflow의 생애 주기가 Branch에 의존적이기 때문에 Branch가 남아있다면 자원을 유휴상태로 낭비하는 경우들이 많았습니다. 또한 Branch가 삭제되었을 때 CI/CD 파이프라인의 이슈로 Airflow가 제대로 삭제되지 않는 문제들이 있었습니다. 
그리고 K8s + Git Sync 조합은 DAG이 많을수록 동기화 속도가 느려져서 피드백 루프와 개발 속도의 저하를 유발했습니다.&lt;/p&gt;

&lt;p&gt;그래서 &lt;strong&gt;개발 환경을 노트북(로컬 환경)에서 쉽게 구축할 수 있다면 생산성이 더 높아질 것이라고 판단하였습니다.&lt;/strong&gt; 기본적으로 Docker는 OS에 크게 상관없이 표준을 따르기 때문에 로컬 환경에 &lt;strong&gt;Docker Compose&lt;/strong&gt;를 띄워서 개발 환경을 개선하는 작업을 진행했습니다.&lt;/p&gt;

&lt;p&gt;결과적으로 로컬 환경을 도입하여서 아래와 같이 개발 생산성을 높이고 인적/클라우드 비용의 절감을 이끌어냈습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Airflow 서버를 띄우는 시간 단축 : &lt;strong&gt;5분 -&amp;gt; 1분&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;개발 피드백 루프 시간 단축 : &lt;strong&gt;1분(Commit -&amp;gt; Sync) -&amp;gt; 5초&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;개발 클러스터에서 유휴 Airflow들이 Node를 점유하였던 문제 해결 : &lt;strong&gt;2개 이상의 VM 절약&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;Docker라는 표준 환경을 통해 Airflow 서버의 불안정성을 낮추고 관리 비용을 줄임&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/img/advanced-airflow-for-databiz/airflow-dev-env-to-be.png&quot; alt=&quot;airflow-dev-env-to-be.png&quot; /&gt;&lt;em&gt;Airflow 로컬 개발 환경&lt;/em&gt;&lt;/p&gt;

&lt;h4 id=&quot;docker-compose로-각-컴포넌트-띄우기&quot;&gt;Docker Compose로 각 컴포넌트 띄우기&lt;/h4&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;docker-compose&lt;/code&gt; 로컬 환경 구축을 진행할 때 기본 Airflow 컴포넌트들은 각각 Image로 나눠서 띄웠습니다. 
기본적으로 공식 Airflow의 &lt;a href=&quot;https://airflow.apache.org/docs/apache-airflow/2.4.1/docker-compose.yaml&quot;&gt;docker-compose 파일&lt;/a&gt;을 참고하였고, 추가로 저희 상황에 맞게 의존성을 추가하였습니다.&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;na&quot;&gt;version&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;3.8&quot;&lt;/span&gt;

&lt;span class=&quot;na&quot;&gt;x-airflow-common&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nl&quot;&gt;&amp;amp;airflow-common&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;apache/airflow:2.3.2&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;environment&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nl&quot;&gt;&amp;amp;airflow-common-env&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;EXECUTOR&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;Local&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# LocalExecutor로 실행합니다 &lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;_PIP_ADDITIONAL_REQUIREMENTS&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;...&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# 추가 의존성을 설치합니다&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;GOOGLE_APPLICATION_CREDENTIALS&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;...&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# 사용자 인증 파일(GCP Service Account) 경로를 넣어줍니다&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;AIRFLOW__SCHEDULER__DAG_DIR_LIST_INTERVAL&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;5&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# DAG 코드의 변화를 빠르게 감지하여 metadb에 반영한다. &lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;...&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;services&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;init&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# Airflow user를 생성하고 .airflowignore를 적용하는 등의 script를 실행합니다&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;*airflow-common&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;entrypoint&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;/bin/bash&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;command&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;/opt/airflow/scripts/entrypoint.sh&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;environment&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;s&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;*airflow-common-env&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;_AIRFLOW_DB_UPGRADE&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;true&quot;&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;_AIRFLOW_WWW_USER_CREATE&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;true&quot;&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;_AIRFLOW_WWW_USER_USERNAME&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;${_AIRFLOW_WWW_USER_USERNAME:-airflow}&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;_AIRFLOW_WWW_USER_PASSWORD&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;${_AIRFLOW_WWW_USER_PASSWORD:-airflow}&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;TARGET_DIR&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;_development&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;...&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;webserver&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;*airflow-common&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;...&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;scheduler&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; 
    &lt;span class=&quot;s&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;*airflow-common&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;...&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;mysql&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; 
    &lt;span class=&quot;s&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;*airflow-common&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;...&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;gcp-service-account를-통합-인증-수단으로-활용하기&quot;&gt;GCP Service Account를 통합 인증 수단으로 활용하기&lt;/h4&gt;

&lt;p&gt;기본적으로 Airflow는 GCP 리소스(BigQuery, Secret Manager, GKE 등)에 접근하는 경우가 많기에, 로컬에서 개발할 때 권한 관리가 필요합니다. 이런 인증 문제는 개인 별 Service Account 발급을 통해 해결하였습니다.&lt;/p&gt;

&lt;p&gt;현재 GCP의 전체적 운영은 데이터 플랫폼 팀에서 담당하고 있습니다. GCP IAM은 팀 단위의 역할에 맞게 Custom Role을 만들어 관리하고 있으며, 사용자별 Service Account는 해당 팀의 Role에 바인딩 되어 있습니다. 사용자가 Airflow 개발을 필요로 할 때 데이터 플랫폼 팀에서 Service Account 발급을 해줍니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/advanced-airflow-for-databiz/service-account-one-key.png&quot; alt=&quot;service-account-one-key.png&quot; /&gt;&lt;em&gt;Service Account 활용 구조&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;이를 잘 활용하여 Secret(Connection, Variable 등)도 GCP Secret Manager로 옮긴 후 Service Account로 인증하여 로컬에 보안 정보를 전부 제외할 수 있었습니다.&lt;/p&gt;

&lt;h4 id=&quot;kubernetespodoperator를-테스트할-수-있는-환경-구축&quot;&gt;KubernetesPodOperator를 테스트할 수 있는 환경 구축&lt;/h4&gt;

&lt;p&gt;현재 쏘카의 Airflow는 &lt;code class=&quot;highlighter-rouge&quot;&gt;KubernetesExecutor&lt;/code&gt;를 사용하고 있습니다. KubernetesExecutor의 장점 중 하나는 KubernetesPodOperator를 통해 사용자가 직접 정의한 컨테이너 이미지를 Pod 형태로 독립적 수행이 가능하다는 점입니다. 
사용자가 정의한 이미지에는 의존성을 별도로 설치할 수 있고 Airflow DAG 레포에 종속되지 않기에, 저희 팀에서도 자주 활용하고 있습니다. (KubernetesExecutor에 대해서 더 궁금하다면 &lt;a href=&quot;https://airflow.apache.org/docs/apache-airflow/stable/executor/kubernetes.html&quot;&gt;여기&lt;/a&gt;를 참고해 주세요)&lt;/p&gt;

&lt;p&gt;KubernetesExecutor에서 실행하는 일반적인 Operator(PythonOperator, BigqueryOperator, etc)는 Pod 형태로 수행되며, 이는 로컬 환경인 LocalExecutor 수행 방식(Scheduler Process에서 Task를 실행)으로 대체해도 수행이 가능합니다.&lt;br /&gt;
하지만 KubernetesPodOperator의 경우 컨테이너 이미지를 Pod에서 수행하다 보니 LocalExecutor로 해당 태스크를 수행하는 것이 불가능합니다. 현재 쏘카에서 KubernetesPodOperator를 많이 사용하고 있는데, 해당 기능 테스트를 제한한다면 사용자 경험을 해칠 것입니다.&lt;/p&gt;

&lt;p&gt;처음에 이 문제를 해결하기 위해서 컨테이너 형태로 태스크를 수행할 수 있는 &lt;code class=&quot;highlighter-rouge&quot;&gt;DockerOperator&lt;/code&gt;를 활용해 보면 어떨까 생각하였습니다. 로컬 환경에서는 DockerOperator, 운영 환경에서는 KubernetesPodOperator를 수행하는 팩토리 형태의 Operator를 만드는 방식을 고민해 봤습니다.
하지만 두 오퍼레이터의 시그니처(속성)가 다른 부분이 꽤 있었으며 개발하더라도 본질적인 문제 해결이 아니라고 판단하였습니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;고민 끝에 결국 개발 환경의 Kubernetes Cluster에 직접 연결해서 Pod을 띄우는 방식으로 문제를 해결하였습니다&lt;/strong&gt;. 여기서 제일 신경 썼던 부분은 사용자가 쿠버네티스를 알지 못해도 동작할 수 있도록 추상화를 하는 것입니다. 
로컬에서는 기본적으로 KubernetesPodOperator를 실행하게 되면, Service Account 기반의 K8s 인증을 한 후 미리 생성한 Namespace(Local 전용 Namespace)에 Pod을 띄울 수 있도록 하였습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;OAuth 인증이 아닌 GCP Service Account 기반의 인증을 할 수 있도록 Service Account를 발급하고 이를 기반으로 .kubeconfig 파일을 사전 정의하여 Docker Image에 Mount 합니다. 이 덕분에 사용자는 Kubernetes 관련 설정(Kubectl, 인증 설정 등)을 하지 않아도 됩니다. (&lt;a href=&quot;https://cloud.google.com/kubernetes-engine/docs/how-to/api-server-authentication?hl=ko#environments-without-gcloud&quot;&gt;Kubernetes API 서버에 인증&lt;/a&gt; 글에서 더 자세한 내용을 확인할 수 있습니다)&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;K8s RBAC을 활용해 미리 허용한 Service Account를 대상으로 Airflow 전용 Namespace에서 K8s Pod의 CRUD가 가능하도록 합니다. 해당 Namespace를 제외하고는 다른 자원에 접근할 수 없도록 Role을 관리합니다.&lt;/p&gt;

    &lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;na&quot;&gt;apiVersion&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;rbac.authorization.k8s.io/v1&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;Role&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;metadata&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;airflow-feature-role&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;s&quot;&gt;...&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;rules&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;apiGroups&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pi&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;]&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;resources&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pi&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;*&quot;&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;]&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;verbs&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pi&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;get&quot;&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;list&quot;&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;watch&quot;&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;apiGroups&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pi&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;]&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;resources&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pi&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;pods&quot;&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;]&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;verbs&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pi&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;get&quot;&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;list&quot;&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;create&quot;&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;delete&quot;&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;update&quot;&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;patch&quot;&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;]&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;---&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;apiVersion&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;rbac.authorization.k8s.io/v1&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;RoleBinding&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;metadata&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;airflow-feature-role&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;s&quot;&gt;...&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;namespace&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;airflow-feature&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;subjects&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;User&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;lt;service_account&amp;gt;&quot;&lt;/span&gt;
      &lt;span class=&quot;s&quot;&gt;...&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;roleRef&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;Role&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;airflow-feature-role&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;apiGroup&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;rbac.authorization.k8s.io&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;사용자는 KubernetesPodOperator의 &lt;code class=&quot;highlighter-rouge&quot;&gt;in_cluster&lt;/code&gt;와 &lt;code class=&quot;highlighter-rouge&quot;&gt;config_file&lt;/code&gt; 속성을 설정합니다. 꼭 KubernetesExecutor가 아니더라도 다른 Executor에서도 KubernetesPodOperator를 실행할 수 있다는 사실 알고 계셨나요? 아래와 같이 설정을 해주면 로컬에서도 K8s 인증을 하고 Pod CRUD가 가능합니다.&lt;/p&gt;

    &lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;     &lt;span class=&quot;n&quot;&gt;task1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;KubernetesPodOperator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
          &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
          &lt;span class=&quot;n&quot;&gt;in_cluster&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
          &lt;span class=&quot;n&quot;&gt;config_file&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;/opt/airflow/.kube/config&quot;&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# Service Account 기반 인증을 설정한 kubeconfig 파일의 경로
&lt;/span&gt;      &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;dag-파싱-효율화를-위한-airflowignore-활용&quot;&gt;DAG 파싱 효율화를 위한 .airflowignore 활용&lt;/h4&gt;

&lt;p&gt;DAG 개수가 늘어나게 되면 Scheduler는 모든 DAG을 파싱 하기까지 시간이 오래 걸리며 컴퓨팅 자원을 많이 소비하게 됩니다. 따라서 개발 중인 DAG들만 Parsing 할 수 있다면 자원을 아끼고 개발 시간을 단축할 수 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;.airflowignore&lt;/code&gt;를 활용하여 Glob 패턴으로 특정 디렉토리를 제외하고는 Parsing이 되지 않도록 설정할 수 있습니다. 
그리고 사용자가 로컬 환경에서 개발할 때 해당 디렉토리 (e.g., _development 폴더)에서 개발하도록 README를 통해 가이드를 주었습니다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;^((?!_development).)*$
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;(&lt;code class=&quot;highlighter-rouge&quot;&gt;.airflowignore&lt;/code&gt;에 대한 내용은 &lt;a href=&quot;https://airflow.apache.org/docs/apache-airflow/stable/concepts/dags.html#airflowignore&quot;&gt;Airflow 공식 문서&lt;/a&gt;를 참고해 주세요)&lt;/p&gt;

&lt;h3 id=&quot;23-테스트-환경-구축&quot;&gt;2.3. 테스트 환경 구축&lt;/h3&gt;

&lt;p&gt;신뢰성 있는 소프트웨어를 운영하기 위해선 테스트는 선택이 아닌 필수입니다. 테스트 작성 및 자동화를 통해 많은 사용자들이 개입하는 코드 베이스의 안전성을 높일 수 있으며 코드 퀄리티를 높게 유지할 수 있습니다.&lt;/p&gt;

&lt;h4 id=&quot;테스트-코드-작성&quot;&gt;테스트 코드 작성&lt;/h4&gt;

&lt;p&gt;수많은 DAG에 대해 모두 테스트 코드를 작성하기보다는 변경된 DAG 파일을 대상으로 DAG 문법 검사 및 일부 포맷 검사를 하는 방식으로 테스트 코드를 작성했습니다. 이를 위해선 커밋에서 변경된 DAG들을 대상으로 문법에 맞게 잘 작성되었는지 &lt;code class=&quot;highlighter-rouge&quot;&gt;dagbag&lt;/code&gt;을 활용했습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;변경되는 파일을 추출하여 테스트를 실행하는 스크립트&lt;/p&gt;

    &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;c&quot;&gt;#!bin/sh&lt;/span&gt;
    
  &lt;span class=&quot;nb&quot;&gt;set&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-eo&lt;/span&gt; pipefail
    
  &lt;span class=&quot;nv&quot;&gt;staged_files&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:-&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;$(&lt;/span&gt;git diff &lt;span class=&quot;nt&quot;&gt;--cached&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--name-status&lt;/span&gt; | &lt;span class=&quot;nb&quot;&gt;awk&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'$1 != &quot;D&quot; { print $2 }'&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;[staged_files] &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;staged_files&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;
    
  airflow db init &lt;span class=&quot;c&quot;&gt;# Airflow DagBag Test를 위해선 Backend DB가 생성되어야 합니다.&lt;/span&gt;
  &lt;span class=&quot;nv&quot;&gt;PYTHONPATH&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;.&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;files&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$staged_files&lt;/span&gt; python &lt;span class=&quot;nt&quot;&gt;-m&lt;/span&gt; pytest tests/test_dag_bag.py
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;pytest의 &lt;code class=&quot;highlighter-rouge&quot;&gt;monkeypatch&lt;/code&gt;을 활용해 외부 의존성(Service Account, BaseHook 등)을 Mocking 합니다.&lt;/p&gt;

    &lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pytest&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fixture&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;changed_files&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;List&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;changed_files&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;getenv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;files&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;replace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot; &quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;split&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;changed_dag_files&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;
          &lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;
          &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;path&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;changed_files&lt;/span&gt;
          &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;startswith&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;dags/&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;might_contain_dag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;file_path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;safe_mode&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;changed_dag_files&lt;/span&gt;
    
  &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pytest&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fixture&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;monkey_patching&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;monkeypatch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
      &lt;span class=&quot;c1&quot;&gt;# Mock
&lt;/span&gt;      &lt;span class=&quot;n&quot;&gt;monkeypatch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;setattr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Credentials&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;from_service_account_file&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;lambda&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;
    
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;변경된 DAG들을 대상으로 다양한 테스트를 진행합니다.&lt;/p&gt;

    &lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;c1&quot;&gt;# 기본 DAG의 문법을 DagBag을 통해 테스트합니다.
&lt;/span&gt;  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;test_dags_validate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;changed_files&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;monkey_patching&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dag_file&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;changed_files&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;
          &lt;span class=&quot;n&quot;&gt;dagbag&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DagBag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dag_folder&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dag_file&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;include_examples&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
          &lt;span class=&quot;k&quot;&gt;assert&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dagbag&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dags&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;keys&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
          &lt;span class=&quot;k&quot;&gt;assert&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dagbag&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;import_errors&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
    
  &lt;span class=&quot;c1&quot;&gt;# DAG에 Owner를 쏘카 이메일 형식(e.g., grab@socar.kr)으로 작성했는지 테스트합니다
&lt;/span&gt;  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;test_dags_owner_validate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;changed_files&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;monkey_patching&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dag_file&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;changed_files&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;
          &lt;span class=&quot;n&quot;&gt;dagbag&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DagBag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dag_folder&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dag_file&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;include_examples&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
          &lt;span class=&quot;n&quot;&gt;dag&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dagbag&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dags&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;values&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
          &lt;span class=&quot;k&quot;&gt;assert&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;validate_owner_format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dag&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;owner&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
  &lt;span class=&quot;c1&quot;&gt;# 로컬에서 KubernetesPodOperator를 테스트한 후 설정을 다시 되돌렸는지 테스트합니다
&lt;/span&gt;  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;test_pod_operator_config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;changed_files&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;monkey_patching&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;POD_OPERATOR_LIST&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;GooglesheetToBigqueryOperator&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;KubernetesPodOperator&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dag_file&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;changed_files&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;
          &lt;span class=&quot;n&quot;&gt;dagbag&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DagBag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dag_folder&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dag_file&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;include_examples&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
          &lt;span class=&quot;n&quot;&gt;dag&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dagbag&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dags&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;values&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
          &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;task&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dag&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tasks&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
              &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;task&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;task_type&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;POD_OPERATOR_LIST&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                  &lt;span class=&quot;k&quot;&gt;assert&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;task&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;in_cluster&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;{task.task_type}의 in_cluster 속성을 삭제해 주세요&quot;&lt;/span&gt;
                  &lt;span class=&quot;k&quot;&gt;assert&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;task&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;config_file&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;{task.task_type}의 config_file 속성을 삭제해 주세요&quot;&lt;/span&gt;
    
  &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이 외에도 팀에서 직접 만든 Operator나 Helper 코드에 대한 테스트를 작성 중에 있습니다.&lt;/p&gt;

&lt;h4 id=&quot;github-action을-통한-테스트-자동화&quot;&gt;Github Action을 통한 테스트 자동화&lt;/h4&gt;

&lt;p&gt;쏘카에서는 현재 대부분의 CI 파이프라인으로 &lt;code class=&quot;highlighter-rouge&quot;&gt;github action&lt;/code&gt;을 사용하고 있습니다. Github Action을 활용하면 &lt;code class=&quot;highlighter-rouge&quot;&gt;workflow&lt;/code&gt; 파일을 통해 간단하게 테스트 자동화가 가능합니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/advanced-airflow-for-databiz/github-action.png&quot; alt=&quot;github-action.png&quot; /&gt;&lt;em&gt;쏘카에서 사용하는 Airflow Repo의 Github Action&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;현재 CI 워크플로우는 아래와 같이 동작합니다&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;변경된 파일들을 감지합니다.&lt;/li&gt;
  &lt;li&gt;Pre Commit으로 정해진 컨벤션(&lt;code class=&quot;highlighter-rouge&quot;&gt;autoflake&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;black&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;isort&lt;/code&gt; 등)에 맞게 작성했는지 확인합니다.&lt;/li&gt;
  &lt;li&gt;변경된 파일을 대상으로 위에서 작성한 테스트를 실행합니다.&lt;/li&gt;
  &lt;li&gt;로컬 환경에서 개발할 때 사용한 파일이나 설정 등을 되돌렸는지 확인합니다.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;운영 환경으로 머지되는 모든 Pull Request는 위 워크플로우를 통과하고 한 명 이상의 리뷰어의 승인이 있어야 머지 될 수 있도록 설정하였습니다.&lt;/p&gt;

&lt;h3 id=&quot;24-사용자의-airflow-러닝-커브를-낮추기-위한-시도들&quot;&gt;2.4. 사용자의 Airflow 러닝 커브를 낮추기 위한 시도들&lt;/h3&gt;

&lt;p&gt;처음 Airflow를 사용한다면 DAG, Task를 작성하는 방법부터 시작해서, 컨벤션에 맞게 코드를 작성하는 것은 난도가 높을 수 있습니다. 따라서 사용자가 최대한 빠르게 온보딩 할 수 있도록 문서화 및 교육을 진행하였습니다.&lt;/p&gt;

&lt;h4 id=&quot;airflow-환경-설치--개발-가이드-등-문서화&quot;&gt;Airflow 환경 설치 &amp;amp; 개발 가이드 등 문서화&lt;/h4&gt;

&lt;p&gt;Airflow 로컬 환경 구축 가이드(Docker, Python 환경 등)을 시작으로 트러블슈팅, 개발 가이드 등을 문서화하여 기존 사용자와 신규 입사자가 더 빠르게 Airflow에 온보딩 할 수 있도록 하였습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/advanced-airflow-for-databiz/airflow-user-guide.png&quot; alt=&quot;airflow-user-guide.png&quot; /&gt;&lt;em&gt;사내 Airflow 이용자를 위해 만든 가이드&lt;/em&gt;&lt;/p&gt;

&lt;h4 id=&quot;사내-airflow-교육-진행&quot;&gt;사내 Airflow 교육 진행&lt;/h4&gt;

&lt;p&gt;Airflow를 사용하고 싶은 사람들을 대상으로 사내 Airflow 세미나를 열었습니다. 
Airflow 기본 개념부터 DAG 작성법과 각종 Operator 사용법 등을 제공했으며 추후 녹화본도 공유되었습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/advanced-airflow-for-databiz/seminar-recording.png&quot; alt=&quot;seminar-recording.png&quot; /&gt;&lt;em&gt;Airflow 사내 세미나 녹화본&lt;/em&gt;&lt;/p&gt;

&lt;h4 id=&quot;오피스-아워-슬랙-문의-채널-운영-등을-통해-개발-서포트&quot;&gt;오피스 아워, 슬랙 문의 채널 운영 등을 통해 개발 서포트&lt;/h4&gt;

&lt;p&gt;데이터 플랫폼 팀에서는 격주 오피스 아워를 통해 Airflow, MLOps Platform 등 데이터 플랫폼을 사용하면서 생기는 문제들을 자유롭게 질문할 수 있도록 하고 있습니다. 또한 슬랙 문의 채널을 통해 데이터 플랫폼 이용 관련 질문들을 할 수 있도록 하여 사용하는데 불편함이 없도록 최대한 서포트하고 있습니다&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/advanced-airflow-for-databiz/dp-office-hour.png&quot; alt=&quot;dp-office-hour.png&quot; /&gt;&lt;em&gt;데이터 플랫폼팀 오피스 아워 페이지&lt;/em&gt;&lt;/p&gt;

&lt;h4 id=&quot;makefile-활용해서-쉽게-명령어들-사용할-수-있도록-구성&quot;&gt;Makefile 활용해서 쉽게 명령어들 사용할 수 있도록 구성&lt;/h4&gt;

&lt;p&gt;사용자가 Airflow를 더 편하게 사용할 수 있도록 주요 명령어를 Shell Script 기반으로 작성하고 Makefile 커맨드를 활용하도록 가이드 하였습니다.&lt;/p&gt;

&lt;div class=&quot;language-makefile highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;project_flag&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;-p&lt;/span&gt; local-airflow

&lt;span class=&quot;c&quot;&gt;# environment variables
&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;.EXPORT_ALL_VARIABLES&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;PROJECT_ROOT_RELATIVE_PATH&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;.
&lt;span class=&quot;nv&quot;&gt;PYTHONPATH&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;.

&lt;span class=&quot;nl&quot;&gt;install&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;##&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt; ♻ 로컬 Airflow 의존성을 설치합니다.&lt;/span&gt;
	&lt;span class=&quot;p&quot;&gt;@&lt;/span&gt;bash scripts/install.sh
&lt;span class=&quot;nl&quot;&gt;local-airflow&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;##&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt; 📍 로컬에 Airflow를 띄웁니다.&lt;/span&gt;
	&lt;span class=&quot;p&quot;&gt;@&lt;/span&gt;bash scripts/run-local.sh
&lt;span class=&quot;nl&quot;&gt;clean-up&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;##&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt; 🌬 Airflow 환경을 초기화합니다.&lt;/span&gt;
	&lt;span class=&quot;p&quot;&gt;@&lt;/span&gt;bash scripts/clean-up.sh
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;3-지속적으로-airflow-안정화하기&quot;&gt;3. 지속적으로 Airflow 안정화하기&lt;/h2&gt;

&lt;h3 id=&quot;31-목적&quot;&gt;3.1. 목적&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Data Freshness를 항상 유지할 수 있도록 합니다.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Data Freshness는 데이터가 얼마나 최신 상태인가를 나타냅니다. Airflow는 배치 데이터 파이프라인의 오케스트레이션 툴인만큼 단일 실패 지점(SPOF, Single Point Of Failure)이 되기도 합니다. 만약 Airflow가 모종의 이유로 중단될 경우 제시간에 데이터가 적재되지 않을 것이며 이는 Data Freshness를 유지하기가 어려워집니다. 따라서 Airflow의 신뢰성을 높이고 지속적으로 퍼포먼스를 확인하고 개선하는 것이 필요합니다.&lt;/p&gt;

&lt;h3 id=&quot;32-airflow-2-마이그레이션&quot;&gt;3.2. Airflow 2 마이그레이션&lt;/h3&gt;

&lt;p&gt;기존 Airflow 1 버전은 DAG 개수가 늘어나면서 연속적인 Task Instance 스케줄링 간 Lag이 길었고 기타 자잘한 버그들이 있었습니다. Airflow 2에서 대표적으로 개선된 부분들은 아래와 같습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;스케줄링 퍼포먼스가 개선되었습니다.&lt;/p&gt;

    &lt;p&gt;Airflow 2는 DAG Serialization과 Fast-Follow를 도입하여 Scheduler의 반복적인 DAG 파싱 작업을 줄이고 Task Scheduling 과정을 개선하였습니다. &lt;a href=&quot;https://www.astronomer.io/blog/airflow-2-scheduler&quot;&gt;Astronomer 블로그&lt;/a&gt;에서 벤치마크 테스트를 했을 때 10배 이상의 성능 개선이 있었다고 합니다. 팀에서 경험하는 문제였던 Task instance 스케줄링 간 Lag 현상도 많이 줄었습니다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Scheduler HA(High Availability)를 지원해서 스케줄러의 Scale Out이 용이합니다.&lt;/p&gt;

    &lt;p&gt;Active-Active 클러스터 형태로 Scheduler의 HA를 지원합니다. 이때 Meta DB는 &lt;code class=&quot;highlighter-rouge&quot;&gt;SELECT ... FOR UPDATE&lt;/code&gt;로 Row Level Lock이 걸리게 됩니다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;웹 서버 사용성이 개선되었습니다.&lt;/p&gt;

    &lt;p&gt;DAG Serialization을 통해 더 빠르게 웹 UI에서 더 빠르게 DAG 정보를 불러올 수 있으며 Auto Refresh 기능 등 사용성이 개선되었습니다. 저희 팀에서도 사용자의 Airflow 사용성을 위해 지속적으로 하위호환성을 고려하며 버전을 업그레이드하고 있습니다. 글을 쓰는 시점인 2.3 버전은 더 직관적인 UI를 제공해 주어 저희 팀에서도 2.3 버전으로 업그레이드를 완료하였습니다.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이 외에도 TaskFlow API 도입, Airflow Core Component에서 Provider 분리, Task Group, Smart Sensor 도입 등등 많은 변화가 있습니다. 더 궁금하신 분들은 &lt;a href=&quot;https://www.astronomer.io/blog/airflow-2-scheduler&quot;&gt;해당 글&lt;/a&gt;을 읽어보시면 도움이 될 것 같습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/advanced-airflow-for-databiz/logo-anim.gif&quot; alt=&quot;logo-anim.gif&quot; /&gt;&lt;em&gt;Airflow 로고를 커스텀 해보았습니다.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Airflow 2로 마이그레이션하면서 1 버전과 호환성이 깨지는 부분들이 다소 있었고 이를 해결하는 데 시간이 꽤 소요됐습니다. 하지만 마이그레이션 한 후 Airflow의 스케줄링 퍼포먼스가 올라갔으며 Task/DAG 간의 의존관계가 복잡하거나 코드가 복잡한 경우도 제공되는 API를 잘 활용하여 코드 퀄리티를 높일 수 있었습니다.&lt;/p&gt;

&lt;h3 id=&quot;33-스케줄러-성능-최적화를-위한-configuration-설정&quot;&gt;3.3. 스케줄러 성능 최적화를 위한 Configuration 설정&lt;/h3&gt;
&lt;p&gt;Airflow는 Scheduler, Webserver의 성능을 &lt;a href=&quot;https://airflow.apache.org/docs/apache-airflow/stable/configurations-ref.html#&quot;&gt;Configuration&lt;/a&gt; 을 통해 설정할 수 있도록 지원합니다.
팀에서도 많은 DAG들을 운영하는 과정에서 스케줄러 성능 최적화를 위해 아래처럼 Configuration을 변경하였습니다.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;변수명&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;정의&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;설정 내용&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;AIRFLOW__CORE__PARALLELISM&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;스케줄러 당 동시에 스케줄링 가능한 DagRun 개수에 대한 설정&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;병렬 처리를 위해 기존보다 높게 설정&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;AIRFLOW__SCHEDULER__PARSING_PROCESSES&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;스케줄러가 DAG 파일을 파싱 할 때 사용할 Process 개수에 대한 설정&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;스케줄러 HA를 적용하기도 했고, CPU 사용량에 비해 기대효과가 잘 나오지 않아 기존 값 유지&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;AIRFLOW__SCHEDULER__MIN_FILE_PROCESS_INTERVAL&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;스케줄러가 DAG File을 파싱 하는 주기(초)에 대한 설정&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Parsing 시 CPU 사용량이 높아져서 기존보다 높게 설정&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;AIRFLOW__SCHEDULER__POOL_METRICS_INTERVAL&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;a href=&quot;https://airflow.apache.org/docs/apache-airflow/stable/concepts/pools.html&quot;&gt;pool&lt;/a&gt; 사용량을 StatSD로 보내는 주기에 대한 설정&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;공식 문서에 상대적으로 비싼 쿼리라고 명시되어 있어 기존보다 높게 설정&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Scheduler에서 지속적으로 스케줄링 지연 현상이 발생하면 아래 Configuration도 함께 조정할 계획입니다.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;변수명&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;정의&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;AIRFLOW__KUBERNETES__WORKER_PODS_CREATION_BATCH_SIZE&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;스케줄러가 한 번 루프를 돌 때 Worker Pod 최대 생성 개수에 대한 설정 &lt;br /&gt; &lt;code class=&quot;highlighter-rouge&quot;&gt;KubernetesExecutor&lt;/code&gt;를 사용할 때 더 높은 퍼포먼스를 기대할 수 있음&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;AIRFLOW__SCHEDULER__MAX_DAGRUNS_PER_LOOP_TO_SCHEDULER&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;스케줄러가 한 번 루프를 돌 때 얼마나 많은 DagRun들을 처리할지에 대한 설정&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;AIRFLOW__SCHEDULER__MAX_DAGRUNS_TO_CREATE_PER_LOOP&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;스케줄러가 한 번 루프를 돌 때 얼마나 많은 DAG이 DagRun을 생성하게 할지에 대한 설정&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;스케줄러 성능 튜닝에 대해 더 자세하게 알고 싶다면 
&lt;a href=&quot;https://airflow.apache.org/docs/apache-airflow/stable/concepts/scheduler.html#fine-tuning-your-scheduler-performance&quot;&gt;공식 문서&lt;/a&gt; 와 &lt;a href=&quot;https://docs.astronomer.io/learn/airflow-scaling-workers&quot;&gt;Astronomer 블로그 문서&lt;/a&gt;를 읽어보세요.&lt;/p&gt;
&lt;h3 id=&quot;34-고가용성-설정&quot;&gt;3.4. 고가용성 설정&lt;/h3&gt;

&lt;p&gt;Airflow 2에서는 Scheduler HA 설정이 가능합니다. 즉 복수개의 Scheduler를 통해 DAG 스케줄링 지연을 개선할 수 있습니다. 저희는 &lt;a href=&quot;https://github.com/apache/airflow/tree/main/chart&quot;&gt;공식 Helm Chart&lt;/a&gt;를 사용하고 있기에 손쉽게 HA 설정을 하였습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/advanced-airflow-for-databiz/scheduler-ha.png&quot; alt=&quot;scheduler-ha.png&quot; /&gt;&lt;em&gt;Airflow Scheduler HA 설정&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;이때 한 가지 주의할 점은 Scheduler가 증가하는 만큼 Meta DB의 부하도 증가하게 된다는 것입니다. 
Scheduler들은 Row Level Locking(SELECT … FOR UPDATE) 방식으로 DAG, Task 등 자원에 접근하므로 Scheduler가 늘어나면 자연스럽게 Meta DB의 자원 사용량도 높아집니다. 그래서 데이터베이스의 메트릭을 보면서 스케일 업을 해주거나 다중화를 설정하는 것도 하나의 옵션일 것 같습니다.&lt;/p&gt;

&lt;h3 id=&quot;34-kubernetes-환경-개선&quot;&gt;3.4. Kubernetes 환경 개선&lt;/h3&gt;

&lt;p&gt;저희는 K8s 환경에서 Airflow를 운영하기 때문에 Kubernetes의 자원 관리도 함께 고려해야 합니다. 현재 운영 중인 DAG이 700개가 넘기 때문에 많은 Task Pod들이 각각 리소스를 점유하게 됩니다. 만약 특정 시간대에 DAG들이 몰려있는 경우 K8s Node의 리소스가 부족해지고 해당 Node에 떠있는 Pod들의 성능이 저하될 수 있습니다.&lt;/p&gt;

&lt;h4 id=&quot;node-pool-분리-및-auto-scaling-적용&quot;&gt;Node Pool 분리 및 Auto Scaling 적용&lt;/h4&gt;

&lt;p&gt;기본적으로 K8s에서 Airflow를 구성하는 컴포넌트는 기본 구성 컴포넌트(Scheduler, Webserver 등)과 Worker Pod으로 분리할 수 있습니다. 기본 컴포넌트는 요청 자원이 충분히 예측 가능한 반면, Worker Pod은 시간대에 따라 요청하는 자원이 다릅니다.&lt;/p&gt;

&lt;p&gt;그래서 저희는 Worker Pod을 별도로 Ochestration 하는 Node Pool을 분리하였습니다. 그리고 해당 Node Pool은 Auto Scaling을 적용하여 유동적으로 Throughput을 늘려줄 수 있도록 하였습니다.&lt;/p&gt;

&lt;h4 id=&quot;사용자의-task-리소스-직접-할당&quot;&gt;사용자의 Task 리소스 직접 할당&lt;/h4&gt;

&lt;p&gt;K8s 환경의 장점은 Task 별로 자원 할당을 할 수 있다는 점입니다. CPU Bound 한 Task의 경우 CPU 리소스를 높게 할당하고, I/O Bound 한 Task는 CPU 리소스를 낮게 관리하여 K8s Node의 자원 관리를 더 효율적으로 할 수 있습니다. 아래와 같이 Operator의 K8s 리소스 설정을 Patch 하는 &lt;code class=&quot;highlighter-rouge&quot;&gt;assign_operator_resources&lt;/code&gt;라는 Helper 함수를 만들어서 관리하고 있습니다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dataclass&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;DynamicResource&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
    요청할 cpu, memory 자원을 입력해 줍니다.
    ex) cpu: &quot;500m&quot;, memory: &quot;500Mi&quot;
    - cpu의 기본 단위는 m으로 1000m이 1코어라고 보시면 됩니다.
    - memory의 기본 단위는 Mi로 MB와 동일합니다.
    &quot;&quot;&quot;&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;request_cpu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;request_memory&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;limit_cpu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Optional&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;limit_memory&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Optional&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__post_init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# validation
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;_request_cpu&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;join&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;findall&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;r&quot;\d+&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;request_cpu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;_request_memory&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;join&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;findall&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;r&quot;\d+&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;request_memory&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;_limit_cpu&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;join&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;findall&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;r&quot;\d+&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;limit_cpu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;limit_cpu&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;_limit_memory&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;join&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;findall&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;r&quot;\d+&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;limit_memory&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;limit_memory&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;

        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_request_cpu&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_limit_cpu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_request_cpu&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_limit_cpu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;raise&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;ValueError&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;request_cpu가 limit_cpu보다 클 수 없습니다&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_request_memory&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_limit_memory&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_request_memory&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_limit_memory&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;raise&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;ValueError&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;request_memory가 limit_memory보다 클 수 없습니다&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;assign_operator_resources&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;operator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BaseOperator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;resource&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DynamicResource&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BaseOperator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
    KubernetesPodOperator가 아닌 Operator들도 Resource 할당이 가능하도록 설정합니다.
    &quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;operator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;executor_config&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;&quot;pod_override&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k8s&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;V1Pod&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;spec&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k8s&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;V1PodSpec&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;containers&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;k8s&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;V1Container&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
                        &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;base&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                        &lt;span class=&quot;n&quot;&gt;resources&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;V1ResourceRequirements&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
                            &lt;span class=&quot;n&quot;&gt;limits&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;cpu&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;resource&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;limit_cpu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;memory&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;resource&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;limit_memory&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;
                            &lt;span class=&quot;n&quot;&gt;requests&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;cpu&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;resource&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;request_cpu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;memory&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;resource&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;request_memory&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;
                        &lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
                    &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;operator&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;t1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;assign_operator_resources&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;PythonOperator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;task_id&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;t1&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;python_callable&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=...&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;resource&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DynamicResource&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;request_cpu&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;100m&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;request_memory&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;128Mi&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;limit_cpu&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;300m&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;limit_memory&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;256Mi&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;35-clean-up-dag-적용&quot;&gt;3.5. Clean Up DAG 적용&lt;/h3&gt;

&lt;p&gt;실제로 DAG 개수가 많아지고 운영 기간이 길어질수록 데이터베이스에 히스토리 관련 레코드들이 많이 쌓여있게 됩니다. 이는 데이터베이스의 성능을 저하시키고 Scheduler의 쿼리 성능 저하를 유발하여 전체적인 퍼포먼스가 떨어지게 됩니다.&lt;/p&gt;

&lt;p&gt;따라서 주기적으로 오래된 DAG과 Task 등 Historical Record들을 지워주게 되면 쿼리 속도를 향상시킬 수 있습니다. 저희는 teamclairvoyant의 &lt;a href=&quot;https://github.com/teamclairvoyant/airflow-maintenance-dags&quot;&gt;airflow-maintenance-dags 레포지토리&lt;/a&gt; 를 참조하여 특정 기간 내에 DAG, Task Instance 등을 지워주는 DAG을 스케줄링했습니다.
&lt;img src=&quot;/img/advanced-airflow-for-databiz/cleanup-dag.png&quot; alt=&quot;cleanup-dag.png&quot; /&gt;&lt;em&gt;Clean Up DAG의 Task 목록&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;실제로 Clean Up DAG이 스케줄링되면서 Database의 리소스 사용량이 상당량 줄었으며, Airflow의 스케줄러 및 웹 서버의 성능 향상을 체감하였습니다.&lt;/p&gt;

&lt;h2 id=&quot;4-보안-강화하기&quot;&gt;4. 보안 강화하기&lt;/h2&gt;

&lt;h3 id=&quot;41-목적&quot;&gt;4.1. 목적&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;코드에서 보안 정보들을 분리합니다.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;외부 자원에 많이 의존하게 되는 Airflow의 특성상 코드에 많은 보안 정보들이 담기게 됩니다. 이때 Airflow의 보안 정보들은 코드 상에 노출되는 것보다 Secret 저장소를 활용하도록 하여 보안성을 높일 수 있도록 합니다. 현재 데이터 본부에서 Airflow를 다수의 사용자가 사용하고 있기에 보안에 대한 교육과 정책 수립도 필요합니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;다수의 사용자를 관리하고 적절한 권한을 줄 수 있도록 합니다.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;다수의 사용자가 시스템을 사용할수록 적절한 권한을 부여하는 것이 중요합니다. 따라서 개인 사용자별 인증을 할 수 있도록 계정을 제공하고, 인가를 더 체계적으로 관리하기 위해 RBAC를 적용합니다.&lt;/p&gt;

&lt;h3 id=&quot;42-보안-강화&quot;&gt;4.2. 보안 강화&lt;/h3&gt;

&lt;p&gt;기존 Airflow는 소스 코드에 보안 정보들이 포함되어 있었습니다. DAG 코드에 보안 정보들(API Key, Password 등)이 포함되는 경우들이 종종 있었고, Airflow 배포를 위한 Helm Chart에서도 Connection, Variable, 보안이 필요한 환경 변수 등을 그대로 노출하고 있었습니다. 따라서 보안 정보들은 별도의 저장소로 분리하는 작업을 진행했습니다.&lt;/p&gt;

&lt;h4 id=&quot;gcp-secret-manager-적용&quot;&gt;GCP Secret Manager 적용&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;/img/advanced-airflow-for-databiz/airflow-secret-manager.png&quot; alt=&quot;airflow-secret-manager.png&quot; /&gt;&lt;em&gt;Secret Manager 목록&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://cloud.google.com/secret-manager&quot;&gt;GCP Secret Manager&lt;/a&gt;는 GCP에서 제공해 주는 보안 정보 관리 툴입니다. 기본적으로 IAM을 통해 세부 권한 조정이 가능하며, 다양한 클라이언트에서 접근할 수 있도록 API를 제공합니다. GCP Secret Manager를 사용하면 손쉽게 보안 정보들과 코드를 분리할 수 있습니다.&lt;/p&gt;

&lt;p&gt;저희는 GCP Secret Manager를 활용할 때 DAG에 하드코딩되어 있는 경우 Airflow Variable 혹은 &lt;a href=&quot;https://cloud.google.com/secret-manager/docs/reference/libraries#client-libraries-install-python&quot;&gt;Secret Manager SDK(Python)&lt;/a&gt;를 사용하였습니다. 
K8s의 경우 &lt;a href=&quot;https://external-secrets.io/latest/&quot;&gt;External Secret&lt;/a&gt; 과 함께 사용하고 있는데 External Secret을 활용하면 외부 Secret 저장소(e.g., GCP Secret Manager)를 통해 쉽게 Secret 리소스로 변환이 가능합니다. 
보안 정보들을 분리하려면 Airflow 사용자들의 보안에 대한 인지가 필요하고 이를 CI 레벨에서 막을 수 있도록 하는 장치도 필요합니다. 현재 저희는 사용자가 암호화된 정보를 직접 저장하고 관리할 수 있도록 프로세스를 구축하고 있으며, 보안 정보들을 감지할 수 있도록 돕는 &lt;a href=&quot;https://github.com/marketplace/actions/gitguardian-shield-action&quot;&gt;GitGuardian Action&lt;/a&gt; 같은 오픈소스를 검토 중에 있습니다.&lt;/p&gt;

&lt;h4 id=&quot;secret-backend-적용을-통해-하드코딩된-connection-variable을-옮기기&quot;&gt;Secret Backend 적용을 통해 하드코딩된 Connection, Variable을 옮기기&lt;/h4&gt;

&lt;p&gt;Airflow에서는 &lt;a href=&quot;https://airflow.apache.org/docs/apache-airflow/stable/security/secrets/secrets-backend/index.html&quot;&gt;Secret Backend&lt;/a&gt;로 GCP Secret Manager, Vault 등 시크릿 관리 툴을 설정할 수 있도록 지원합니다. 위에서 언급한 것처럼 GCP Secret Manager를 Secret Backend로 사용하여 Connection, Variable을 암호화하여 사용하고 있습니다.&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;AIRFLOW__SECRETS__BACKEND: airflow.providers.google.cloud.secrets.secret_manager.CloudSecretManagerBackend &lt;span class=&quot;c&quot;&gt;# GCP Secret Manager 적용&lt;/span&gt;
AIRFLOW__SECRETS__BACKEND__KWARGS: &lt;span class=&quot;s1&quot;&gt;'{ &quot;connections_prefix&quot;: &quot;airflow-connections&quot;, &quot;variables_prefix&quot;: &quot;airflow-variables&quot;, &quot;gcp_key_path&quot;: &quot;...&quot; }'&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;위와 같이 &lt;code class=&quot;highlighter-rouge&quot;&gt;AIRFLOW__SECRETS__BACKEND&lt;/code&gt; 환경 변수를 활용해 Secret Backend 설정이 가능합니다. 그리고 &lt;code class=&quot;highlighter-rouge&quot;&gt;AIRFLOW__SECRETS__BACKEND__KWARGS&lt;/code&gt; 환경 변수를 활용하면 Connection, Variable의 Prefix를 설정해두면 GCP Secret Manager에 Prefix에 맞게 작성된 Secret들을 자동으로 불러오게 됩니다. 
더 자세한 내용은 &lt;a href=&quot;https://airflow.apache.org/docs/apache-airflow/1.10.10/howto/use-alternative-secrets-backend.html#aws-ssm-parameter-store-secrets-backend&quot;&gt;여기&lt;/a&gt;를 참고해 주세요.&lt;/p&gt;

&lt;h3 id=&quot;43-rbac-적용-진행-중&quot;&gt;4.3. RBAC 적용 (진행 중)&lt;/h3&gt;

&lt;p&gt;Airflow는 &lt;a href=&quot;https://airflow.apache.org/docs/apache-airflow/stable/security/access-control.html&quot;&gt;RBAC(Rule Based Access Control)&lt;/a&gt; 을 제공합니다. 
기본적으로 제공해 주는 Role(Admin, Public, Viewer 등) 뿐만 아니라 Resource, DAG Based Permission에 기반한 Custom Role을 만들 수도 있습니다.
(저희 팀은 현재는 기본 Role에 기반해서 계정을 운영하고 있지만, 추후 액세스 패턴에 맞춰 Custom Role을 만들어 관리할 계획입니다.)&lt;/p&gt;

&lt;p&gt;사용자가 많아지면 Airflow 계정 관리도 중요해집니다. 현재 팀 별로 공용 계정을 운영하고 있는데 팀별 계정의 Role이 실제 사용 대비 여유롭게 권한을 부여한 부분이 있습니다. 이는 추후 문제가 발생했을 때 Audit이 힘들어질 수 있습니다.&lt;/p&gt;

&lt;p&gt;Airflow의 &lt;a href=&quot;https://airflow.apache.org/docs/apache-airflow/stable/security/api.html&quot;&gt;auth_backend&lt;/a&gt;를 활용하면 Airflow Auth API가 아닌 외부 인증 프레임워크를 사용할 수 있습니다. 현재 쏘카에서는 SSO로 &lt;a href=&quot;https://www.keycloak.org/&quot;&gt;Keycloak&lt;/a&gt;을 사용하고 있는데 (&lt;a href=&quot;https://tech.socarcorp.kr/security/2019/07/31/keycloak-sso.html&quot;&gt;참고 글 : Keycloak를 이용한 SSO 구축&lt;/a&gt;).
위 인증 문제를 해결하기 위해 Airflow 사용자 인증을 Keycloak으로 위임하는 방식을 검토 중에 있습니다. 사용자 별로 인증을 관리할 수 있다면 이후 Audit Log를 통해 문제 해결에 도움을 줄 수 있을 것입니다.&lt;/p&gt;

&lt;h2 id=&quot;5-모니터링-고도화하기&quot;&gt;5. 모니터링 고도화하기&lt;/h2&gt;

&lt;h3 id=&quot;51-목적&quot;&gt;5.1. 목적&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;사용자가 직접 DAG 오류에 대응할 수 있도록 합니다.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;사용자가 늘어나고 운영하는 DAG의 개수가 늘어나면서 관리자가 모든 DAG의 맥락을 파악하고 대응하기가 어려워졌습니다. 따라서 DAG 스케줄링, 런타임 오류 등의 1차적 책임은 DAG 사용자(혹은 팀)이 질 수 있도록 하는 것이 중요해졌습니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;관리자가 더 다양한 지표들을 보고 모니터링할 수 있도록 합니다.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Airflow on K8s의 모니터링을 위해선 Airflow의 상태뿐만 아니라 이를 실행하는 K8s 환경도 함께 모니터링할 수 있어야 합니다. 또한 DAG에 대한 통계 정보(시계열 메트릭, 실패 추이 등)를 보고 거시적으로 대응할 수 있도록 하는 것도 중요합니다.&lt;/p&gt;

&lt;h3 id=&quot;52-dag-별-모니터링-담당자-지정&quot;&gt;5.2. DAG 별 모니터링 담당자 지정&lt;/h3&gt;

&lt;p&gt;데이터 파이프라인을 직접 개발하기 위해 Airflow를 사용하는 경우들이 늘어났고, 현재 700개 이상의 DAG이 운영되고 있습니다. 이에 관리자는 모든 DAG을 관리하고 문맥을 파악하는 것이 힘들어졌습니다. 
따라서 1차적으로 DAG 개발/동작에 대한 책임은 DAG 사용자(개발자)가 질 수 있도록 기반 모니터링 환경을 구축하였습니다(기본적인 Airflow 개발/관리 교육과 지원을 가정합니다)&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/advanced-airflow-for-databiz/user-slack-mention.png&quot; alt=&quot;user-slack-mention.png&quot; /&gt;&lt;em&gt;실패한 DAG의 담당자를 태그 하는 알람&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;정상적으로 스케줄 되지 않은 DAG을 모아서 10분에 한 번씩 슬랙 채널에 알림을 주고 있습니다. 이때 즉각적으로 대응할 수 있도록 담당자를 멘션 할 수 있도록 구현하였습니다. 이를 통해 실패한 DAG을 대응하는 속도가 빨라졌으며 관리자도 담당자를 찾고 대응하지 않아도 되기에 관리 비용을 줄일 수 있었습니다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;schedule_interval&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;*/10 * * * *&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;default_args&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;owner&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;grab@socar.kr&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;
		&lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;failed_dag_alert_v2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
		&lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;task&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;get_failed_dag_list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;start_date&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;end_date&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;get_query_datetime&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;session&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sqlalchemy&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;orm&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Session&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;settings&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Session&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;query&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;session&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;query&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DagModel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TaskInstance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;join&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;TaskInstance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TaskInstance&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dag_id&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DagModel&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dag_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;TaskInstance&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;state&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;failed&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TaskInstance&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;end_date&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;start_date&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TaskInstance&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;end_date&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;end_date&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;List&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Tuple&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DagModel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TaskInstance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;query&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;all&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;asdict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;create_payload&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dag_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;task_instance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dag_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;task_instance&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

    &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;task&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;send_slack_notification&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;failed_dags&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;List&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;payloads&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DAGAlertPayload&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;failed_dag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;failed_dag&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;failed_dags&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;payloads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;hook&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;SlackHook&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;slack_conn_id&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;slack_dp_monitoring&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# hook.
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;hook&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;call&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
            &lt;span class=&quot;s&quot;&gt;&quot;chat.postMessage&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;json&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
                &lt;span class=&quot;s&quot;&gt;&quot;channel&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MONITORING_CHANNEL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                &lt;span class=&quot;s&quot;&gt;&quot;attachments&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;
                    &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;color&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;#FF0000&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;blocks&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;payload&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to_attachment_block&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;payload&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;payloads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]}&lt;/span&gt;
                &lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
                &lt;span class=&quot;s&quot;&gt;&quot;username&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;SLACK_USERNAME&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                &lt;span class=&quot;s&quot;&gt;&quot;icon_url&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;SLACK_ICON_URL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;send_slack_notification&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_failed_dag_list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dataclass&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;DAGAlertPayload&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;dag_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;task_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;execution_date&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;owners&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;duration&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;try_number&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;url_link&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;

    &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;property&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;owner_name_in_slack&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;get_linked_text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;link&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Optional&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;....&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;to_attachment_block&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;s&quot;&gt;&quot;type&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;section&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;s&quot;&gt;&quot;text&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
                &lt;span class=&quot;s&quot;&gt;&quot;type&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;mrkdwn&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                &lt;span class=&quot;s&quot;&gt;&quot;text&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;DAG ID: *{self.get_linked_text(text=self.dag_id, link=self.url_link)}* {self.get_linked_text(text='datadog:datadog:', link=self.get_datadog_dashboard_link())}&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Task: {self.task_name}&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Execution Date: {self.execution_date}&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;실행 시간: {self.duration}&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;담당자: &amp;lt;{self.owner_name_in_slack}&amp;gt;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;위와 같이 10분마다 Meta DB에서 실패한 Task를 DAG과 Join 하여 쿼리한 후, 입력된 Owner 정보를 바탕으로 담당자 멘션을 하는 Slack Hook이 호출됩니다.&lt;/p&gt;

&lt;p&gt;슬랙 사용자 멘션을 위해선 유저의 ID 값이 필요합니다. 저희는 DAG의 Owner에 Email 정보를 필수로 받도록 하였으며(Github Action을 통해 PR 단계에서 검증합니다) 슬랙의 &lt;a href=&quot;https://api.slack.com/methods/users.lookupByEmail&quot;&gt;users.lookupByEmail&lt;/a&gt; API를 활용하여 해당 문제를 해결하였습니다.&lt;/p&gt;

&lt;h3 id=&quot;53-관리자-모니터링&quot;&gt;5.3. 관리자 모니터링&lt;/h3&gt;

&lt;p&gt;Airflow는 내부적으로 &lt;code class=&quot;highlighter-rouge&quot;&gt;statsd&lt;/code&gt;를 통해 Metric을 외부로 전송이 가능합니다. 대표적인 Metric으로는 Task Instance의 성공/실패 개수, DAG Run의 Task 실행 시간, DAG Run의 스케줄 딜레이 시간 등이 있습니다. 더 자세한 내용은 &lt;a href=&quot;https://airflow.apache.org/docs/apache-airflow/stable/logging-monitoring/metrics.html&quot;&gt;Airflow 공식 문서&lt;/a&gt;를 참고해 주세요.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/advanced-airflow-for-databiz/airflow-dashboard.png&quot; alt=&quot;airflow-dashboard.png&quot; /&gt;&lt;em&gt;Datadog의 Airflow Dashboard&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;쏘카는 전사 모니터링 툴로 Datadog을 사용하고 있는데, Datadog에서 &lt;a href=&quot;https://docs.datadoghq.com/integrations/airflow/?tab=host&quot;&gt;Airflow Integration&lt;/a&gt; 을 제공하므로 손쉽게 주요 Airflow Metric을 대시보드로 확인할 수 있습니다. 저희는 Airflow 공식 차트를 통해 statsd 설정을 통해 Datadog과 연결하여 사용하고 있습니다. 
Datadog에서 수집한 Metric들을 통해 저희가 집중해서 봐야 할 대상(e.g., 너무 오래 실행 중인 DAG)을 알림으로 만들어 슬랙에서 확인이 가능하도록 하고 있습니다.&lt;/p&gt;

&lt;p&gt;Kuberentes의 경우도 동일하게 Datadog을 활용하여 모니터링하고 있습니다. Kubernetes 전용 대시보드를 통해 기본 상태를 확인하고 있으며, Task의 Log(Remote Logging)가 제대로 남지 않는 문제가 발생했을 때 Pod Log를 보고 있습니다.
현재 Kubernetes를 Managed Service인 GKE(Google Kubernetes Engine)로 사용하고 있는데, 간혹 Node가 갑자기 내려가서 Task가 실패하는 경우들도 발생하고 있습니다. 이 경우 Task의 로그가 제대로 남지 않아서 K8s Node의 상태와 기타 인프라 상황을 종합적으로 검토하여 문제를 해결하려고 시도 중입니다.&lt;/p&gt;

&lt;h2 id=&quot;6-되돌아보기&quot;&gt;6. 되돌아보기&lt;/h2&gt;

&lt;h3 id=&quot;61-좋아진-점&quot;&gt;6.1 좋아진 점&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;기존보다 빠르고 쉽게 원하는 데이터 파이프라인 구축이 가능해졌습니다.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;불편했던 개발 환경과 DAG 개발에 대한 러닝 커브가 높았던 문제가 있었지만, 현재 팀 차원에서 Airflow 사용법에 대한 교육을 진행하고 쉽고 빠르게 개발할 수 있도록 개발 환경을 개선하고 있습니다. &lt;br /&gt;
또한 사용자가 Kubernetes를 알지 못하도록 관심사를 분리하고, 인프라 의존 관계를 걷어내서 사용성을 개선하였습니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;안정적인 Airflow 운영이 가능해졌습니다.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;매니지드 서비스가 아닌 K8s Native 환경에서 Airflow를 운영하기 위해선 신경 써야 할 부분들이 꽤 있습니다. K8s 관리/운영으로 시작해서 KubernetesExecutor의 동작 방식을 이해하고 최적화 방안도 계속 고민해야 합니다. K8s 인프라 환경에 대한 모니터링을 강화하고 있으며, Airflow를 지속적으로 업그레이드하고 유연하게 자원을 분배할 수 있도록 하여 Airflow 운영을 안정적으로 할 수 있게 됐습니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;모니터링 및 보안 환경이 개선되었습니다.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;기존에는 장애가 발생했을 때 K8s Pod이나 Node에 직접 접근해서 Log, Event를 확인했다면, 현재는 모니터링 대시보드를 통해 거시적으로 문제를 파악하고 해결하고 있으며 사용자가 빠르게 장애에 대응할 수 있는 환경을 구축하였습니다.&lt;/p&gt;

&lt;p&gt;또한 다수의 사용자들이 접근하는 만큼 보안에 취약할 수 있기에, 보안 정보들을 중앙 저장소에서 관리할 수 있도록 하고 사용자 교육과 시크릿 탐지 자동화 등 개선 작업을 진행 중에 있습니다.&lt;/p&gt;

&lt;h3 id=&quot;62-발전해야-할-점&quot;&gt;6.2 발전해야 할 점&lt;/h3&gt;

&lt;p&gt;Airflow를 Docker Compose 환경으로 옮기면서 확실한 이점들이 있지만 아직까지 해결해야 하는 문제들도 있습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;M1 호환 문제 : 데이터 본부 팀원들이 사용하는 MacOS는 Intel과 M1 두 가지로 나뉩니다. 기존의 Intel은 Docker 호환에 크게 문제가 없지만 M1의 경우 특정 부분에서 호환이 안되는 이슈가 있으며, Airflow 의존성 일부가 제대로 설치되지 않는 문제들이 있습니다.&lt;/li&gt;
  &lt;li&gt;추상화 개선 : 로컬 환경 사용에 대해 추상화를 해두었지만, 사용자들이 Python 환경(&lt;code class=&quot;highlighter-rouge&quot;&gt;poetry&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;pyenv&lt;/code&gt;)과 Docker에 대해 알고 있어야 하며 파이썬 버전 이슈나 컨테이너 미 종료 이슈 등을 마주칠 때가 있어 해결할 필요가 있습니다.&lt;/li&gt;
  &lt;li&gt;의존성 간소화 : 파이썬 의존성을 하나 설치해서 운영까지 올리기 위해서는 3번의 의존성 설치가 필요합니다. Airflow 런타임에서는 Docker Compose에 의존성을 명시해 줘야 하고, 개발하는 IDE에서 Type Hinting과 Auto Complete를 위해서 로컬 가상환경에 의존성을 설치해 줘야 합니다. 또 운영 환경에 배포할 때는 Airflow 이미지 Dockerfile에 의존성을 추가해 준 후 CI 파이프라인을 거쳐야 합니다. 따라서 이런 복잡한 의존성 관리 방식을 간소화할 필요가 있습니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이 외에도 보안을 강화하는 동시에 사용성을 해치지 않는 방향으로 Secret Manager 사용 정책과 가이드를 세워야 하며 종종 Pod 로그를 남기지 않고 Task가 실패하는 이슈들이 있어 모니터링 환경을 더 개선하고 알림 정책을  개선할 필요가 있습니다.&lt;/p&gt;

&lt;h3 id=&quot;63-마무리&quot;&gt;6.3 마무리&lt;/h3&gt;

&lt;p&gt;위와 같은 시도들을 통해 더 많은 사용자가 Airflow를 사용하여 직접 데이터 파이프라인을 구축할 수 있도록 하였으며 동시에 시스템의 신뢰성과 안전성을 높여가고 있습니다. 
Airflow 로컬 환경을 시작으로 나중에는 Airflow를 모르더라도 사용자가 손쉽게 파이프라인을 구축할 수 있는 사내 플랫폼을 만들 계획입니다.&lt;/p&gt;

&lt;p&gt;Airflow는 배치 데이터 파이프라인의 중추인 만큼, 중요하게 관리되어야 합니다. 데이터 플랫폼 팀은 계속해서 사용 패턴에 맞게 Airflow 플랫폼을 개선해 나갈 것이며 궁극적으로 쏘카의 모든 구성원들이 손쉽게 데이터 파이프라인을 구축하여 데이터를 활용할 수 있도록 하겠습니다.&lt;/p&gt;

&lt;p&gt;많은 시행착오들을 거치며 Airflow를 함께 고도화하고 있는 험프리, 디니, 루디, 피글렛, 토마스 그리고 모든 데이터 비즈니스 본부 분들에게 감사드립니다.&lt;/p&gt;</content><author><name>그랩</name></author><category term="data" /><category term="data" /><category term="data engineering" /><category term="airflow" /><category term="data platform" /><summary type="html">안녕하세요. 데이터 플랫폼 팀의 그랩입니다.</summary></entry><entry><title type="html">신입 백엔드 개발자의 우당탕탕 엔지니어링 온보딩팀 교육 후기</title><link href="https://tech.socarcorp.kr/dev/2022/10/17/onboarding-service-engineering.html" rel="alternate" type="text/html" title="신입 백엔드 개발자의 우당탕탕 엔지니어링 온보딩팀 교육 후기" /><published>2022-10-17T00:00:00+00:00</published><updated>2022-10-17T00:00:00+00:00</updated><id>https://tech.socarcorp.kr/dev/2022/10/17/onboarding-service-engineering</id><content type="html" xml:base="https://tech.socarcorp.kr/dev/2022/10/17/onboarding-service-engineering.html">&lt;style scoped=&quot;&quot;&gt;
    thead {
    font-size: 15px;
    }
    tbody {
    font-size: 13px;
    }
&lt;/style&gt;

&lt;p&gt;안녕하세요! 올해 3월부로 쏘카 백엔드 엔지니어로 합류한 코기(이해원)입니다.&lt;/p&gt;

&lt;p&gt;쏘카 서비스 엔지니어링(Service Engineering) 본부에 입사하면 엔지니어링 온보딩 팀으로 소속되어 온보딩 과정을 밟게 됩니다. 입사 후 받은 온보딩 교육이 저를 지금의 모습으로 성장시켜주는데 가장 큰 도움이 되었다고 생각합니다. 
그 이유를 크게 &lt;strong&gt;세 가지&lt;/strong&gt;로 함축해 봤습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;쏘카에서 사용 중인 &lt;code class=&quot;highlighter-rouge&quot;&gt;Kotlin, Spring Boot, AWS&lt;/code&gt; 와 같은 언어 / 기술과 &lt;code class=&quot;highlighter-rouge&quot;&gt;Datadog, BuddyWorks, ArgoCD, Rancher&lt;/code&gt; 등 여러 개발 도구에 대해 교육받고 실습하며 학습할 기회를 제공받았습니다.&lt;/li&gt;
  &lt;li&gt;실제로 상용화하는 프로젝트를 동기끼리 0(Zero)부터 시작해서 만들어보고 이에 대한 피드백을 받으며 학습하고 성장할 수 있었습니다.&lt;/li&gt;
  &lt;li&gt;서비스 엔지니어링 본부의 동료들과 친해지고 쏘카에 더욱 빠르게 적응할 수 있었습니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;쏘카에서 온보딩 교육을 어떻게 진행&lt;/strong&gt;하는지, 또 &lt;strong&gt;온보딩 교육을 통해 무엇을 배우고 얼마나 더 성장할 수 있었는지&lt;/strong&gt; 알리고자 이 글을 작성하게 되었습니다. 
아래에 해당하신다면 이 글을 끝까지 읽어주시면 좋습니다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;쏘카의 엔지니어링 온보딩 과정이 궁금하신 분&lt;/li&gt;
  &lt;li&gt;소프트웨어 엔지니어를 준비하고 계신 분&lt;/li&gt;
  &lt;li&gt;쏘카의 기술 문화가 궁금하신 분&lt;/li&gt;
  &lt;li&gt;동료들과 함께 학습하며 기술적인 성장을 해나가고 싶은 분&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;목차&quot;&gt;목차&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;#1-서비스-엔지니어링-본부와-엔지니어링-온보딩-팀이란&quot;&gt;서비스 엔지니어링 본부와 엔지니어링 온보딩 팀이란?&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#2-온보딩-강의&quot;&gt;온보딩 강의&lt;/a&gt;&lt;br /&gt;
 2.1. &lt;a href=&quot;#21-프로그래머의-기본--쏘카의-service-architecture&quot;&gt;프로그래머의 기본 &amp;amp; 쏘카의 Service Architecture&lt;/a&gt;&lt;br /&gt;
 2.2. &lt;a href=&quot;#22-backend-강의--쏘카의-개발-문화&quot;&gt;BackEnd 강의 &amp;amp; 쏘카의 개발 문화&lt;/a&gt;&lt;br /&gt;
 2.3. &lt;a href=&quot;#23-frontend-강의--쏘카의-infra와-db&quot;&gt;FrontEnd 강의 &amp;amp; 쏘카의 Infra와 DB&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#3-dogfooding-project&quot;&gt;Dogfooding Project&lt;/a&gt;&lt;br /&gt;
 3.1. &lt;a href=&quot;#31-dogfooding이란&quot;&gt;Dogfooding 이란?&lt;/a&gt;&lt;br /&gt;
 3.2. &lt;a href=&quot;#32-kick-off-미팅&quot;&gt;Kick-off 미팅&lt;/a&gt;&lt;br /&gt;
 3.3. &lt;a href=&quot;#33-프로젝트-진행&quot;&gt;프로젝트 진행&lt;/a&gt;&lt;br /&gt;
 3.4. &lt;a href=&quot;#34-스프린트-데모&quot;&gt;스프린트 데모&lt;/a&gt;&lt;br /&gt;
 3.5. &lt;a href=&quot;#35-회고-및-플래닝&quot;&gt;회고 및 플래닝&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#4-동료와의-교류-및-스터디&quot;&gt;동료와의 교류 및 스터디&lt;/a&gt;&lt;br /&gt;
 4.1. &lt;a href=&quot;#41-서비스-엔지니어링-본부-타운홀-미팅-자기소개&quot;&gt;서비스 엔지니어링 본부 타운홀 미팅 자기소개&lt;/a&gt;&lt;br /&gt;
 4.2. &lt;a href=&quot;#42-쏘풍-데이&quot;&gt;쏘풍데이&lt;/a&gt;&lt;br /&gt;
 4.3. &lt;a href=&quot;#43-스터디&quot;&gt;스터디&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#5-온보딩-졸업-후-각자-버킷으로&quot;&gt;온보딩 졸업 후 각자 버킷으로&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#6-나날이-발전하는-온보딩-교육&quot;&gt;나날이 발전하는 온보딩 교육&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#7-나에게-온보딩-교육이란&quot;&gt;나에게 온보딩 교육이란?&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#8-마치며&quot;&gt;마치며&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;1-서비스-엔지니어링-본부와-엔지니어링-온보딩-팀이란&quot;&gt;1. 서비스 엔지니어링 본부와 엔지니어링 온보딩 팀이란?&lt;/h2&gt;

&lt;p&gt;쏘카의 서비스 엔지니어링(Service Engineering) 본부는 &lt;strong&gt;‘쏘카를 이용하는 고객들에게 더 나은 가치를 제공하기 위해 새로운 서비스를 만들고 기존 서비스들을 안정적으로 운영하는 모든 것을 개발하고 책임진다.’&lt;/strong&gt;라는 미션 아래 쏘카 서비스와 관련된 소프트웨어를 전반적으로 담당하는 조직입니다.&lt;/p&gt;

&lt;p&gt;서비스 엔지니어링 본부는 &lt;strong&gt;‘버킷’&lt;/strong&gt; 을 활용하여 서비스(또는 도메인) 단위로 쪼개서 &lt;code class=&quot;highlighter-rouge&quot;&gt;MSA(MicroService Architecture)&lt;/code&gt;를 추진하고 있습니다. 기본적으로 BackEnd, FrontEnd 등 직군 별로 팀이 있고 그 팀원들이 도메인별로 각자 다른 버킷에 포함되어 버킷 내 서비스를 담당하고 있습니다. 이에 더해 비슷한 버킷을 그룹 단위로 묶어 그룹 별 리더가 총괄하는 구조로 운영되고 있습니다.&lt;/p&gt;

&lt;p&gt;버킷의 업무는 빠르게 변화하는 시장에 대응하기 위해 &lt;strong&gt;MVP 완성을 목표로 하는 스프린트 방식으로 진행&lt;/strong&gt;됩니다. 각 버킷 별로 차이가 있을 수 있지만 보통 2주 또는 3주 내외입니다.&lt;/p&gt;

&lt;p&gt;현재 신규 사업 또는 서비스의 확장에 힘을 실어주기 위해 버킷이 계속해서 만들어지고 있습니다. 게시글 작성 시점을 기준으로 운영되는 11개의 버킷은 다음과 같습니다.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;&lt;center&gt;버킷명&lt;/center&gt;&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;&lt;center&gt;업무&lt;/center&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Core Platform Bucket&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;예약 및 성능 개선&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Car Sharing Bucket(B2C)&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;카셰어링 서비스(왕복, 존편도, 부름, 페어링)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Core Experience Bucket&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;쏘카 앱/웹(Android/iOS, Web)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Accounts Bucket&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;회원 관련(가입, 탈퇴, 로그인, 휴면, 인증 등)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Payment Bucket&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;결제 / 정산 / 크레딧&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Operation Framework Bucket&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;백오피스&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Asset Bucket&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;운영 시스템(사고 관리, 전 관리) / 차량 자원관리자&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Marketing Bucket&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;패스포트 / 마케팅(이벤트, 알림, 쿠폰, 타게팅)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;B2B Bucket&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;쏘카 비즈니스(웹, 멤버십, 플랜)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;FMS Bucket&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;FMS(차량 관제 시스템)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;유레카 Bucket&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;쏘카 통합 차량관리 서비스(세차 관리, 소모품 교체 등)&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;본부 내에는 버킷 외에도 &lt;strong&gt;EM 유닛,&lt;/strong&gt; &lt;strong&gt;QA 팀, Cloud DB/Infra 팀, iOS/Android 팀, Web 팀, 정보 보안팀, LiveOps 팀, 엔지니어링 온보딩 팀&lt;/strong&gt;이 속해있고, 본부의 미션을 위해 각자 담당하는 업무를 열심히 수행하고 있습니다.&lt;/p&gt;

&lt;p&gt;엔지니어링 온보딩 팀은 쏘카 도메인 온보딩 및 기술 온보딩 교육을 통해 쏘카에 새로 합류한 엔지니어의 빠른 적응을 돕습니다.  &lt;br /&gt;
엔지니어링 온보딩 팀에서 온보딩 교육을 마치게 되면 각자 희망하는 버킷을 작성한 후 이를 최대한 반영할 수 있도록 조율합니다. 그렇게 버킷 배정을 받아 각 버킷으로 이동해서 주어진 서비스 개발 및 운영을 시작합니다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;2-온보딩-강의&quot;&gt;2. 온보딩 강의&lt;/h2&gt;

&lt;p&gt;온보딩 커리큘럼은 크게 &lt;strong&gt;온보딩 강의&lt;/strong&gt;와 &lt;strong&gt;Dogfooding Project&lt;/strong&gt;으로 나뉩니다.
온보딩 강의는 1주 단위로 총 3개의 파트가 진행되고 이후 Dogfooding Project를 2~3주간 수행합니다. 온보딩 당시 전사 재택 기간이라 강의는 모두 비대면으로 진행되었고 추후 녹화본이 공유되었습니다.&lt;/p&gt;

&lt;p&gt;이때, “FrontEnd 개발 직무와 BackEnd 개발 직무 별로 교육의 차이가 있을까?”라는 의문점이 생길 수 있습니다. 정답은 &lt;strong&gt;‘공통 교육은 필수이고, 다른 직무의 교육은 선택’&lt;/strong&gt;입니다. 
동기 중 BackEnd 개발하는 분들은 FrontEnd 교육도 수강했는데 이후 Dogfooding 프로젝트 진행에 있어 BackEnd ↔️ FrontEnd 간 원활한 협업에 도움이 되었다고 합니다.&lt;/p&gt;

&lt;p&gt;이후 작성한 내용은 주 단위로 나눠서 작성했습니다.&lt;/p&gt;

&lt;h3 id=&quot;21-프로그래머의-기본--쏘카의-service-architecture&quot;&gt;2.1. 프로그래머의 기본 &amp;amp; 쏘카의 Service Architecture&lt;/h3&gt;

&lt;p&gt;1주 차 강의는 &lt;strong&gt;프로그래머의 기본과 쏘카 서비스 아키텍처&lt;/strong&gt;가 중점입니다.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;&lt;center&gt;주제&lt;/center&gt;&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;&lt;center&gt;내용&lt;/center&gt;&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;소속&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;강사&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;쏘카 Business Introduction&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;쏘카는 어떤 일들을 하고 있을까요?&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;EM 유닛&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;케이제이&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;프로그래머로 산다는 것&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;어떤 개발자가 좋은 개발자인지 함께 고민해 보아요.&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;CTO&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;람다&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Service Engineering - How To Work&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;서비스 엔지니어링 본부에서 어떻게 일하고 있을까요?&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;EM 유닛&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;케이제이&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;90 Days Planning 작성 가이드&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;90 Days Planning 이란 무엇이고, 어떻게 작성하면 될까요?&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;EM 유닛&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;케이제이&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Service Architecting Model&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;현재 서비스의 Architecture와 추후 지향하는 방향을 소개합니다.&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;SE 본부장&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;아나킨&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Service Engineering - How To Work (Jira)&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;쏘카가 사용하고 있는 Jira의 기초 / 심화 기능 사용법에 대해 설명합니다.&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;QA 팀&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;딕키&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Service Architecture AS-IS&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;쏘카의 카셰어링 사례를 통해 현재와 미래의 쏘카 Architecture를 공유합니다.&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Sharing 그룹장&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;브래드&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;img src=&quot;/img/onboarding-service-engineering/6.png&quot; alt=&quot;람다가 생각하는 '좋은 프로그래머'&quot; /&gt;&lt;em&gt;람다가 생각하는 ‘좋은 프로그래머’&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;1주 차 강의 중 가장 인상 깊었던 강의는 람다의 &lt;strong&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;프로그래머로 산다는 것&lt;/code&gt;&lt;/strong&gt; 입니다. 제가 지금까지는 단순히 개발만 잘하는 프로그래머가 되고 싶었는데 이 강의를 통해 &lt;strong&gt;좋은 프로그래머&lt;/strong&gt;로 성장해나가는 명확한 목표를 설정할 수 있었습니다. 덧붙여서 &lt;strong&gt;지식 공유 및 협업&lt;/strong&gt; 을 위해 고민하고 실천해나가는 자세를 가지고 쏘카에서 열심히 해야겠다는 열의도 생기게 되었습니다.&lt;/p&gt;

&lt;p&gt;강의 중 &lt;strong&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;90 Days Planning 작성 가이드&lt;/code&gt;&lt;/strong&gt; 는 서비스 엔지니어링 본부에서 시행하고 있는 개개인 별 분기 단위 마일스톤을 작성하는 것으로, 자기발전을 위한 업무, 개인 활동 등 정량적 목표를 자유롭게 적을 수 있습니다. 
또한 작성했던 계획의 실천을 위해 TL(Tech Lead)에게 공유하고 미팅하면서 업무 일정을 조율할 수 있습니다. &lt;strong&gt;‘주도적으로 일하고 성장하기’&lt;/strong&gt;의 목표를 지닌 ‘90 Days Planning’ 덕분에 작성했던 마일스톤을 자유의지로 실천하려는 노력이 있었고, 현재의 저는 작성하기 이전보다 한 층 더 성장한 것을 체감하고 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/onboarding-service-engineering/5.png&quot; alt=&quot;3Q 90 Days Planning 작성한 내용&quot; /&gt;&lt;em&gt;3Q 90 Days Planning 작성한 내용&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;이전까지는 그저 시키는 업무와 주어진 범위까지만 생각하며 일해왔었는데 작성한 planning을 가지고 TL 미팅을 하면서 &lt;strong&gt;‘이번 분기에는 내가 어떠한 업무를 왜 하는지, 어디까지 하고 싶은지’&lt;/strong&gt;를 객관적으로, 명확하게 파악할 수 있었습니다. 덕분에 플래닝 한 업무의 우선순위를 부여하고, 저의 일정과 능력에 맞게 스케줄링(Scheduling) 하는 주도적인 자세로 일할 수 있었습니다.&lt;br /&gt;
이에 더해, &lt;strong&gt;‘Personal Growth’&lt;/strong&gt;를 작성하며 &lt;strong&gt;‘제 자신, 제 역량을 성장시키기 위해’&lt;/strong&gt; 무엇을 하면 좋을지 고민해 볼 수 있었습니다. 그렇게 작성한 목표 달성을 위해 업무 시간 중 일부를 사용하도록 TL이 장려해서 입사 후부터 걱정했었던 개인의 성장을 해결하고 있습니다.&lt;/p&gt;

&lt;h3 id=&quot;22-backend-강의--쏘카의-개발-문화&quot;&gt;2.2. BackEnd 강의 &amp;amp; 쏘카의 개발 문화&lt;/h3&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;&lt;center&gt;주제&lt;/center&gt;&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;&lt;center&gt;내용&lt;/center&gt;&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;소속&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;강사&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Service Development Introduction&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;쏘카의 Service Repository 구조, 개발 환경(Dev, QA/Stage, Production), 개발부터 배포까지의 과정을 소개합니다.&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Car Sharing&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;믈브&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;BackEnd  Running Services In The Local&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;실제 운영 중인 쏘카 서버의 Repository를 받아 Local 환경에서 실행하기 위한 과정을 환경설정과 함께 실습해 봅니다.&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Car Sharing&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;믈브&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Github and PR and Reviewing&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;쏘카의 Github 관리 및 협업(PR / Code Review / Merge) 방식을 듣고 실습하는 시간입니다.&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Car Sharing&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;믈브&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;BackEnd - Coding: Convention and Styles&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Kotlin 기본 코딩 가이드 및 IntelliJ Plugin(+ Gradle) 활용 방법을 설명합니다.&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Car Sharing&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;믈브&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;BackEnd - Tests And Testable Code&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;테스팅에 대해 배우고, 실습을 통해 테스트 코드를 작성해봅니다.&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;B2B&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;카이&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Homework&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;쏘카 서버의 Repository에서 서비스 하나를 선택해서 Test Code 작성 / PR / Code Review 해보기.&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;BackEnd - CI/CD&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;품질관리 및 배포/운영까지 함께하는 CI/CD와 쏘카는 어떤 방식인지 설명합니다.&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Marketing&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;도가, 브루스&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;BackEnd - Datadog &amp;amp; Monitoring&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;쏘카 서버를 모니터링하고 관리할 수 있는 Datadog, 그 외 모니터링 도구에 대해 설명합니다.&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Marketing&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;도가, 브루스&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;BackEnd - Performance Testing&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;내가 만든 서비스가 얼마까지 버틸 수 있는지 알기 위해 수행하는 Performance Testing을 배웁니다.&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Marketing&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;도가, 브루스&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;2주 차에는 BackEnd 기술 관련 강의와 함께 쏘카의 협업 문화와 개발 문화를 배울 수 있었습니다. 이와 더불어 개발 환경 설정까지 진행했는데 그 덕분에 이론으로 배운 것을 실제로 연습해 볼 수 있었습니다.&lt;/p&gt;

&lt;p&gt;가장 흥미로웠던 강의는 &lt;strong&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;BackEnd - Datadog &amp;amp; Monitoring&lt;/code&gt;&lt;/strong&gt; 과 &lt;strong&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;BackEnd - Performance Testing&lt;/code&gt;&lt;/strong&gt;, 마지막으로 &lt;strong&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;BackEnd - Tests And Testable Code&lt;/code&gt;&lt;/strong&gt; 였습니다.
&lt;img src=&quot;/img/onboarding-service-engineering/7.png&quot; alt=&quot;쏘카의 Datadog Profiling 일부 화면&quot; /&gt;&lt;em&gt;쏘카의 Datadog Profiling 일부 화면&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;도가와 브루스가 해주신 &lt;strong&gt;Datadog&lt;/strong&gt; 강의를 통해 다음과 같은 다양한 Datadog 활용 사례를 배울 수 있었습니다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;쏘카 서버 대시보드&lt;/li&gt;
  &lt;li&gt;Error 발생 시 Slack / Opsgenie 툴과 연동해서 alert을 받을 수 있는 Monitors(APM / Metric 등)&lt;/li&gt;
  &lt;li&gt;Kubernetes Container / Pod / Cluster Monitoring&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/img/onboarding-service-engineering/8.png&quot; alt=&quot;Locust를 활용한 Performance Testing 결과 지표&quot; /&gt;&lt;em&gt;Locust를 활용한 Performance Testing 결과 지표&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Locust&lt;/code&gt;를 이용한 Performance Testing을 통해 실제 내가 만든 서비스가 쏘카 서버에서 버틸 수 있는지, 트래픽을 얼마까지 받아낼 수 있는지 등 성능을 측정해 볼 수 있어 흥미로웠습니다.&lt;/p&gt;

&lt;p&gt;마지막으로 &lt;strong&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;BackEnd - Tests And Testable Code&lt;/code&gt;&lt;/strong&gt; 강의는 TDD 방식 및 테스트 코드 작성의 중요성을 다시금 상기시키게 해준 강의였습니다. 
특히 JUnit의 변천사도 설명해 주시고 실제 쏘카에서 사용하는 컨벤션에 맞게 Unit Test와 Integration Test를 만들어볼 수 있었습니다.&lt;/p&gt;

&lt;h3 id=&quot;23-frontend-강의--쏘카의-infra와-db&quot;&gt;2.3. FrontEnd 강의 &amp;amp; 쏘카의 Infra와 DB&lt;/h3&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;&lt;center&gt;주제&lt;/center&gt;&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;&lt;center&gt;내용&lt;/center&gt;&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;소속&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;강사&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;FrontEnd  Coding: Convention And Styles&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Backoffice 개발 역량을 위한 FrontEnd 기본 코딩에 대해 설명합니다.&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Web 팀&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;라파엘&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;FrontEnd - Package Management&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;npm이 무엇인지 설명하고, FrontEnd의 공통 npm module 사용법을 실습합니다.&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;B2B&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;블랑&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;FrontEnd - Running Services In The Local&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;local 환경에서 BackEnd 서비스와 직접 실행해 연동하고, 결과를 확인해 보는 실습하는 시간입니다.&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Car Sharing&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;리스본&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;FrontEnd - CI/CD&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;FrontEnd의 CI/CD에 대해 설명을 듣고, 개발부터 코드 리뷰 / 배포까지 직접 실습하는 시간입니다.&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Marketing&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;버틀러&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;AWS And GCP In SOCAR&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;AWS와 GCP를 쏘카에서는 어떻게 활용하는지 소개합니다.&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;에코&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;(Kubernetes) How To Use In SOCAR&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Kubernetes(K8S)의 기본 개념과 원리에 대해 설명을 듣고, 실습을 통해 명령어를 익힙니다.&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Core Platform&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;코알라&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;SOCAR Network&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;쏘카 서버의 Network Architecture에 대해 소개합니다.&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Cloud Infra 팀&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;로원&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;SOCAR Database Structure&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;AWS RDS를 활용하는 쏘카의 Database Architecture에 대해 소개합니다.&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Cloud DB 팀&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;제이든&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;DB - SQL Basic Grammar&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;실제 쏘카에서 활용하는 SQL 문법을 보고 작성해 보는 시간입니다.&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Cloud DB 팀&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;알티&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;마지막 3주 차 교육은 FrontEnd 관련 강의가 절반을 차지했습니다. 서버 개발자라고 해서 BackEnd만 알고 있는 것보다 쏘카에서의 FrontEnd 개발 문화도 알아두는 것이 이후 협업에 있어 큰 도움이 될 것이라고 판단해서 전부 수강했습니다. 
쏘카에서 FrontEnd 개발은 주로 &lt;code class=&quot;highlighter-rouge&quot;&gt;react&lt;/code&gt;와 &lt;code class=&quot;highlighter-rouge&quot;&gt;typescript&lt;/code&gt; 를 사용하는데 저는 개인적으로 &lt;code class=&quot;highlighter-rouge&quot;&gt;Vue.js&lt;/code&gt; 를 사용해 본 경험이 있어 강의를 이해하기 한결 수월했고 관심 있게 수강했습니다.&lt;/p&gt;

&lt;p&gt;그리고 인프라 네트워크 구조와 &lt;code class=&quot;highlighter-rouge&quot;&gt;AWS RDS&lt;/code&gt; 를 사용하는 쏘카의 DB 구조도를 보며 쏘카 전체 DB 구조에 대해 설명을 들었는데 관련 지식이 부족하다보니 이해하지 못하고 놓친 부분이 있었습니다. 그래서 강의가 끝나고 개인적으로 공부하며 DB와 인프라 구조를 이해하려고 노력했습니다.&lt;/p&gt;

&lt;p&gt;이렇게 총 3주간의 온보딩 강의 수강이 끝나고 &lt;del&gt;(쉴 틈 없이)&lt;/del&gt; 다음 온보딩 과정인 &lt;strong&gt;‘Dogfooding Project’&lt;/strong&gt;를 시작하게 되었습니다!&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;3-dogfooding-project&quot;&gt;3. Dogfooding Project&lt;/h2&gt;

&lt;h3 id=&quot;31-dogfooding-이란&quot;&gt;3.1. Dogfooding 이란?&lt;/h3&gt;

&lt;p&gt;대략 3주간의 개발 교육을 마친 후에 온보딩 동기 4명이 한 팀을 이뤄 Dogfooding Project를 수행하게 됩니다. 
Dogfooding은 &lt;strong&gt;‘자사의 제품(소프트웨어)을 직원들이 직접 사용해 보고 개선하는 것’&lt;/strong&gt; 을 뜻합니다. 이 프로젝트를 수행하는 취지는 크게 세 가지입니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;피드백을 통해 소프트웨어 개발 기술을 객관적으로 측정하고 성장한다.&lt;/li&gt;
  &lt;li&gt;쏘카의 서비스를 파악하고 개선점을 찾아 더욱 서비스를 발전시킨다.&lt;/li&gt;
  &lt;li&gt;실제 쏘카 서비스에 상용화되기 때문에 프로젝트에 대한 열정과 동기가 생긴다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;저희가 수행하게 된 Dogfooding Project의 명칭은 ‘&lt;strong&gt;RFC103 - CDN 및 업로드 관리’&lt;/strong&gt;입니다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;RFC(Request For Comments)란?&lt;/strong&gt; &lt;br /&gt; 
새로운 연구 / 기술 / 서비스를 작성하고 동료들에게 공유하며 의견을 받기 위한 문서를 뜻합니다. 의견을 바탕으로 최종 승인된 문서는 더 이상의 수정이 불가능하고 공식적인 표준 가이드로 활용됩니다.)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;이 프로젝트의 목적은 다음과 같습니다.
&lt;img src=&quot;/img/onboarding-service-engineering/9.png&quot; alt=&quot;‘RFC103 - CDN 및 업로드 관리’ 프로젝트 목표&quot; /&gt;&lt;em&gt;‘RFC103 - CDN 및 업로드 관리’ 프로젝트 목표&lt;/em&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;AS-IS : 현재 외부로의 노출 또는 제공이 필요한 디지털 에셋(이미지, PDF 파일 등)을 제공하는 일관된 방식이 존재하지 않는 상황입니다.&lt;/li&gt;
  &lt;li&gt;TO-BE : &lt;strong&gt;디지털 에셋을 관리하는 독립적인 시스템을 구축&lt;/strong&gt;하여 정해진 규칙과 규격에 맞게 관리할 수 있습니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;애자일 방식으로 1주 단위의 스프린트 3회에 걸쳐 총 3주간 진행된 이 프로젝트의 결과부터 말씀드리자면, &lt;strong&gt;최종 데모까지 성공적으로 마무리했습니다.&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&quot;32-kick-off-미팅&quot;&gt;3.2. Kick-Off 미팅&lt;/h3&gt;

&lt;p&gt;프로젝트 일정 첫날 오전에는 &lt;strong&gt;Dogfooding 사전 미팅&lt;/strong&gt;을 통해 작성자인 아나킨에게 전체적인 설명을 듣고 &lt;strong&gt;Kick-Off 미팅&lt;/strong&gt;을 가졌습니다. Kick-Off 미팅에서 제일 중점으로 둔 부분은 &lt;strong&gt;‘협업을 위한 프로젝트 싱크 업(Sync-Up)’&lt;/strong&gt;입니다.
서로가 똑같이 프로젝트에 대해 이해하고 목표를 수립해야 원활한 협업을 할 수 있다고 판단하여 아래와 같은 세 가지 어젠다를 가지고 미팅을 진행했습니다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;구현해야 할 기능을 RFC 문서에서 도출하여 유저 스토리를 작성하고 스토리 별 FrontEnd / BackEnd 필요한 개발 사항을 정리했으며, 프로젝트 성공 목표와 함께 전반적인 내용을 싱크 업 했습니다.&lt;/li&gt;
  &lt;li&gt;언어 / 프레임워크 / 라이브러리뿐 아니라 서버 환경 구성 및 시스템에 필요한 AWS 서비스를 리스트 업(List-Up) 했습니다.&lt;/li&gt;
  &lt;li&gt;주어진 일정을 파악하여 전체적인 플래닝을 세웠고 스프린트 단위 선정 및 스프린트 별 목표를 설정했습니다.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;BackEnd는 현재 쏘카 전반적으로 사용하고 있는 언어인 &lt;code class=&quot;highlighter-rouge&quot;&gt;Kotlin&lt;/code&gt; 과 &lt;code class=&quot;highlighter-rouge&quot;&gt;Spring Boot framework&lt;/code&gt; 를 사용했습니다. 이에 더해 디지털 에셋을 저장하기 위해 &lt;code class=&quot;highlighter-rouge&quot;&gt;AWS S3&lt;/code&gt;, 디지털 에셋을 표면적으로 노출시키기 위해 &lt;code class=&quot;highlighter-rouge&quot;&gt;AWS CloudFront&lt;/code&gt;, 업로드 / 삭제 와 같이 디지털 에셋의 변경 이력을 기록해두기 위해 &lt;code class=&quot;highlighter-rouge&quot;&gt;Amazon DynamoDB&lt;/code&gt;를 사용하기로 결정했습니다. 저로서는 실무에서 처음 접해보는 서비스였기 때문에, 퇴근 후에 개인적으로 공부하며 이를 활용할 수 있게 노력했습니다.&lt;/p&gt;

&lt;h3 id=&quot;33-프로젝트-진행&quot;&gt;3.3. 프로젝트 진행&lt;/h3&gt;

&lt;p&gt;이후에는 첫날에 협의한 일정대로 프로젝트를 진행했습니다. &lt;code class=&quot;highlighter-rouge&quot;&gt;Jira&lt;/code&gt;에서 스프린트를 생성하고 각자 맡은 업무를 티켓으로 만들어 주도적으로 개발했습니다. 그리고 매일 정해진 시간에 데일리 스크럼을 하면서 그날의 업무와 개발 관련 협의가 필요한 사항을 공유했습니다.&lt;/p&gt;

&lt;p&gt;예를 들면 &lt;strong&gt;코딩 컨벤션, 프로젝트 구조 설계, 유저 시나리오, API 명세, CI/CD 환경설정&lt;/strong&gt; 등이 있었는데 스크럼 이후 미팅을 통해 가장 효율적이고 최적의 방안을 도출했습니다. 물론 미팅마다 회의록 및 협의 결과를 노션 문서에 기록했습니다.&lt;/p&gt;

&lt;p&gt;프로젝트에서 직무 별 수행했던 개발 사항은 다음과 같습니다.&lt;br /&gt;
(작성한 순서대로 순차적으로 수행하진 않았습니다.)&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;BackEnd - 코기, 이누, 키이라
    &lt;ul&gt;
      &lt;li&gt;Amazon S3 연동 환경 구축 / 에셋 파일 S3 버킷 업로드&lt;/li&gt;
      &lt;li&gt;Git Action / Husky / Ktfmt 설정&lt;/li&gt;
      &lt;li&gt;에셋 파일 삭제&lt;/li&gt;
      &lt;li&gt;에셋 파일 로그 조회&lt;/li&gt;
      &lt;li&gt;DynamoDB, CloudFront 생성 및 연동 / DynamoDB 활용해서 에셋 파일 로그 저장&lt;/li&gt;
      &lt;li&gt;에셋 파일 조회&lt;/li&gt;
      &lt;li&gt;Testcontainer, Localstack 모듈 구현&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;FrontEnd - 도시
    &lt;ul&gt;
      &lt;li&gt;Wireframe 작성 / FrontEnd 개발 환경 구현&lt;/li&gt;
      &lt;li&gt;디자인 토큰 정의 및 설정&lt;/li&gt;
      &lt;li&gt;UI 단위 컴포넌트 및 관련 기능 구현&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;저희 모두 테스트 코드 작성에 진심이었기 때문에 작업 기간 중 절반은 거의 테스트 코드 작성에 할애했습니다. Unit Test 관련해서 Service는 &lt;code class=&quot;highlighter-rouge&quot;&gt;kotest&lt;/code&gt;의  &lt;code class=&quot;highlighter-rouge&quot;&gt;AnnotationSpec&lt;/code&gt; 을, Controller는 &lt;code class=&quot;highlighter-rouge&quot;&gt;MockMvc&lt;/code&gt;를 사용했습니다. 
이에 더해 AmazonS3 Integration Test를 위해서 &lt;code class=&quot;highlighter-rouge&quot;&gt;Testcontainer&lt;/code&gt;로  &lt;code class=&quot;highlighter-rouge&quot;&gt;Localstack&lt;/code&gt; 모듈을 사용하기도 했습니다.&lt;/p&gt;

&lt;h3 id=&quot;34-스프린트-데모&quot;&gt;3.4. 스프린트 데모&lt;/h3&gt;

&lt;p&gt;이렇게 정신없이 첫 스프린트를 마친 후 &lt;code class=&quot;highlighter-rouge&quot;&gt;스프린트 데모&lt;/code&gt;와 &lt;code class=&quot;highlighter-rouge&quot;&gt;스프린트 회고 및 플래닝&lt;/code&gt; 시간이 되었습니다.&lt;/p&gt;

&lt;p&gt;총 3번의 데모를 통해 아래 리스트와 같이 정의했던 &lt;strong&gt;프로젝트의 인수 조건(Acceptance Criteria)&lt;/strong&gt;에 대한 개발을 시연했습니다. 데모 시연은 도시가 &lt;code class=&quot;highlighter-rouge&quot;&gt;localhost&lt;/code&gt; 환경에서 진행해 주셨습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;쏘카 운영자는 Admin Website를 통해 Public 한 디지털 에셋을 관리하고 싶다.&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;‘디지털 에셋 관리 화면’에서 업로드한 에셋 파일을 볼 수 있어야 한다.&lt;/li&gt;
      &lt;li&gt;에셋 파일을 미리 보기로 볼 수 있어야 한다.&lt;/li&gt;
      &lt;li&gt;에셋 파일을 업로드할 수 있어야 한다.&lt;/li&gt;
      &lt;li&gt;에셋 파일을 검색할 수 있어야 한다.&lt;/li&gt;
      &lt;li&gt;에셋 파일을 삭제할 수 있어야 한다.&lt;/li&gt;
      &lt;li&gt;에셋 파일을 담는 폴더(디렉토리)를 생성할 수 있어야 한다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;쏘카 운영자는 에셋 파일의 History를 저장한 Log를 보고 싶어 한다.&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;운영자는 에셋 파일의 변경(생성, 삭제) 이력과 변경한 사람 / 변경일자 / 변경 사유에 대해 알 수 있다.&lt;/li&gt;
      &lt;li&gt;운영자는 전체 Log에 대해 날짜 기준으로 조회할 수 있다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;첫 데모 당시에는 많이 긴장했고 떨렸지만 서비스 추가 및 개선 관련 Q&amp;amp;A 시간까지 무사히 마칠 수 있었습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/onboarding-service-engineering/10.png&quot; alt=&quot;스프린트 데모 시연&quot; /&gt;&lt;em&gt;스프린트 데모 시연&lt;/em&gt;&lt;/p&gt;

&lt;h3 id=&quot;35-회고-및-플래닝&quot;&gt;3.5. 회고 및 플래닝&lt;/h3&gt;

&lt;p&gt;데모 다음 날 스프린트 회고 및 플래닝을 진행했습니다. 스프린트 회고 방식은 &lt;code class=&quot;highlighter-rouge&quot;&gt;KPT 회고 방식&lt;/code&gt; 을 도입하였습니다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;💡 KPT 회고란? &lt;strong&gt;Keep / Problem / Try&lt;/strong&gt; 의 세 가지 관점으로 분류하여 회고를 진행하는 회고 방법론입니다.&lt;/p&gt;
  &lt;ul&gt;
    &lt;li&gt;Keep - 잘하고 있는 점 또는 이대로 유지했으면 좋겠다고 생각되는 점&lt;/li&gt;
    &lt;li&gt;Problem - 문제라고 생각되는 점 또는 개선했으면 하는 점&lt;/li&gt;
    &lt;li&gt;Try - 잘하고 있는 것을 유지하기 위한 방법 또는 문제를 해결하기 위한 방법&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;/img/onboarding-service-engineering/11.png&quot; alt=&quot;KPT 회고&quot; /&gt;&lt;em&gt;KPT 회고&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;이처럼 스프린트를 진행하면서 느꼈던 Keep, Problem, Try를 스프린트 참여자들이 포스트잇에 작성하고 이를 공유하며 토론을 통해 내용을 개선했습니다. 이후 투표를 통해 다음 스프린트에 수행할 &lt;strong&gt;Action Item&lt;/strong&gt;을 선정하는데, 회고의 사회자가 다음 스프린트 기간 동안 Action Item을 잘 수행하는지 감독하게 됩니다.&lt;/p&gt;

&lt;p&gt;저희 모두 처음 해보는 회고 방식이어서 퇴근 시간이 가까워질 때가 돼서야 위와 같이 간결하게 정리하고 마칠 수 있었습니다. 다음 회고에서는 &lt;strong&gt;소요시간은 줄이고 회고 목적에 맞게 적합한 Item을 도출해 내는&lt;/strong&gt; 노하우가 생겼고, 이는 이후 버킷에서 진행한 스프린트 회고에 있어 큰 도움이 되었습니다.&lt;/p&gt;

&lt;p&gt;이렇게 이전 스프린트 회고를 마치고 바로 다음 스프린트를 위한 플래닝을 진행했습니다.
&lt;img src=&quot;/img/onboarding-service-engineering/12.png&quot; alt=&quot;jira 를 활용한 플래닝&quot; /&gt;&lt;em&gt;jira 를 활용한 스프린트 플래닝&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;처음 작성했던 유저 스토리를 바탕으로 스프린트 업무 범위를 구체화한 후 티켓을 함께 생성하며 업무 분배를 했습니다. 이때 각 티켓 별로 협의를 통해 최종 Story Point를 확정합니다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;💡 Story Point 란?&lt;br /&gt;
→ 지라 티켓에서의 Story Point는 &lt;strong&gt;해당 티켓을 완료하는 데까지 걸리는 노력(시간, 난이도 등)의 총합&lt;/strong&gt; 을 의미합니다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;스프린트 도중에 하게 된 모든 미팅과 회고 / 플래닝은 넉넉하게 시간을 두고 진행했습니다. 
그 이유는 동료들이 자유롭게 의견을 공유하도록 하기 위해서입니다. 그 결과로 프로젝트 기간 동안 충분한 소통을 하며 성공적으로 마무리할 수 있었습니다.
&lt;br /&gt;&lt;/p&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;4-동료와의-교류-및-스터디&quot;&gt;4. 동료와의 교류 및 스터디&lt;/h2&gt;

&lt;p&gt;당연히! 온보딩 강의를 듣고 프로젝트를 수행하는 교육만 받지 않았습니다. 쏘카에서 저희 온보딩팀도 참여할 수 있는 활동이 여러 가지가 있습니다만, 가장 기억에 남는 세 가지 활동에 대해 소개하려고 합니다.&lt;/p&gt;

&lt;h3 id=&quot;41-서비스-엔지니어링-본부-타운홀-미팅-자기소개&quot;&gt;4.1. 서비스 엔지니어링 본부 타운홀 미팅 자기소개&lt;/h3&gt;

&lt;p&gt;서비스 엔지니어링 본부에서는 매달 말일에 한 시간 정도 모두가 모여 서로 인사하고, 정보 / 기술 / 성과를 공유하는  &lt;strong&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;서비스 엔지니어링 본부 타운홀 미팅&lt;/code&gt;&lt;/strong&gt; 이 있습니다.
매 회차마다 있는 &lt;strong&gt;‘신규 동료 소개’&lt;/strong&gt; 세션에서 저에 대한 소개 자료를 PPT 1페이지 분량으로 준비해서 &lt;strong&gt;자기 PR&lt;/strong&gt;할 수 있었습니다.
&lt;img src=&quot;/img/onboarding-service-engineering/13.png&quot; alt=&quot;코기는 이런 사람입니다.&quot; /&gt;&lt;em&gt;코기는 이런 사람입니다.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;이렇게 마련해 주신 세션 덕분에 서비스 엔지니어링 본부 동료분들에게 &lt;strong&gt;‘코기’&lt;/strong&gt;에 대해 알릴 수 있는 기회가 되었고 다들 뜨거운 박수와 환호로 맞이해주셨습니다.&lt;br /&gt;
(질문도 엄청 해주셔서 Q&amp;amp;A 타임이 되었습니다.)&lt;/p&gt;

&lt;p&gt;특히 &lt;strong&gt;‘쏘카에 입사한 것을 진심으로 환영하고 축하한다.’&lt;/strong&gt;는 따뜻한 말이 지금까지도 가슴속에 자리 잡고 있습니다. 이러한 세션 덕분에 동료들과 더욱 가까워졌고 회사 또한 빠르게 적응할 수 있었습니다.&lt;/p&gt;

&lt;h3 id=&quot;42-쏘풍-데이&quot;&gt;4.2. 쏘풍 데이&lt;/h3&gt;

&lt;p&gt;올해부터 &lt;strong&gt;쏘카 회사 적응 및 동료 간의 친목 도모&lt;/strong&gt;를 위해 &lt;strong&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;쏘풍 데이&lt;/code&gt;&lt;/strong&gt; 가 추진되었습니다.
다른 팀의 동료분들과 하루 종일 식사하고 액티비티 활동을 하면서 더욱 가까워질 수 있는 날입니다.&lt;/p&gt;

&lt;p&gt;이날에는 업무를 하지 않고 쏘풍 데이에 집중할 수 있는 환경을 조성해 주기 때문에 편하게 시간을 보낼 수 있었습니다. 
저희 조는 ‘브런치 → 영화 → 볼링 → 북 카페’ 코스로 활동을 기획했습니다.&lt;br /&gt;
&lt;em&gt;(다른 조는 양평 두물머리 드라이브, 강원도 바다멍 여행, 남양주 물의 정원, 낙산공원과 연극 등 다양한 활동을 했다고 합니다.)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/onboarding-service-engineering/14.png&quot; alt=&quot;쏘풍 데이 중 볼링 치는 모습&quot; /&gt;&lt;em&gt;쏘풍데이 중 볼링 치는 모습&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;이런 날을 제공해 준 쏘카 덕분에 잊지 못할 추억을 하나 간직할 수 있었고 다음에 다른 본부와도 쏘풍 데이를 함께하면 좋겠다고 느꼈습니다.&lt;/p&gt;

&lt;h3 id=&quot;43-스터디&quot;&gt;4.3. 스터디&lt;/h3&gt;

&lt;p&gt;쏘카에서는 다양한 주제로 자유롭게 스터디를 만들어 진행할 수 있습니다. 저는 온보딩 기간에 개인적으로 &lt;code class=&quot;highlighter-rouge&quot;&gt;kotlin in action&lt;/code&gt; 책을 혼자서 공부하다가 버킷에 배정받은 이후에는 MSA 스터디에 참여하여 동료들과 함께 &lt;code class=&quot;highlighter-rouge&quot;&gt;마이크로 서비스 도입, 이렇게 한다.&lt;/code&gt; 책으로 공부하고 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/onboarding-service-engineering/15.png&quot; alt=&quot;온보딩 팀 스터디 진행 리스트&quot; /&gt;&lt;em&gt;온보딩 팀 스터디 진행 리스트&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;5-온보딩-졸업-후-각자-버킷으로&quot;&gt;5. 온보딩 졸업 후 각자 버킷으로&lt;/h2&gt;

&lt;p&gt;프로젝트 최종 데모를 끝으로 모든 온보딩 교육 일정을 마쳤습니다. 이후 티타임을 가지면서 각 버킷에 대해 어떠한 서비스와 프로젝트를 진행하는지 소개를 듣고 희망하는 버킷을 3순위까지 작성했습니다.
한 가지 아쉬운 점은 원하는 버킷이 있어도 다른 버킷의 인원이 해당 버킷의 인원보다 적거나 추가 인원이 필요한 경우에만 TO가 생기고, 이러한 &lt;strong&gt;TO가 나온 버킷에만 희망이 가능&lt;/strong&gt;했다는 것입니다.&lt;/p&gt;

&lt;p&gt;이 때 EM(Engineering Manangement) 유닛의 케이제이가 개인과 각 버킷 별 TL의 희망 순위가 모두 반영될 수 있도록 최대한 조율해 주셨습니다.&lt;/p&gt;

&lt;p&gt;그렇게 저는 제가 희망했던 B2B 버킷에 배정받았습니다. 이후 서로 모르는 부분이 있거나 다른 버킷의 서비스와 연관된 기능을 개발할 때에 버킷 간 편하게 교류할 수 있었습니다. 
이는 모두 온보딩 교육이 있었기에 가능했다고 생각합니다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;6-나날이-발전하는-온보딩-커리큘럼&quot;&gt;6. 나날이 발전하는 온보딩 커리큘럼&lt;/h2&gt;

&lt;p&gt;쏘카의 온보딩 커리큘럼은 피드백을 통해 지속적으로 개선되고 있다고 합니다. Dogfooding Project 기간이 짧다는 피드백을 반영하여 현재는 &lt;strong&gt;Dogfooding Project를 2달 가까이 진행&lt;/strong&gt;하고 있으며, 기존 커리큘럼에 아래 강의들이 추가되었다고 합니다.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;&lt;center&gt;주제&lt;/center&gt;&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;&lt;center&gt;내용&lt;/center&gt;&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;소속&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;강사&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;CITY DILEMMA : 쏘카 다큐멘터리 시청&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;쏘카가 추구하는 방향과 지금까지 달려온 여정을 담은 다큐멘터리를 시청합니다.&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;차량 시뮬레이터 온보딩&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;본부 별 차량 시뮬레이터 체험 &amp;amp; 교육&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;커넥티드디바이스팀&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;라네&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Modern Architecture 1, 2&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;아키텍트의 역할과 아키텍트는 어떻게 만들어지는지에 대한 이야기를 전해드립니다.&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;SE 본부장&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;아나킨&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;당신이 모르던 코틀린&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;코틀린에 대한 기초 및 심화 교육&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;외부강사&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;오현석&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;7-나에게-온보딩-교육이란&quot;&gt;7. 나에게 온보딩 교육이란?&lt;/h2&gt;

&lt;p&gt;쏘카에서는 같은 달에 입사한 분들과 함께 온보딩 교육을 받기 때문에 입사 동기가 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/onboarding-service-engineering/1-4.png&quot; alt=&quot;신규 입사자 4명 프로필&quot; /&gt;&lt;em&gt;왼쪽부터 코기, 도시, 이누, 키이라입니다.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;저와 함께 우당탕탕 했던 동기들에게 온보딩 교육 관련해서 Q&amp;amp;A 하는 인터뷰를 진행해 봤습니다.
&lt;br /&gt;
&lt;em&gt;(인터뷰 질문에 성실히 대답해 주셔서 감사합니다!)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Q. 나에게 있어 쏘카의 온보딩 교육이란?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;코기&lt;/strong&gt; : 쏘카에 동화되어 진정한 쏘카 일원으로 합류하게 만들어 주었습니다. 또한 온보딩 교육이 없었다면 평생 갈 소중한 동기를 얻지 못했을 것이라고 생각합니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;도시&lt;/strong&gt; : 쏘카 문화에 적응하며 동료들과 밍글링(Mingling) 할 수 있는 즐거운 시간이었습니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;이누&lt;/strong&gt; : 쏘카에 자연스럽게 적응할 수 있는 따뜻하고 즐거운 시간이었습니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;키이라&lt;/strong&gt; : 쏘카 문화에 스며들고 쏘카의 기술들을 천천히 살펴볼 수 있는 시간뿐 아니라 나에게 필요한 것들을 파악하고 준비할 수 있는 시간이었습니다. 이에 더해, 동기 및 쏘카 동료들과 친해질 수 있는 시간이었습니다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Q. 온보딩 교육을 통해 어떤 도움을 받았나요?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;코기&lt;/strong&gt; : 온보딩 교육 이후 저의 직업을 ‘백엔드 서버 개발자’라고 자신 있게 소개할 수 있었습니다. 그만큼 더 깊고 전문적인 지식과 경험을 쌓는데 발판을 마련해 줬고, ‘넌 쏘카에서 충분히 잘 해낼 수 있는 사람’이라는 생각을 자리 잡게 해주었습니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;도시&lt;/strong&gt; : 쏘카의 개발 문화와 추구하는 가치를 체계적으로 알 수 있었고 여러 분야의 전문가분들에게 직접 관련 지식과 경험을 배울 수 있던 점이 저에게 많은 도움이 되었습니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;이누&lt;/strong&gt; : 체계적인 개발 수업을 들으며 개발자로서의 기반을 닦을 수 있었습니다. Dogfooding 프로젝트를 하며 쏘카 내에서의 협업은 어떻게 이뤄지는지, 이슈가 발생했을 땐 어떻게 핸들링해야 하는지, 개발 및 업무 진행에 있어 도움은 어떻게 받을 수 있는지 등 을 배울 수 있었습니다. 가장 큰 건 무엇보다 소중한 동기들을 얻은 것입니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;키이라&lt;/strong&gt; : 쏘카가 추구하는 개발 방향에 대해 전반적으로 파악할 수 있었고 무엇보다 Dogfooding 프로젝트를 진행하면서 협업 방식과 의사소통 방식을 배울 수 있었습니다. 이는 각자 버킷에 배정된 이후에도 빠르게 적응할 수 있는 기반이 되었다고 생각이 듭니다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Q. 가장 인상 깊은 온보딩 교육은 어떤 것인가요?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;코기&lt;/strong&gt; : 교육받는 모든 순간이 전부 기억에 남았고 인상깊었습니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;도시&lt;/strong&gt; : 함께 3월에 입사한 동기들과 함께 진행한 &lt;strong&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Dogfooding 프로젝트&lt;/code&gt;&lt;/strong&gt; 가 가장 기억에 남습니다. 이 프로젝트를 진행하면서 온보딩 강의로 배웠던 쏘카의 애자일 문화를 실제로 사용해 볼 수 있었고, 이후에는 실제 쏘카에서 사용하기 위한 목적이었어서 쏘카와 관련된 도메인 지식을 익힐 수 있었습니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;이누&lt;/strong&gt; : 모든 교육이 개성 있고 유익했습니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;키이라&lt;/strong&gt; : 음.. 온보딩 기간 동안 협업 방법, Architecturing Model, CI/CD, 서버 모니터링, Test Code 등 다양한 강의를 수강했고 Dogfooding 프로젝트를 진행했습니다. 사실 이러한 온보딩 프로세스가 체계적으로 구성되어 있다는 점에 굉장히 만족했습니다. 또한실제로도 교육받은 내용들이 온보딩 이후 팀에서의 적응을 수월하게 해주었습니다.&lt;/p&gt;

&lt;p&gt;이 중 가장 인상 깊었던 온보딩 교육을 꼽자면 &lt;strong&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Dogfooding 프로젝트&lt;/code&gt;&lt;/strong&gt; 인 것 같습니다. 직접 경험해 보는 것만큼 이해가 잘 되는 것은 없으니까요. 프로젝트 과정을 통해서 실제로 쏘카에서 쓰이는 기술들을 미리 찾아보고 적용해 볼 수 있었던 시간이어서 많은 도움이 되었습니다. 마지막으로 동기들과 같이 진행했던 프로젝트가 현재 저희 Marketing Bucket으로 넘어왔는데, 고도화 후 쏘카 서비스에 얼른 적용시켜보고 싶습니다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Q. 그렇다면, 현재 배정받은 버킷에서 업무를 하는 데 있어 가장 크게 도움 되었다고 생각되는 강의와 그 이유가 궁금합니다.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;코기&lt;/strong&gt; : 저는 도가와 브루스가 강의해 주신 &lt;strong&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;BackEnd - CI/CD 및 Datadog &amp;amp; Monitoring&lt;/code&gt;&lt;/strong&gt; 강의가 가장 도움이 되었습니다. 현재 B2B 버킷의 서비스를 모니터링하는 &lt;strong&gt;Datadog Monitor 및 Opsgenie 구성&lt;/strong&gt;을 수월하게 할 수 있는데 도움이 많이 되었습니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;도시&lt;/strong&gt; : 저는 경력으로 입사하였지만 쏘카 FrontEnd 직무의 업무방식을 전부 이해하는 것은 아니었기 때문에 &lt;strong&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;프론트엔드 직무 관련 모든 강의&lt;/code&gt;&lt;/strong&gt; 들이 업무를 이해하는 데 도움이 되었습니다.&lt;br /&gt;
현재는 FrontEnd 개발자로써 Core Platform Bucket과 Web 팀에 소속되어 관련 업무를 하고 있는데, 온보딩 강의를 통해 저의 지금까지의 경험과 쏘카 FrontEnd 직무의 업무방식의 차이를 알 수 있었고, 더 나은 기술 및 개발 문화를 모색할 수 있는 기반을 만들어줬다고 생각합니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;이누&lt;/strong&gt; : 카이가 해주신 &lt;strong&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;BackEnd - Tests and testable code&lt;/code&gt;&lt;/strong&gt; 강의가 실무에서 가장 유용한 것 같습니다. 직접 테스트 코드를 짜면서 비즈니스 로직을 파악하고 어떤 상황에서 에러 처리를 해야 하는지 꼼꼼하게 배울 수 있었습니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;키이라&lt;/strong&gt; : 현재 속한 버킷에서 업무를 하는데 많은 도움이 되었던 강의는 대표적으로 2개가 있습니다. (한 가지만 선택하라고 하셨지만..)&lt;/p&gt;

&lt;p&gt;첫 번째는, &lt;strong&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;BackEnd - Runnning Services In The local&lt;/code&gt;&lt;/strong&gt; 강의입니다. 이 강의에서 Git 관련 설정부터 로컬에서 서버 띄워보는 작업까지 전부 진행했는데, 처음 슬라이드를 보고 설명을 들었을 때만 해도 간단해 보였습니다. 하지만 처음 Mac 환경 설정부터 시작해서 로컬에서 쏘카 서버를 띄울 수 있는 환경을 구축하기까지 함께 실습해 보면서 만약 이걸 혼자 했다면 무조건 헤맸을 거라는 생각이 들었고, 그와 함께 이 강의에 대한 고마움이 계속 기억에 남아있습니다.&lt;br /&gt;
 두 번째는, &lt;strong&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;BackEnd - Tests and Testable Code&lt;/code&gt;&lt;/strong&gt; 강의입니다. 이 강의에서는 테스트 코드 종류부터 왜 테스트 코드가 필요한지, TDD 등에 대한 설명과 실습을 수행했습니다. 입사하기 전 따로 프로젝트를 진행해 본 경험은 있었지만 프로젝트에 테스트 코드를 활용해 보지는 않았어서 해당 강의가 도움이 되었습니다. 또한 현재 버킷에서 진행하는 업무의 대부분은 테스트 코드 작성이 필수여서 이 강의를 통해 얻은 지식과 기술을 지금도 계속 사용하고 있기 때문입니다.&lt;/p&gt;

&lt;p&gt;제가 백엔드 직무여서 그런지 직무와 관련된 강의들이 조금 더 인상 깊었던 것 같습니다. 하지만 돌이켜보면 온 보딩 강의 중에 저에게 도움이 되지 않았던 강의는 하나도 없다고 생각합니다. 강의해 주신 분들 모두 감사합니다!&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Q. 새롭게 합류할 동료에게 해주고 싶은 이야기가 있다면?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;코기&lt;/strong&gt; : 이 글을 보고 합류하셨다면, 댓글을 달아주세요! 너무너무 환영하고, 반갑다는 의미로 식사 한 끼 대접하겠습니다~ 🍚&lt;br /&gt;
(매일매일 모니터링 하고 있겠습니다 👀)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;도시&lt;/strong&gt; : 애자일 문화, 개발 문화, 개발자가 일하기 좋은 회사를 찾고 있다면 쏘카로 (당장) 오세요~!&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;이누&lt;/strong&gt; : 쏘카에 온 걸 환영하고 같이 즐겁게 개발했으면 좋겠습니다! 😊&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;키이라&lt;/strong&gt; : 성장할 수 있는 회사, 워라벨이 좋은 회사를 찾으신다면, 쏘카에 만족하실 것 같아요~ 👍&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;8-마치며&quot;&gt;8. 마치며&lt;/h2&gt;

&lt;p&gt;회사에서는 같이 협업하고 퇴근 후에는 친목을 다지며 하루하루 행복하게 만들어준 동기들에게 감사 인사를 드리며, 고마움의 표시로 함께 카페에서 추억을 나눴던 사진을 첨부하며 글을 마무리하겠습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/onboarding-service-engineering/16.png&quot; alt=&quot;왼쪽부터 도시, 이누, 코기(저), 키이라입니다.&quot; /&gt;&lt;em&gt;왼쪽부터 도시, 이누, 코기(저), 키이라입니다.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;지금까지 긴 글 읽어주셔서 감사합니다.&lt;/p&gt;</content><author><name>코기</name></author><category term="dev" /><category term="backend" /><category term="frontend" /><category term="developer" /><category term="service engineering" /><category term="onboarding" /><summary type="html"></summary></entry><entry><title type="html">React Custom Icon Component 개발기</title><link href="https://tech.socarcorp.kr/dev/2022/09/06/react-icon-component.html" rel="alternate" type="text/html" title="React Custom Icon Component 개발기" /><published>2022-09-06T00:00:00+00:00</published><updated>2022-09-06T00:00:00+00:00</updated><id>https://tech.socarcorp.kr/dev/2022/09/06/react-icon-component</id><content type="html" xml:base="https://tech.socarcorp.kr/dev/2022/09/06/react-icon-component.html">&lt;p&gt;안녕하세요. 쏘카 웹 프론트엔드 개발자 시에나, 블랑입니다.&lt;/p&gt;

&lt;p&gt;이 글에 다룰 내용은 쏘카에서 공통적으로 사용하는 &lt;strong&gt;React Icon Component 개발 과정&lt;/strong&gt;입니다. 아이콘 컴포넌트를 어떻게 개발했으며 어떤 점들을 개선했는지에 대해서 중점적으로 다룰 예정입니다.&lt;/p&gt;

&lt;p&gt;다음과 같은 분들이 읽어보시면 좋을 것 같습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;웹 프론트엔드 개발자, 웹 디자이너&lt;/li&gt;
  &lt;li&gt;웹 개발에 관심이 있으신 분&lt;/li&gt;
  &lt;li&gt;쏘카 웹 프론트엔드 팀이 궁금하신 분&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;목차&quot;&gt;목차&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;#1.-React-Icon-Component란?&quot;&gt;1. React Icon Component란?&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#2.-React-Icon-Component-개발의-필요성&quot;&gt;2. React Icon Component 개발의 필요성&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#2.1-기존-방식에-대해-알아보자&quot;&gt;2.1 기존 방식에 대해 알아보자&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#2.2-기존-방식의-문제점을-알아보자&quot;&gt;2.2 기존 방식의 문제점을 알아보자&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#2.3-이렇게-개선해 보자&quot;&gt;2.3 이렇게 개선해 보자&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#3.-Icon-Component-개발-과정&quot;&gt;3. Icon Component 개발 과정&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#3.1-아이콘-파일로-사용되는-SVG를-알아보자&quot;&gt;3.1 아이콘 파일로 사용되는 SVG를 알아보자&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#3.2-다양한-Element-도형을-Path-Element로-변경해 보자&quot;&gt;3.2 다양한 Element 도형을 Path Element로 변경해 보자&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#3.3-컴포넌트를-만들어서-적용해 보자&quot;&gt;3.3 컴포넌트를 만들어서 적용해 보자&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#3.4-타입을-적용해 보자&quot;&gt;3.4 타입을 적용해 보자&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#3.5-스토리북에-적용해서-확인해 보자&quot;&gt;3.5 스토리북에 적용해서 확인해 보자&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#4.-Icon-Component-등록-과정&quot;&gt;4. Icon Component 등록 과정&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#4.1-아이콘-등록을-해보자&quot;&gt;4.1 아이콘 등록을 해보자&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#4.2-아이콘-등록-방식을-자동화-해보자&quot;&gt;4.2 아이콘 등록 방식을 자동화해 보자&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#5.-문제점-해결&quot;&gt;5. 문제점 해결&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#6.-개선할-점&quot;&gt;6. 개선할 점&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#7.-마무리&quot;&gt;7. 마무리&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;1-react-icon-component란-&quot;&gt;1. React Icon Component란? &lt;a name=&quot;1.-React-Icon-Component란?&quot;&gt;&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;React에서 Component는 재사용이 가능한 UI의 단위를 말합니다. 즉 React Icon Component는 React를 활용하여 아이콘 재사용을 용이하게 만들어주는 UI 단위를 말합니다.&lt;/p&gt;

&lt;h2 id=&quot;2-react-icon-component-개발의-필요성-&quot;&gt;2. React Icon Component 개발의 필요성 &lt;a name=&quot;2.-React-Icon-Component-개발의-필요성&quot;&gt;&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;디자인 시스템이란 재사용 가능한 UI 요소들을 미리 정의하여 일관된 디자인을 할 수 있도록 도와주는 규칙을 말합니다.&lt;/p&gt;

&lt;p&gt;쏘카의 디자인 시스템은 디자이너, IOS 개발자, Android 개발자, 웹 프론트엔드 개발자가 협업하여 구축했습니다. 사용자가 일관된 UI/UX를 경험할 수 있도록 IOS, Android, 웹에서 모두 같은 형태의 컴포넌트들을 개발하여 사용합니다. 쏘카의 디자인 시스템에 대한 자세한 내용은 프로덕트 디자인 팀이 작성해 주신 &lt;em&gt;&lt;a href=&quot;/design/2020/06/23/socar-design-system-01.html&quot;&gt;&lt;u&gt;쏘카의 디자인 시스템 맛보기&lt;/u&gt;&lt;/a&gt;&lt;/em&gt; 를 참고해 주세요.&lt;/p&gt;

&lt;p&gt;이번 글에서 다룰 아이콘 또한 디자인 시스템에 정의되어 있습니다. 쏘카의 아이콘은 쏘카 앱 내 곳곳에서 찾아볼 수 있고 &lt;a href=&quot;https://plan.socar.kr/&quot;&gt;쏘카 플랜&lt;/a&gt;에서도 사용되고 있습니다.&lt;/p&gt;

&lt;div style=&quot;display: flex; justify-content: space-between;&quot;&gt;
    &lt;img src=&quot;/img/icon-component/infoIcon.jpg&quot; width=&quot;30%&quot; /&gt;
    &lt;img src=&quot;/img/icon-component/chevronIcon.jpg&quot; width=&quot;30%&quot; /&gt;
    &lt;img src=&quot;/img/icon-component/socarplanIcons.jpg&quot; width=&quot;30%&quot; /&gt;
&lt;/div&gt;

&lt;h3 id=&quot;21-기존-방식에-대해-알아보자-&quot;&gt;2.1 기존 방식에 대해 알아보자 &lt;a name=&quot;2.1-기존-방식에-대해-알아보자&quot;&gt;&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;저희는 기존에 아이콘을 웹폰트로 변환하여 사용하고 있었습니다. 해당 방식으로도 아이콘을 등록하고 사용하는 데에는 큰 무리가 없지만, 디자인 시스템은 여러 개발자가 공동으로 사용하기 때문에 개발자 경험(Developer Experience, DX) 또한 중요합니다. 기존의 방식은 개발자 경험 측면에서 불편한 점이 있어 아이콘 방식 개선에 대한 필요성을 느끼게 되었습니다.&lt;/p&gt;

&lt;p&gt;구체적으로 기존의 방식에 어떤 문제점이 있었는지 말씀드리겠습니다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;SVG → 웹폰트 변환&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://icomoon.io/app&quot;&gt;&lt;b&gt;외부 서비스&lt;/b&gt;&lt;/a&gt;를 이용해서 아이콘 SVG 파일들을 웹폰트로 변환합니다.&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;&lt;img src=&quot;/img/icon-component/svgToFont.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;생성된 파일 등록&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;웹폰트로 변환하면 폰트 파일과 CSS 파일이 생성됩니다.&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;&lt;img src=&quot;/img/icon-component/generateIconResult.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;/img/icon-component/iconFontFiles.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;생성된 파일들을 디자인 시스템 저장소에 넣어줍니다. 이때 아이콘 폰트에 원하는 컬러를 주입할 수 있도록 하기 위해 CSS의 color 속성을 제거해 줍니다.&lt;/li&gt;
    &lt;/ul&gt;

    &lt;div style=&quot;display: flex; justify-content: space-between;&quot;&gt;
    &lt;img style=&quot;width: 60%; display: inline-block;&quot; src=&quot;/img/icon-component/cssBefore.png&quot; /&gt;
    &lt;img style=&quot;width: 35%; display: inline-block;&quot; src=&quot;/img/icon-component/cssAfter.png&quot; /&gt;
&lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;디자인 시스템 배포
    &lt;ul&gt;
      &lt;li&gt;아이콘 폰트 등록이 완료되면 디자인 시스템의 배포를 진행합니다. 디자인 시스템을 사용 중인 모든 서비스들도 디자인 시스템 버전을 최신화해서 같이 배포를 진행합니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;아이콘 사용
    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;i&amp;gt;&lt;/code&gt; 태그에 사용하고자 하는 아이콘의 className을 주입하여 사용합니다.&lt;/p&gt;

        &lt;div class=&quot;language-html highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nt&quot;&gt;&amp;lt;i&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;className=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;ic18_help grey050&quot;&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;/&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;22-기존-방식의-문제점을-알아보자-&quot;&gt;2.2 기존 방식의 문제점을 알아보자 &lt;a name=&quot;2.2-기존-방식의-문제점을-알아보자&quot;&gt;&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;기존 방식을 사용하면서 겪은 문제점은 다음과 같습니다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;외부 서비스에 의존적이다.&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;위에서 설명드렸듯이 SVG 파일 -&amp;gt; 웹폰트 변환 과정은 외부 서비스에 전적으로 의존하고 있습니다. 해당 서비스의 기능이 변경되거나 서비스가 종료되면 기존의 방식으로는 아이콘 등록을 못 하게 될 수도 있는 위험성이 있습니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;휴먼 에러가 발생할 여지가 많다.&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;아이콘 등록하는 전 과정을 수기로 진행하는 것이 번거롭고 어느 한 과정이라도 누락하거나 실수가 발생하면 아이콘이 제대로 등록되지 않거나 실 서비스 화면에서 아이콘이 깨져 보이게 됩니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;폰트 방식을 이용하면 발생하는 문제점이 많다.&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;글꼴 파일을 불러오고 빌드 하는 시간이 소요됩니다.&lt;/li&gt;
      &lt;li&gt;웹 접근성이 좋지 않습니다.&lt;/li&gt;
      &lt;li&gt;화면을 확대하면 화질 저하가 발생합니다.&lt;/li&gt;
      &lt;li&gt;텍스트 기반 CSS 규칙을 따르기 때문에 CSS 컨트롤이 어렵습니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;23-이렇게-개선해-보자-&quot;&gt;2.3 이렇게 개선해 보자 &lt;a name=&quot;2.3-이렇게-개선해 보자&quot;&gt;&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;위와 같은 문제점들을 겪으면서 디자인 시스템에 아이콘을 등록하는 방식 자체를 개선해야겠다고 생각했습니다. 개선의 목표는 다음과 같았습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;아이콘 등록 과정의 간소화&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;아이콘 등록 방식의 자동화&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;위의 목표를 달성하면서도 기존에 사용 중인 아이콘들에 영향을 미치지 않는 방식으로 개선을 시도했습니다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;3-icon-component-개발-과정-&quot;&gt;3. Icon Component 개발 과정 &lt;a name=&quot;3.-Icon-Component-개발-과정&quot;&gt;&lt;/a&gt;&lt;/h2&gt;

&lt;h3 id=&quot;31-아이콘-파일로-사용되는-svg를-알아보자-&quot;&gt;3.1 아이콘 파일로 사용되는 SVG를 알아보자 &lt;a name=&quot;3.1-아이콘-파일로-사용되는-SVG를-알아보자&quot;&gt;&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;SVG는 2차원 벡터 그래픽을 표현하는 XML 기반의 마크업 언어입니다.&lt;/p&gt;

&lt;p&gt;벡터 그래픽이란 수학적 표현을 통해 점, 직선, 곡선을 사용하여 이미지를 만드는 그래픽을 말합니다. 흔히 알고 있는 또 다른 그래픽 파일 포맷으로는 래스터 그래픽, 즉 비트맵으로 PNG, JPEG가 있습니다. 이것은 픽셀로 구성된 이미지로 작은 컬러 사각형인 픽셀이 무수히 많이 모여 만들어지는 그래픽입니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/icon-component/vector&amp;amp;bitmap.png&quot; alt=&quot;image&quot; /&gt;&lt;em&gt;출처: &lt;a href=&quot;https://www.selfmadedesigner.com/what-are-vector-graphics/&quot;&gt;벡터 그래픽과 래스터 그래픽의 차이 &lt;/a&gt;&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;벡터 그래픽과 래스터 그래픽은 해상도에서 차이점을 보입니다.
픽셀로 이루어진 래스터 그래픽은 벡터 그래픽보다 더 다양한 색상을 표현할 수 있지만 크기를 크게 조절하면 이미지 품질이 저하된다는 단점이 있습니다. 이미지 품질을 높이면 크게 조절이 가능하지만 용량이 커지면서 웹 성능의 영향을 미칠 수 있습니다.&lt;/p&gt;

&lt;p&gt;벡터 그래픽은 크기를 크게 조절하더라도 이미지 품질이 저하되지 않고 용량도 래스터 그래픽보다 작다는 장점을 갖습니다. 이에 더하여 애니메이션이 가능하고, 수정이 용이하며, 출력이 빠르기 때문에 &lt;strong&gt;아이콘 파일 포맷&lt;/strong&gt;으로 사용되고 있습니다.&lt;/p&gt;

&lt;h3 id=&quot;32-다양한-element-도형을-path-element로-변경해-보자-&quot;&gt;3.2 다양한 Element 도형을 Path Element로 변경해 보자 &lt;a name=&quot;3.2-다양한-Element-도형을-Path-Element로-변경해 보자&quot;&gt;&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;SVG를 이루는 기본적인 도형의 종류로는 Path, Rect, Circle, Ellipse, Line, Polyline, Polygon Element가 있습니다. 그중에서 Path Element는 &lt;strong&gt;d&lt;/strong&gt; Attribute 하나로 정의되고, 선과 곡선, 호 등 다양한 형태를 그릴 수 있는 Element입니다. 여러 개의 직선과 곡선을 합쳐서
&lt;strong&gt;복잡한 도형을 그릴 수 있다는 큰 장점&lt;/strong&gt;을 갖고 있습니다.&lt;/p&gt;

&lt;p&gt;가장 먼저 Path Element의 장점을 이용해 쏘카가 가진 다양한 형태의 아이콘을 하나의 형태로 바꾸는 스크립트를 작성하였습니다.&lt;/p&gt;

&lt;p&gt;Path Element로 바꾸는 원리를 Rect Element로 작성된 아이콘으로 설명해 드리겠습니다.&lt;/p&gt;

&lt;div class=&quot;language-html highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nt&quot;&gt;&amp;lt;rect&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;x=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;8&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;y=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;8&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;width=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;2&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;height=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;2&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;fill=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;#374553&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;/&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;해당 코드는 (8,8)가 사각형 왼쪽 꼭짓점이고 넓이, 높이가 2인 사각형을 그리게 됩니다.&lt;/p&gt;

&lt;p&gt;Path Element로 나타내면 아래와 같은 코드가 됩니다.&lt;/p&gt;

&lt;div class=&quot;language-html highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nt&quot;&gt;&amp;lt;path&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;d=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;M8,8 H10 V10 H8 z&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;M은 시작점, H는 수평선, V는 수직선을 뜻합니다. 마지막 z는 “Close Path”라는 의미로 다시 시작점으로 선을 그리라는 뜻입니다.
이대로 위 path를 해석해 보면 (8,8)에서 (10,8), (10,10), (8,10)을 찍고 마지막으로 z를 통해 첫 시작 점 (8,8)으로 그리면 2x2인 정사각형 아이콘이 그려집니다.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/img/icon-component/iconExample.jpg&quot; width=&quot;200&quot; /&gt;
&lt;/p&gt;

&lt;p&gt;이런 원리를 식으로 계산하여 Circle, Rectangle Element를 Path Element로 변환하는 스크립트 파일을 작성하였고, 이 결과물로 아이콘 이름을 Key 값으로 갖는 Path JSON 파일이 만들어집니다.&lt;/p&gt;

&lt;div class=&quot;language-json highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;w&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;ic18_description_dash2&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;width&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;18&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;height&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;18&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;path&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;M8,8H10V10H8z&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;33-컴포넌트를-만들어서-적용해-보자-&quot;&gt;3.3 컴포넌트를 만들어서 적용해 보자 &lt;a name=&quot;3.3-컴포넌트를-만들어서-적용해 보자&quot;&gt;&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;아이콘의 형태를 동일하게 만들어 하나의 JSON 파일에 모아두었으니 이걸 활용하여 컴포넌트를 만들어 적용해 보겠습니다.&lt;/p&gt;

&lt;p&gt;3.2에서 만든 Path JSON 파일을 활용하여 컴포넌트를 만들었습니다. Icon 이름, Icon 색상, Style, ClassName 을 Parameter로 받고 SVG Path로만 이루어진 컴포넌트입니다.&lt;/p&gt;

&lt;div class=&quot;language-jsx highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;svgPaths&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;dl&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;iconDist/svgIcons.json&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;'&lt;/span&gt;

&lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;Icon&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;({&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;icon&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;iconColor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;style&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;className&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;})&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;width&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;height&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;path&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;svgPaths&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;icon&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

  &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;svg&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;width=&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;width&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;height=&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;height&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;fillRule=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;evenodd&quot;&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;clipRule=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;evenodd&quot;&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;xmlns=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;http://www.w3.org/2000/svg&quot;&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;style=&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;style&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;className=&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;className&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;p&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;path&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;d=&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;/&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;&amp;lt;/&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;svg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Icon Component를 사용하려고 보니 IDE가 제공해 주는 자동완성이 되지 않는 문제점이 있었습니다. 
아이콘 개수와 색상이 수백 개인데 사용할 때마다 일일이 적는 것이 번거로웠습니다.
이때 생각한 것이 아이콘 이름과 색상을 타입으로 지정하면 IDE의 도움을 받을 수 있을 것이라 예상했습니다.&lt;/p&gt;

&lt;h3 id=&quot;34-타입을-적용해-보자-&quot;&gt;3.4 타입을 적용해 보자 &lt;a name=&quot;3.4-타입을-적용해 보자&quot;&gt;&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;아이콘의 이름을 리터럴 타입으로 정의하기 위해서 3.2에서 만든 Path JSON 파일에서 아이콘 이름만 추출하는 작업이 필요합니다.&lt;/p&gt;

&lt;div class=&quot;language-json highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
 &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;ic12_24_chevron_right2&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;width&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;12&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;height&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;24&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;path&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;M3.4949,4.5051L11.2399,12.2501L3.4949,19.9951L2.505,19.0051L9.261,12.2501L2.505,5.4951L3.4949,4.5051z&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;ic12_24_divider_vertical&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;width&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;12&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;height&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;24&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;path&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;M5,5H7V19H5z&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;ic12_24_divider_vertical_small&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;width&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;12&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;height&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;24&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;path&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;M5.3,7H6.7V17H5.3z&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;ic12_24_field_dash&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;width&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;12&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;height&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;24&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;path&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;M2,11H10V13H2z&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;아이콘 이름이 Key 값으로 정의되어 있기 때문에 Key 값만 가져온다면 손쉽게 타입 정의를 할 수 있을 것이라 생각했습니다.
&lt;code class=&quot;highlighter-rouge&quot;&gt;Object.key()&lt;/code&gt;를 활용해 아이콘 이름을 가져오는 스크립트를 작성하였고, 실행시키면 아래와 같은 파일이 만들어집니다.&lt;/p&gt;

&lt;div class=&quot;language-jsx highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;export&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;ICON_NAME&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;gr_icon_credit&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;gr_icon_credit&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
  &lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;ic12_24_chevron_right2&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;ic12_24_chevron_right2&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
  &lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;ic12_24_divider_vertical&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;ic12_24_divider_vertical&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
  &lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;ic12_24_divider_vertical_small&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;ic12_24_divider_vertical_small&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
  &lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;ic12_24_field_dash&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;ic12_24_field_dash&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;export&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;type&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;IconName&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;typeof&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;ICON_NAME&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;keyof&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;typeof&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;ICON_NAME&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;];&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;아이콘 이름을 리터럴 타입으로 정의했듯이 색상도 타입으로 정의하기 위해 색상 이름을 추출하는 작업이 필요합니다.&lt;/p&gt;

&lt;p&gt;색상 코드가 적힌 CSS 파일을 문자열 메서드를 이용하여 색상 이름만 가져와 JSON 파일을 만들어 주고, JSON 파일에 특정 부분만 읽어 색상 이름만 타입으로 정의하는 스크립트를 작성합니다.&lt;/p&gt;

&lt;div class=&quot;language-json highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;grey005&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;#fefefe&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;grey010&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;#fdfdfd&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;grey020&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;#f8f9fb&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;grey025&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;#f2f4f6&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;grey030&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;#e9ebee&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;grey040&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;#c5c8ce&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;div class=&quot;language-jsx highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;export&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;ICON_COLOR&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;grey005&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;grey005&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
  &lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;grey010&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;grey010&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
  &lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;grey020&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;grey020&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
  &lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;grey025&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;grey025&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
  &lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;grey030&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;grey030&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
  &lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;grey040&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;grey040&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;export&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;type&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;IconColor&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;typeof&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;ICON_COLOR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;keyof&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;typeof&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;ICON_COLOR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;];&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;아이콘 이름과 색상을 Type으로 정의하여 적용하니 컴포넌트를 사용할 때 IDE의 자동완성이 뜨는 것을 확인할 수 있었습니다.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/img/icon-component/iconName.png&quot; /&gt;
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/img/icon-component/iconColor.png&quot; /&gt;
&lt;/p&gt;

&lt;p&gt;타입까지 적용된 최종 아이콘 컴포넌트는 다음과 같습니다.&lt;/p&gt;

&lt;div class=&quot;language-jsx highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;React&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;CSSProperties&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;dl&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;react&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;'&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;svgPaths&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;dl&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;src/iconDist/svgIcons.json&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;'&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;iconPalette&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;dl&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;src/iconDist/iconPalette.json&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;'&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;IconName&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;IconColor&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;dl&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;./type&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;'&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;export&lt;/span&gt; &lt;span class=&quot;kr&quot;&gt;interface&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;IconProps&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;nl&quot;&gt;icon&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;IconName&lt;/span&gt;
  &lt;span class=&quot;nx&quot;&gt;color&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;IconColor&lt;/span&gt;
  &lt;span class=&quot;nx&quot;&gt;style&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;?:&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;CSSProperties&lt;/span&gt;
  &lt;span class=&quot;nx&quot;&gt;className&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;?:&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;string&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;Icon&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;({&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;icon&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;color&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;style&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;className&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;}:&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;IconProps&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;width&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;height&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;path&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;svgPaths&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;icon&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

  &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;svg&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;width=&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;width&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;height=&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;height&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;fill=&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;iconPalette&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;color&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;fillRule=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;evenodd&quot;&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;clipRule=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;evenodd&quot;&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;xmlns=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;http://www.w3.org/2000/svg&quot;&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;style=&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;style&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;className=&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;className&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;p&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;path&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;d=&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;/&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;&amp;lt;/&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;svg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;export&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;default&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;Icon&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;35-스토리북에-적용해서-확인해-보자-&quot;&gt;3.5 스토리북에 적용해서 확인해 보자 &lt;a name=&quot;3.5-스토리북에-적용해서-확인해 보자&quot;&gt;&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;스토리북은 컴포넌트 단위의 UI 개발 환경을 지원하는 도구입니다. 개발한 아이콘 컴포넌트를 출시하기 전에 미리 디자이너, 개발자가 테스트해서 확인할 수 있습니다.
&lt;img src=&quot;/img/icon-component/storybook.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이렇게 아이콘과 색을 지정해서 출력해 볼 수 있으며, Docs를 확인하여 아이콘 컴포넌트의 사용 방법을 알 수 있으며, 디자이너가 원하는 아이콘이 맞는지 QA도 진행할 수 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/icon-component/StorybookTest.png&quot; alt=&quot;image&quot; /&gt;
&lt;img src=&quot;/img/icon-component/storybookDocs.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;4-icon-component-등록-과정-&quot;&gt;4. Icon Component 등록 과정 &lt;a name=&quot;4.-Icon-Component-등록-과정&quot;&gt;&lt;/a&gt;&lt;/h2&gt;

&lt;h3 id=&quot;41-아이콘-등록을-해보자-&quot;&gt;4.1 아이콘 등록을 해보자 &lt;a name=&quot;4.1-아이콘-등록을-해보자&quot;&gt;&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;아이콘 컴포넌트를 사용하기 위해서는 SVG 파일의 아이콘이 필요합니다. 피그마에서 아이콘을 SVG 형태로 받아 지정된 폴더에 넣어줍니다.
추가한 아이콘의 형식을 통일시키기 위해 &lt;a href=&quot;#3.2-다양한-Element-도형을-Path-Element로-변경해 보자&quot;&gt;Path Element로 전환하는 스크립트&lt;/a&gt;를 실행합니다. 
아이콘에 색상을 넣어주기 위해 형식에 맞게 아이콘 색상 코드를 적어 지정된 폴더에 넣어줍니다. 
아이콘 컴포넌트를 IDE의 도움을 받아 사용하려면 타입 정의도 필요하기 때문에 아이콘 이름과 색상 값의 &lt;a href=&quot;#3.4-타입을-적용해 보자&quot;&gt;타입을 추출해 주는 스크립트&lt;/a&gt;도 실행합니다. 이렇게 하면 원하는 아이콘을 아이콘 컴포넌트를 사용하여 화면에 나타낼 수 있습니다.&lt;/p&gt;

&lt;p&gt;정리하면, 새로운 아이콘 파일과 색상 코드가 적힌 CSS 파일을 지정된 폴더에 넣고 스크립트만 돌리면 등록이 손쉽게 완료됩니다.&lt;/p&gt;

&lt;h3 id=&quot;42-아이콘-등록-방식을-자동화해보자-&quot;&gt;4.2 아이콘 등록 방식을 자동화해보자 &lt;a name=&quot;4.2-아이콘-등록-방식을-자동화-해보자&quot;&gt;&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;아이콘을 등록할 때마다 스크립트를 실행해야 합니다. 매번 스크립트 파일을 찾아보면서 실행하기엔 불편한 점이 많아 스크립트 자동화를 진행했습니다.
Node.js의 패키지를 관리하는 NPM을 이용하여 스크립트를 명령어 한 줄로 실행할 수 있도록 package.json 파일에 &lt;code class=&quot;highlighter-rouge&quot;&gt;scripts&lt;/code&gt;를 작성했습니다.&lt;/p&gt;

&lt;div class=&quot;language-json highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nl&quot;&gt;&quot;scripts&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;build-icon&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;node build/convertSvgPath.js &amp;amp;&amp;amp; npm run build-icon-palette &amp;amp;&amp;amp; npm run build-icon-type&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;npm run build-icon&lt;/code&gt;을 터미널에 입력하면 작성한 스크립트를 한 번에 실행시킬 수 있습니다.&lt;/p&gt;

&lt;h2 id=&quot;5-문제점-해결-&quot;&gt;5. 문제점 해결 &lt;a name=&quot;5.-문제점-해결&quot;&gt;&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;매번 기존에 있던 아이콘부터 새로운 아이콘까지 전부 넣고 외부 서비스를 사용하여 아이콘 폰트 파일로 만들어야 했었습니다.
아이콘 폰트 파일을 만들면 추가해야 할 파일도 여러 개고, 아이콘 색상을 모든 파일에 직접 추가해야 했었습니다. 
이 과정에서 휴먼 에러도 발생하고 리소스도 많이 필요했습니다.&lt;/p&gt;

&lt;p&gt;이제는 새로운 아이콘만 폴더에 추가하여 스크립트 실행만으로 손쉽게 아이콘을 등록하여 사용할 수 있게 됐습니다. 
더 이상 외부 서비스를 사용하지 않아도 되고 아이콘 색상도 손쉽게 바꿀 수 있게 됐습니다. 
스크립트 실행을 명령어 한 줄로 빌드 하여 아이콘 등록 과정을 자동화하며 사용자의 경험을 개선할 수 있었습니다.&lt;br /&gt;
수동으로 작성했을 때 발생하는 휴먼 에러를 방지할 수 있다는 점에서도 의미 있는 작업이었습니다.&lt;/p&gt;

&lt;h2 id=&quot;6-개선할-점-&quot;&gt;6. 개선할 점 &lt;a name=&quot;6.-개선할-점&quot;&gt;&lt;/a&gt;&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://react-svgr.com/docs/webpack/&quot;&gt;SVGR&lt;/a&gt;을 활용한 SVG Path 파싱&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;SVG Path를 파싱 하는 코드를 작성했지만, SVG의 형태에 따라 Path를 파싱 하지 못하는 경우가 있습니다.&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;SVGR을 활용해서 이런 경우를 방지할 수 있을 것으로 기대합니다.&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;&lt;img src=&quot;/img/icon-component/codeReview.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Figma와 연동&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;아이콘을 등록하는 방식 중 대부분을 자동화하는데 성공했지만 SVG 파일을 디렉터리에 넣는 과정은 여전히 수기로 진행해야 합니다.&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;디자이너분들이 아이콘 파일을 Figma를 통해 전달해 주시기 때문에, Figma와 연동 혹은 다른 방법을 통해 모든 과정을 자동화할 예정입니다.&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;7-마무리-&quot;&gt;7. 마무리 &lt;a name=&quot;7.-마무리&quot;&gt;&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;쏘카 웹 프론트엔드 팀에서 React Icon Component를 개발한 과정에 대해 알아보았습니다. 외부 서비스는 사용자 경험을 중요시하는 것처럼 회사 내 개발자들이 사용하는 서비스는 개발자 경험이 중요합니다.&lt;/p&gt;

&lt;p&gt;컴포넌트는 한번 개발되면 여러 개발자들이 공동으로 사용하기 때문에 개발할 때 ‘개발자 경험 향상’을 중점으로 두고 진행했습니다. 팀원들이 새로운 아이콘 등록 방식과 아이콘 컴포넌트를 잘 사용하고 있는 걸 보면 목적을 잘 달성했다는 생각이 듭니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/icon-component/commentLisbon.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/icon-component/commentDosii.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;내가 개발한 것을 통해서 다른 누군가가 편해진다는 것은 뿌듯한 일입니다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;긴 글 읽어주셔서 감사합니다. 지금까지 쏘카 웹 프론트엔드 팀의 시에나, 블랑이었습니다.&lt;/p&gt;</content><author><name>sienna, blanc</name></author><category term="dev" /><category term="web" /><category term="frontend" /><category term="react" /><category term="design system" /><summary type="html">안녕하세요. 쏘카 웹 프론트엔드 개발자 시에나, 블랑입니다.</summary></entry><entry><title type="html">주니어 PM의 ‘중요한 고객’ 발굴하기</title><link href="https://tech.socarcorp.kr/product/2022/08/26/important-customer.html" rel="alternate" type="text/html" title="주니어 PM의 '중요한 고객' 발굴하기" /><published>2022-08-26T00:00:00+00:00</published><updated>2022-08-26T00:00:00+00:00</updated><id>https://tech.socarcorp.kr/product/2022/08/26/important-customer</id><content type="html" xml:base="https://tech.socarcorp.kr/product/2022/08/26/important-customer.html">&lt;p&gt;안녕하세요. 쏘카에서 고객용 제품을 담당하는 PM1 팀의 PM(Product Manager) 버키입니다. 저는 쏘카 입사 후 이제 막 수습 기간을 종료한 주니어 PM입니다. 이 글은 서비스 기획자였던 제가 쏘카의 PM으로서 실무에 투입하기 전 수습 과제를 진행하며 알게 된 방법론과 풀어내는 과정에서 배운 사고과정, 쏘카 프로덕트 본부는 어떻게 함께 자라는가?를 공유하기 위한 글입니다.&lt;/p&gt;

&lt;p&gt;다음 내용이 궁금하시다면 끝까지 함께해 주세요. 😃&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;쏘카 PM은 어떤 관점으로 일하는지 궁금하신 분&lt;/li&gt;
  &lt;li&gt;장기적으로 중요한 고객을 찾고자 하시는 분&lt;/li&gt;
  &lt;li&gt;고객 ↔ 비즈니스 가치의 조율점을 고민하시는 분&lt;/li&gt;
  &lt;li&gt;서비스 기획자 경험을 기반으로 쏘카 PM으로 함께하고자 하시는 분&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;목차&quot;&gt;목차&lt;/h2&gt;

&lt;p&gt;글의 목차는 다음과 같습니다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;#why&quot;&gt;글을 쓴 이유&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#defintion&quot;&gt;장기적인 관점에서 중요한 고객의 정의&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;장기적인 관점에서 중요한 고객을 왜 찾아야 하는가?&lt;/li&gt;
      &lt;li&gt;중요한 고객은 누구인가?&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#find-client&quot;&gt;고객 관점에서 장기적으로 중요한 고객 찾기&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#find-business&quot;&gt;비즈니스 관점에서 장기적으로 중요한 고객 찾기&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;행동목표, 5 why로 파고들기&lt;/li&gt;
      &lt;li&gt;액션 포인트, 수치 목표 연결하기&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#sync&quot;&gt;고객 ↔ 비즈니스 관점 싱크 하기&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;교차점 찾기&lt;/li&gt;
      &lt;li&gt;실효성 있는 액션 플랜을 위한 방법 (feat. 코호트 분석)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#wrap-up&quot;&gt;느낀 점&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;1-글을-쓴-이유-&quot;&gt;1. 글을 쓴 이유 &lt;a name=&quot;why&quot;&gt;&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/img/important-customer/pm-avator.png&quot; alt=&quot;혼란스러운 주니어 PM&quot; /&gt;&lt;/p&gt;

&lt;p&gt;약 2년 동안 서비스 기획자로 커리어를 쌓아오다 쏘카의 PM이 된 지 어엿 4개월 차, 입사 직후 PM의 R&amp;amp;R에 대해 많은 궁금증과 혼란이 있었습니다. 분명 서비스 기획자와 사고하는 큰 방향성은 다르지 않은 것 같은데 미묘하게 다른 부분들이 있었고, “앞으로 실무, 커리어를 위한 PM 적 사고로 어떻게 전환하지?”가 가장 큰 고민거리였습니다.&lt;/p&gt;

&lt;p&gt;우선 서비스 기획자와 쏘카의 PM은 어떤 점에서 차이를 보이는지 데스크 리서치와 프로덕트 본부의 온보딩을 통해 다음과 같은 차이점을 발견할 수 있었습니다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;👉🏽 서비스 기획자 (이전 경험)&lt;/p&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;커뮤니케이션 형태&lt;/code&gt; 기능 조직 형태로 기획, 디자인, 개발 팀이 분리되어 있음. 프로젝트가 생성됨에 따라 협업하게 됨&lt;/li&gt;
    &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;조직문화 형태&lt;/code&gt; 수직적인 의사결정 체계, 워터폴 운영 방식&lt;/li&gt;
    &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;의사결정 형태&lt;/code&gt; 디렉터급에서 비즈니스 의사결정이 이뤄지고 여기에 의견을 덧붙일 수 있음. 이후 화면 기획서, 요구사항 정의서 등과 같은 산출물로 디자인, 개발팀과 커뮤니케이션을 진행함&lt;/li&gt;
  &lt;/ul&gt;

  &lt;p&gt;👉🏽 쏘카 PM (현재)&lt;/p&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;커뮤니케이션 형태&lt;/code&gt; 목적 조직 형태로 ‘프로덕트’를 기준으로 팀이 형성됨. 기획, 디자인, 개발 구성원이 자발적이고 적극적인 태도로 최종 산출물(결과)를 만들게 됨&lt;/li&gt;
    &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;조직문화 형태&lt;/code&gt; 수평적인 의사결정 체계, 애자일 방법론 운영 방식 (작은 구성 요소를 신속하고 빠른 주기로, 반복적으로 개선/제공하여 고객 만족도를 높이는 것)&lt;/li&gt;
    &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;의사결정 형태&lt;/code&gt; 프로덕트를 기준으로 생성된 팀에서 전사&amp;amp;프로젝트 목표 맥락 안에서 자유롭게 의견을 발제하고 의사결정을 이룰 수 있음. 이 과정에서 로드맵과 방향성 설정의 리더십을 기반으로 자유도가 있음&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;p&gt;쏘카의 PM이라고 자신 있게 말하기 위해서 ‘PM의 사고방식’을 함양하는 것이 가장 중요한 목표라고 생각하고 있던 찰나 적응을 돕기 위한 수단으로 수습 과제가 있다는 것을 알게 되었습니다.&lt;/p&gt;

&lt;p&gt;마침 리더와 1on1 미팅을 진행 중 ‘고객’에 대해 진지하게 고민해 볼 수 있는 주제로 과제를 진행하는 것이 어떤지 제안을 받았습니다.  ‘고객’이라는 큰 주제로 쏘카 PM, 더 나아가 고객을 위해 프로덕트를 만드는 PM으로서 사고하는 방법을 익히고 쏘카에 적응하는 시간을 가질 수 있는 기회였습니다.&lt;/p&gt;

&lt;p&gt;그럼 이제부터 본격적으로 과제로 선택한 주제인 ‘고객’, 그중에서도 장기적인 관점에서 중요한 고객을 선별하기 위해 고민했던 부분들을 함께 나누고자 합니다.&lt;/p&gt;

&lt;h2 id=&quot;2-장기적인-관점에서-중요한-고객-&quot;&gt;2. 장기적인 관점에서 중요한 고객 &lt;a name=&quot;definition&quot;&gt;&lt;/a&gt;&lt;/h2&gt;

&lt;h3 id=&quot;21-장기적인-관점에서-중요한-고객을-왜-찾아야-하는가&quot;&gt;2.1 장기적인 관점에서 중요한 고객을 왜 찾아야 하는가?&lt;/h3&gt;

&lt;p&gt;먼저 장기적으로 중요한 고객(이하 중요한 고객)은 누구일까요?&lt;/p&gt;

&lt;p&gt;우선 ‘장기적’의 의미는 제품 라이프 사이클(Product Life Cycle) 측면에서 쇠퇴기 전까지의 기간, 즉 제품의 도입기부터 성장/성숙기라고 정의 내려 볼 수 있습니다. 쇠퇴기 전까지로 한정 지은 이유는 제품이 쇠퇴기에 진입하면 이후 시장에서 제품의 기회를 기대할 수 없기 때문입니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/important-customer/product-life-cycle.png&quot; alt=&quot;그림 1) 제품 라이프 사이클&quot; /&gt;&lt;em&gt;그림 1) 제품 라이프 사이클 / 출처 : &lt;a href=&quot;https://haltian.com/resource/new-product-development-cycle-infographic/&quot;&gt;https://haltian.com/resource/new-product-development-cycle-infographic/&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;제품의 쇠퇴기를 늦추려면 성장/성숙기 기간을 길게 만들어야 합니다. 제품, 비즈니스가 존재하기 위한 타임라인인 성장/성숙기의 ‘장기성’ 안에서 목표해야 하는 사용자를 ‘중요한 고객’이라고 말해볼 수 있습니다.&lt;/p&gt;

&lt;p&gt;하지만 우리에게 시간과 리소스는 언제나 한정되어 있기 때문에 이 모든 것을 가능케 할 확률이 가장 높은 ‘중요한 고객’을 우선순위로 액션 플랜을 수립해야 합니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/important-customer/polaris-metric.png&quot; alt=&quot;그림 2) 북극성 지표를 통해 제품의 올바른 성공을 측정할 수 있습니다.&quot; /&gt;&lt;em&gt;그림 2) 북극성 지표를 통해 제품의 올바른 성공을 측정할 수 있습니다&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;중요한 고객을 선별하기 위해서 우선 PM의 전문 영역이라고 할 수 있는 제품 측면에서 궁극적인 목표부터 설정해야 합니다.&lt;/p&gt;

&lt;p&gt;“목표? 그냥 매출로 설정하자! 그게 제일 직관적이고 제품(혹은 비즈니스)의 가치는 언제나 매출로 산정하지 않냐!”라고 질문하실 수도 있을 것 같습니다. 하지만 매출은 오직 비즈니스 관점만 반영한 지표이며 우리가 제품에 신규 기능이나 개선 사항을 반영한 후에만 확인할 수 있는 수동적인 지표인 후행 지표라고 답변드려 볼 수 있을 것 같습니다.&lt;/p&gt;

&lt;p&gt;더불어 후행 지표는 판단의 근거로 활용할 수 없기 때문에 좋은 지표라고 보긴 어렵습니다. 그렇다면 어떤 지표가 ‘목표’로 지정할 만하며 액션을 통해 조정할 수 있는 능동적인 성격을 띤 지표일까요?&lt;/p&gt;

&lt;p&gt;이에 대해선 제품, 고객, 비즈니스 등 다양한 관점의 조건을 포함하며 제품이 ‘진짜로’ 성장하고 있는지 판단할 수 있는 ‘북극성 지표’라는 개념으로 설명드리겠습니다. 북극성 지표는 &lt;strong&gt;제품이 고객에게 전달하고자 하는 가장 핵심적인 가치가 반영된&lt;/strong&gt; 단 하나의 핵심 지표이며 관점입니다.&lt;/p&gt;

&lt;p&gt;북극성 지표의 특성을 좀 더 살펴보자면 다음과 같습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;실제 고객에게 실현된 가치를 반영해야 하며 액션을 통해 정량적인 임팩트로 산출할 수 있어야 합니다.&lt;/li&gt;
  &lt;li&gt;우리가 행하는 각 액션의 최종 목표로 귀결될 수 있어야 합니다.&lt;/li&gt;
  &lt;li&gt;‘매출’과 같이 통제 불가한 후행지표가 아닌 액션을 통해 판단하고 조정할 수 있는 선행 지표여야 합니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;조금 더 빠른 이해를 위해 다른 기업의 북극성 지표 예시를 함께 살펴보겠습니다.&lt;/p&gt;

&lt;p&gt;아래 그림 3과 같이 Airbnb의 경우 ‘n 박 예약’, Spotify의 경우 ‘음악 재생 시간’을 북극성 지표로 설정한 것을 볼 수 있습니다. 
아래 예시에서 볼 수 있듯 각 기업이 설정한 북극성 지표의 공통점은 액션을 통해 통제 가능한 선행 지표라는 것입니다. 이는 통제 불가한 후행지표의 특성과 대비됩니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/important-customer/polaris-metric-of-companies.png&quot; alt=&quot;그림 3) 여러 기업의 북극성 지표&quot; /&gt;&lt;em&gt;그림 3) 여러 기업의 북극성 지표 / 출처 : &lt;a href=&quot;https://growwithward.com/north-star-metric/&quot;&gt;https://growwithward.com/north-star-metric/&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;북극성 지표를 증분 시키기 위해 해볼 수 있는 액션은 너무도 다양합니다. 우리가 행할 액션을 조금 더 구체적으로 설정하기 위해 북극성 지표와 상관관계에 있는 투입 지표를 추가로 고려해 볼 수 있습니다.&lt;/p&gt;

&lt;p&gt;이 투입 지표가 북극성 지표와 매출에 어떤 영향을 주는지 살펴보면서 액션을 조정하고 목표하는 방향으로 나아갈 수 있습니다.&lt;/p&gt;

&lt;p&gt;아래는 음악 스트리밍 서비스인 Spotify의 북극성 지표와 상관관계에 있는 투입 지표 예시입니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/important-customer/polaris-metric-of-spotify.png&quot; alt=&quot;그림 4) Spotify의 북극성 지표, 투입 지표&quot; /&gt;&lt;em&gt;그림 4) Spotify의 북극성 지표, 투입 지표 / 출처 : &lt;a href=&quot;https://growwithward.com/north-star-metric/&quot;&gt;https://growwithward.com/north-star-metric/&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Spotify가 최종 목표를 ‘매출’로 바라보고 있는지 정확히 알 수 없지만 ‘음악 재생 시간’으로 북극성 지표를 설정하였으며 투입 지표로 ‘더 자주 사용자가 앱을 방문하도록 하는 것’, ‘사용자가 앱에서 보내는 시간을 더 길게 하는 것’에 집중하고 있음을 알 수 있습니다.&lt;/p&gt;

&lt;p&gt;이렇게 되면 방문율, 사용자가 앱에 머문 시간을 뜻하는 세션 시간에 집중하여 이 두 지표를 증가시키기 위한 액션을 고려할 수 있게 됩니다.&lt;/p&gt;

&lt;p&gt;그럼 Spotify의 예시를 살펴봤으니 제품, 고객, 비즈니스 등 다양한 관점을 포함하여 제품 측면에서 쏘카의 북극성 지표를 위해 다음의 기준에 의해 함께 설정해 보도록 하겠습니다.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;아래의 북극성 지표는 쏘카의 공식적인 북극성 지표가 아닌 개인 과제로 도출된 지표입니다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;고객의 성공 순간을 반영했는가?
    &lt;ul&gt;
      &lt;li&gt;쏘카에서 고객들의 ‘성공’ 순간은 쏘카를 통해 편리한 경험을 얻고, 만족하는 순간입니다.&lt;/li&gt;
      &lt;li&gt;그러기 위해선 단순 ‘예약’에만 그치면 안 되고 차량 반납을 통해 ‘경험을 완료했다.’는 근거가 있어야 합니다 = &lt;strong&gt;‘반납’&lt;/strong&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;모든 고객이 ‘가치’를 얻는 내용인가?
    &lt;ul&gt;
      &lt;li&gt;쏘카에서 ‘가치’란 쏘카에서 제공되는 제품인 앱과 차를 통한 이동 경험에서 얻을 수 있는 것입니다.&lt;/li&gt;
      &lt;li&gt;더불어 “가치를 얻었다.”란 앱과 차를 통한 경험이 완수된 시점 기준이 포함되어야 합니다.&lt;/li&gt;
      &lt;li&gt;경험이 완료되지 않았다면 정확히 가치를 100% 경험했다, 얻었다고 보기는 힘듭니다. = &lt;strong&gt;‘반납’&lt;/strong&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;측정 가능한가?
    &lt;ul&gt;
      &lt;li&gt;일, 주, 월별로 측정 가능합니다. = &lt;strong&gt;‘반납 건 수’&lt;/strong&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;투입 지표를 통해 통제 가능한 요인인가?
    &lt;ul&gt;
      &lt;li&gt;앱과 차를 통한 경험 과정(예약 전(앱) &amp;gt; 이용 중 및 반납(앱&amp;amp;차량))에서 과정을 세분화해 관련된 다양한 투입 지표를 통해 북극성 지표를 통제할 수 있습니다.&lt;/li&gt;
      &lt;li&gt;즉, 다양한 투입 지표에 따른 &lt;strong&gt;반납 건 수의 증감을 확인&lt;/strong&gt;할 수 있습니다&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;비즈니스 관점에서 성장을 직접 반영하는가?
    &lt;ul&gt;
      &lt;li&gt;예약이 발생한 시점에선 고객이 언제든지 예약 취소를 할 수 있으므로 비즈니스 관점에서 성장이 발생하지 않습니다.&lt;/li&gt;
      &lt;li&gt;하지만 ‘반납’ 시 고객은 이용료를 지불해야 하므로 &lt;strong&gt;비즈니스의 성장을 반영&lt;/strong&gt;한다고 볼 수 있습니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;빠르게 판단할 수 있는가?
    &lt;ul&gt;
      &lt;li&gt;‘반납 건 수’ 조회 기준을 &lt;strong&gt;시간/일자별로 설정하여 빠르게 판단&lt;/strong&gt;할 수 있습니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;위 기준에 따라 최종적으로 도출한 제품 측면에서 쏘카의 북극성 지표를 &lt;strong&gt;‘월 반납 건수 증분’&lt;/strong&gt;이라고 결론지어 볼 수 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/important-customer/polaris-metric-of-socar.png&quot; alt=&quot;그림 5) 제품 측면에서 쏘카의 북극성 지표&quot; /&gt;&lt;em&gt;그림 5) 제품 측면에서 쏘카의 북극성 지표&lt;/em&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;쏘카 프로덕트 본부는 이렇게 일해요 1 : 자발적인 스터디&lt;/code&gt;&lt;/strong&gt; &lt;br /&gt; 
북극성 지표, 선행&amp;amp;후행지표, 투입 지표.. 모두 똑같은 ‘지표’이지만 위계가 다릅니다. 
저 역시 쏘카 프로덕트 본부의 일원이 되기 전엔 이러한 개념에 대해 알고 있지 못했습니다. 😉
쏘카 프로덕트 본부에선 실무를 진행하며 부족한 부분이 있다고 느낄 경우 누구나, 자발적으로 
스터디를 만들 수 있습니다. 지금도 그로스 해킹, 가격 전략, 심리, 데이터 분석 등 다양한 주제로 활발히 
진행되고 있습니다! &lt;br /&gt; 
글에 언급되는 다양한 지표에 대한 개념은 그로스 해킹 스터디에서 배우게 되었습니다. 해당 스터디에서 동료들과 지표의 개념을 익히고 프로젝트에 대입하여 고민하는 기회가 있었습니다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;22-중요한-고객은-누구인가&quot;&gt;2.2 중요한 고객은 누구인가?&lt;/h3&gt;

&lt;p&gt;그럼 중요한 고객은 누구일까요?  장기적으로 중요한 고객의 배경을 ‘제품’으로 설정하였기 때문에 우리에게는 ‘제품 시각’으로 사고하고 고민하여 그 안에 존재할 수 있는 중요한 고객을 찾는 과정이 필요합니다.&lt;/p&gt;

&lt;p&gt;제품 시각은 곧 제품을 이용하는 고객 중심으로 사고하는 ‘고객 관점’과 이를 지속 가능하게 제공할 수 있는 사업 측면에서의 ‘비즈니스 관점’을 함께 고려하는 것을 의미합니다.&lt;/p&gt;

&lt;p&gt;획기적인 기술과 말도 안 되게 편리하고 아름다운 UI/UX를 제공한다 하더라도 그것이 우리 제품을 사용하는 고객의 니즈가 아니라면 그들에게 우리 제품은 혁신적인 것도, 사용할 만한 것도 아니게 될 가능성이 큽니다.&lt;/p&gt;

&lt;p&gt;하지만 여기서 중요한 것은 고객 관점으로만 제품을 제작하면 안 된다는 것입니다. 고객 관점을 초석으로 발견한 고객의 니즈(문제)는 비즈니스 관점에선 곧 기회입니다. 이 기회를 활용해 사업적으로 얻고자 하는 것은 무엇인지,  “어디로, 어떻게 고객을 드라이브할 것인가?”라는 목표점이 있어야 시장 존속 가능한 제품 제작이 가능하며 이를  통해 얻은 가치를 고객에게 환원하여 시장에서 오랫동안 살아남는 제품을 만들 수 있습니다.&lt;/p&gt;

&lt;p&gt;사용자 측면의 고객 관점과 공급자 측면의 비즈니스 관점을 모두 고려한 ‘제품 시각’, 더 나아가 제품 시각에서 가장 중요한 고객을 찾았을 때 비로소 제품을 통해 가치를 얻는 고객 수의 증분과 이를 통한 매출, 브랜드 이미지 확산을 통한 투자로 성장/성숙기는 길어질 수 있으며 쇠퇴기의 도래를 막을 수 있습니다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;쏘카 프로덕트 본부는 이렇게 일해요 2 : 함께 자랍니다.&lt;/code&gt;&lt;/strong&gt; &lt;br /&gt; 
처음 과제를 진행할 때 생각했던 포인트는 [북극성 지표에 따른 중요한 고객 찾기]였습니다. 
하지만 스스로 생각하기에도 “비약이 있는 것 같은데?”란 느낌을 받았는데요.
이에 리더, 동료들에게 솔직한 고민으로 대화를 나누며 힌트를 얻을 수 있었습니다.&lt;/p&gt;
  &lt;ul&gt;
    &lt;li&gt;안톤 :  버키! 고객 관점을 세분화하기 위해 고객이 제품을 이용하면서 겪는 단계인 퍼널(Funnel)로 쪼개어서 고민해 보는 건 어떨까요? 과거에 관련한 내용이 있었는데 공유드릴게요. 참고해 보세요!&lt;/li&gt;
    &lt;li&gt;타미 : 고객 관점만으로 비약이 있다고 느껴진다면 상반되는 개념인 비즈니스 관점도 생각해 보는 건 어떨까요? 우리가 고객에게 뭘 원하는지, 고객은 뭘 원하는지 함께 살펴보면 그 접점에서 우리가 집중해야 하는 부분을 찾을 수 있을 것 같아요!&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;/img/important-customer/customer-diagram.png&quot; alt=&quot;그림 6) 제품 시각에서 중요한 고객을 왜 찾아야 하는가?&quot; /&gt;&lt;em&gt;그림 6) 제품 시각에서 중요한 고객을 왜 찾아야 하는가?&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;그림 6의 벤 다이어그램을 통해 비즈니스 관점과 고객 관점의 교차점에 있는 중요한 고객을 왜 찾아야 하는지 조금 더 살펴보겠습니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;1. 오직 비즈니스 관점에서만 고려한 중요한 고객 (a\b)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;효과
    &lt;ul&gt;
      &lt;li&gt;신규 사용자 유치, 매출 증분 등 오직 비즈니스 관점의 성공을 위해서만 제품을 개선할 가능성이 높아집니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;액션 예시
    &lt;ul&gt;
      &lt;li&gt;오직 ‘많은 수의’ 신규 사용자 유치만을 위해 이벤트, 프로모션을 상시 진행하고 이후 사용자 행동 패턴 분석 및 후속 조치는 고려하지 않음&lt;/li&gt;
      &lt;li&gt;오직 ‘매출’만을 위해 지역별 수요는 고려하지 않고 모든 차량에 대한 가격 인상을 단행함&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;2. 오직 고객 관점에서만 고려한 중요한 고객 (b\a)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;효과
    &lt;ul&gt;
      &lt;li&gt;앱 리뷰, 인터뷰, 사용성 등을 통해 ‘고객’이 불편을 겪는 부분으로만 제품을 개선할 가능성이 높아집니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;액션 예시
    &lt;ul&gt;
      &lt;li&gt;특정 지역에 ‘쏘카 존이 부족하다.’는 의견만 반영하여 해당 지역에만 쏘카 존을 증설함&lt;/li&gt;
      &lt;li&gt;‘특정 차량을 타고 싶다.’는 의견만 반영하여 해당 차량을 구매 및 제공함&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;3. 비즈니스 관점과 고객 관점 모두를 고려한 교집합에 있는 고객 군 = 중요한 고객(a ∩ b)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;효과
    &lt;ul&gt;
      &lt;li&gt;비즈니스 관점 및 고객 관점을 모두 고려하여 제품을 개선하고 북극성 지표를 통해 이를 검증하며 전략을 수정할 수 있습니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;액션 예시
    &lt;ul&gt;
      &lt;li&gt;고객 관점에서 &lt;strong&gt;주중에 쏘카를 사용하는 고객들이 ‘쿠폰’사용에 어려움&lt;/strong&gt;을 겪고 있다는 것을 발견하고 비즈니스 관점에서 &lt;strong&gt;‘쿠폰’ 사용이 가장 저조한 지역/차종 등을 고려&lt;/strong&gt;하여 새로운 쿠폰 기획을 통해 ‘쿠폰 사용성’ 측면에서 효과를 검증함 → 사용성 증대 시 이후 전 지역, 전 차종으로 영향 범위 확대함&lt;/li&gt;
      &lt;li&gt;고객 관점에서 &lt;strong&gt;‘여행지에선 조금 더 많은 인원이 탑승 가능한 차량’을 원한다&lt;/strong&gt;는 니즈를 발견하고 비즈니스 관점에서 &lt;strong&gt;가장 대여가 활발한 여행 지역을 선정&lt;/strong&gt;하여 차종을 다양화한 후 ‘대여 기준’에서 효과를 검증함 → 효과를 입증한 후 ‘여행지’라는 지역의 특수성을 고려하여 [여름맞이 캠핑카 프로모션] 등 차종 다양화, 마케팅 전략으로 영향 범위 확대함&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;3-고객-관점에서-장기적으로-중요한-고객-찾기-&quot;&gt;3. 고객 관점에서 장기적으로 중요한 고객 찾기 &lt;a name=&quot;find-client&quot;&gt;&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;그럼 이제부터 고객 관점에서 장기적으로 중요한 고객이 누구인지 한번 찾아보도록 하겠습니다. 아래 그림 7은 고객 관점에서 중요한 고객을 찾기 위해 진행했던 단계입니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/important-customer/customer-view-stage.png&quot; alt=&quot;그림 7) 고객 관점에서 장기적으로 중요한 고객 찾기 진행 단계&quot; /&gt;&lt;em&gt;그림 7) 고객 관점에서 장기적으로 중요한 고객 찾기 진행 단계&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;중요한 고객을 마케팅, 사업, 운영 관점에서 고민해 볼 수도 있지만 이번 글에선 사고의 주체가 PM이기 때문에 제품 관점에 초점을 맞춰 고객이 제품을 이용하면서 겪는 단계인 퍼널(Funnel)을 기준으로 세분화하여 찾아보겠습니다.&lt;/p&gt;

&lt;p&gt;고객이 앱을 이용하면서 겪는 단계를 세분화하기 위해서 ‘고객 여정 지도’라는 개념을 이용해 볼 수 있습니다. 
고객 여정 지도란 고객이 서비스 또는 제품과 관련된 모든 접점에서 고객의 경험하는 여정을 시각화한 단계를 말합니다. 고객 여정 지도를 활용함으로써 사고 기준을 고객에 둘 수 있으며 이를 통해 고객 중심 가치로 사고할 수 있습니다.&lt;/p&gt;

&lt;p&gt;이를 통해 쏘카의 고객 여정 지도를 크게 다음 부분으로 나눠볼 수 있습니다. 더불어 퍼널을 고려할 때 고객 관점 외에 해적 지표, 비즈니스 관점을 추가함으로써 어디로 고객의 니즈를 드라이브할 수 있을지 대략적으로 고려할 수 있었습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/important-customer/funnel-stages.png&quot; alt=&quot;그림 8) 쏘카를 이용하기 위한 고객 여정 지도&quot; /&gt;&lt;em&gt;그림 8) 쏘카를 이용하기 위한 고객 여정 지도&lt;/em&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;💡 &lt;strong&gt;해적 지표(AARRR)란?&lt;/strong&gt;  &lt;br /&gt; 
기업이 사업의 성장을 평가하기 위해 추적해야 할 5가지 사용자 행동 지표인 획득(Acquisition), 활성화(Activation), 유지(Retention), 추천(Referral), 수익(Revenue)의 이니셜을 딴 약자입니다.
해적 지표의 목적은 다음과 같이 크게 2가지가 있습니다.&lt;/p&gt;
  &lt;ol&gt;
    &lt;li&gt;기업이 비즈니스의 건전성에 직접적인 영향을 미칠 수 있는 지표에만 집중할 수 있도록 합니다.&lt;/li&gt;
    &lt;li&gt;올바른 데이터를 사용하여 제품 관리 및 마케팅 노력의 성공을 가늠할 수 있도록 하고, 효과가 없는 마케팅 계획을 개선하는 데 도움이 됩니다. &lt;br /&gt;&lt;/li&gt;
  &lt;/ol&gt;

  &lt;p&gt;출처 : &lt;a href=&quot;https://mixpanel.com/ko/blog/aarrr-pirate-metrics/&quot;&gt;https://mixpanel.com/ko/blog/aarrr-pirate-metrics/&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;여러 퍼널 중 한 단계인 ‘탐색/조회’에 집중하여 과정을 설명드리겠습니다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;고객 여정 지도에 의해 퍼널을 분리한 뒤  각 퍼널에서 고객이 할 수 있는 행동들과 해당 단계에서의 고객의 니즈를 나열합니다.
    &lt;ul&gt;
      &lt;li&gt;고객이 할 수 있는 행동 : 고객이 최종 결정을 위해 ‘할 수 있는’ 행동들을 아이데이션 합니다.&lt;/li&gt;
      &lt;li&gt;해당 단계에서 고객의 니즈 : 고객이 최종 결정 과정에서 가질 수 있는 니즈를 앱 리뷰, CS 내용, 동료 인터뷰 내용을 참고하여 갈음합니다. (실제 업무에선 고객 니즈를 발굴할 때 설문조사, 인터뷰, &lt;a href=&quot;https://brunch.co.kr/@sweetsavasana/41&quot;&gt;FGI(Focus Group Interview)&lt;/a&gt;, 데이터 분석 등을 활용하곤 합니다.)&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;&lt;img src=&quot;/img/important-customer/searching-stage.png&quot; alt=&quot;그림 9) 탐색/조회 단계에서 고객이 할 수 있는 행동 및 고객의 니즈&quot; /&gt;&lt;em&gt;그림 9) 탐색/조회 단계에서 고객이 할 수 있는 행동 및 고객의 니즈&lt;/em&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;탐색/조회 퍼널 내 존재할 수 있으며 위의 니즈를 가질 수 있는 세그먼트를 카테고리 별로 나열하고 세분화합니다.&lt;/p&gt;

    &lt;p&gt;e.g. 멤버십 여부에 따라 → 멤버십이 있는(패스포트 구독자) / 없는(비구독자)&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;/img/important-customer/searching-stage-segments.png&quot; alt=&quot;그림 10) 탐색/조회 단계에서 니즈를 가질 수 있는 다양한 세그먼트&quot; /&gt;&lt;em&gt;그림 10) 탐색/조회 단계에서 니즈를 가질 수 있는 다양한 세그먼트&lt;/em&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;그 후 북극성 지표인 ‘월 반납 건 수’를 위해  모수(규모) 기준으로 세그먼트를 다음과 같이 분류합니다. 모수 기준으로 분류하는 이유는 실제 액션 전개 시 작은 액션에도 큰 임팩트를 낼 수 있는 세그먼트를 고려하기 위함입니다.
    &lt;ul&gt;
      &lt;li&gt;일반적인 경우 = Mass 고객 (임팩트가 큼)
        &lt;ul&gt;
          &lt;li&gt;정의 : 특정한 니즈, 페인 포인트 없이 일반적인 상황에 있는 고객 군을 의미합니다.&lt;/li&gt;
          &lt;li&gt;예시 : 개인회원, 신규 가입한 회원, 준회원(카드/면허 등록 여부에 따라)&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;특이한 상황 속에 있는 경우 = Specific 고객 (임팩트가 적음)
        &lt;ul&gt;
          &lt;li&gt;정의 : Mass 고객과는 반대로 모수 규모가 크지 않은, 즉 특이 상황에 있는 고객 군을 의미합니다.&lt;/li&gt;
          &lt;li&gt;예시 : 사고가 발생한 경우, 등록한 카드로 결제가 불가한 경우, 면허 등록 시 다양한 이유로 보류 처리된 회원&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;분류 과정 중 고객이 가질 수 있는 ‘성격’으로 볼 수 있는 경우 = 고객의 요소
        &lt;ul&gt;
          &lt;li&gt;정의 : 위 두 개의 고객 군을 나눈 기준과 별개로 고객이 가질 수 있는 성격(특성)을 의미합니다.&lt;/li&gt;
          &lt;li&gt;예시 : 경험 빈도 (예약 경험이 전무한, 회원 평균 대비 많은/적은, 예약 경험은 있으나 반납 경험이 없는) 등&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;&lt;img src=&quot;/img/important-customer/mass-and-specific.png&quot; alt=&quot;그림 11) 다양한 세그먼트를 일반적인 경우와 특이한 경우로 분리&quot; /&gt;&lt;em&gt;그림 11) 다양한 세그먼트를 일반적인 경우와 특이한 경우로 분리&lt;/em&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;그다음 최대한 다양하게 분류하기 위해 Mass 고객(일반적인 경우)와 고객의 요소를 조합하여 다양한 세그먼트를 고려합니다.&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;/img/important-customer/various-segments.png&quot; alt=&quot;그림 12) 일반적인 경우와 조합될 고객의 요소&quot; /&gt;&lt;em&gt;그림 12) 일반적인 경우와 조합될 고객의 요소&lt;/em&gt;&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;/img/important-customer/mass-segments.png&quot; alt=&quot;그림 13) Mass 고객(일반적인 경우)의 요소로 조합된 세그먼트&quot; /&gt;&lt;em&gt;그림 13) Mass 고객(일반적인 경우)과 고객의 요소로 조합된 세그먼트&lt;/em&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;그 후 북극성 지표인 ‘월 반납 건수’에 큰 영향을 미칠 수 있는 세그먼트(=중요한 고객)에서 집중해야 하는 고객을 직관적으로 찾아낼 수 있도록 x축은 예약 시도 횟수, y 축은 운행 완료 횟수인 사분면을 구성합니다. 
이 중 어느 분면에 위치한 세그먼트가 제품의 성장/성숙기를 길게 만들어 줄 수 있는 장기적으로 중요한 고객인지 살펴볼 수 있습니다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;실제 업무 시 데이터 사이언티스트 분들과 함께 협업하며 가설을 세우고, 데이터로 검증하며 임팩트 산출까지 하는 것이 일반적이나, 이번 글은 ‘사고하는 법’에 초점이 맞춰져 있으므로 데이터 검증 전, 사고 과정에서 도출된 중요 고객으로 갈음하였습니다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;/img/important-customer/quadrant.png&quot; alt=&quot;그림 14) 조합으로 새롭게 발견한 세그먼트를 사분면 위에 위치 시킨 모습&quot; /&gt;&lt;em&gt;그림 14) 조합으로 새롭게 발견한 세그먼트를 사분면 위에 위치 시킨 모습&lt;/em&gt;&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;No.&lt;/th&gt;
      &lt;th&gt;사분면 이름&lt;/th&gt;
      &lt;th&gt;정의&lt;/th&gt;
      &lt;th&gt;중요도 고려 사항&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;자연 증분 하는 유형&lt;/td&gt;
      &lt;td&gt;- 방문/탐색 조회를 통해 예약 시도하는 횟수가 많으며  &lt;br /&gt; - 시도 경험이 반납 횟수까지 영향을 미치는 유형&lt;/td&gt;
      &lt;td&gt;- 공급자 관점에서 큰 개선을 제공하지 않아도, 쏘카의 가치가 일상생활에서 필요한 유형  &lt;br /&gt; - Loyalty에 대한 보상, 할인 등을 통해 끈끈한 관계를 이어나갈 수 있는 유형&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;액션이 필요한 유형&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;- 방문/탐색 조회를 통해 예약 시도하는 횟수가 많지만  &lt;br /&gt; - 시도 경험이 반납 횟수로는 이어지지 않는 유형&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;- 방문/탐색은 활발하나 만족되지 않는 ‘페인 포인트’가 있어 예약/반납까진 이어지지 않는 유형 &lt;br /&gt; - 공급자 관점에서 해당 세그먼트를 분석해 제품 안에서 개선책을 제공해야 하는 유형  &lt;br /&gt; - 쏘카 제품에서 가장 많은 비율을 차지할 것으로 고려되는 유형&lt;/strong&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;사용자 유치 전략이 필요한 유형&lt;/td&gt;
      &lt;td&gt;- 방문/탐색 조회를 자주 하진 않지만,  &lt;br /&gt; - 평균 대비 조금 더 긴 텀으로 쏘카를 이용하는 유형&lt;/td&gt;
      &lt;td&gt;- 공급자 관점에서 제품을 개선하기보단 마케팅 전략이 조금 더 필요할 것으로 고려되는 유형  &lt;br /&gt; - 제품 관점에서만 개선 사항을 고려하긴 힘들 것으로 추측되는 유형&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;임팩트가 적은 유형&lt;/td&gt;
      &lt;td&gt;- 방문/탐색 조회를 자주 하지 않고  &lt;br /&gt; - 예약/반납 횟수도 거의 없는 유형&lt;/td&gt;
      &lt;td&gt;- 공급자 관점에서 제품을 개선하고, 마케팅 전략을 펼치기 위해 많은 리소스가 투입될 것으로 고려되는 유형 &lt;br /&gt; - 개선 보다 신사업 등을 통한 새로운 가치를 제공해야 할 것으로 추측되는 유형&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;em&gt;표 1) 조합으로 새롭게 발견한 세그먼트에 대한 설명&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&quot;4-비즈니스-관점에서-중요한-고객-찾기-&quot;&gt;4. 비즈니스 관점에서 중요한 고객 찾기 &lt;a name=&quot;find-business&quot;&gt;&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;고객 관점으로 중요한 고객을 선별했지만 이들이 “우리(비즈니스) 관점에서도 정말 장기적으로 중요한 고객일까?”라는 추가로 고민이 필요합니다. 이에 비즈니스 관점에서 중요한 고객을 한 번 더 찾아보는 과정을 진행했습니다. (고객 관점과 마찬가지로 ‘탐색/조회’단계를 중심으로 합니다.)&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/important-customer/business-view-stage.png&quot; alt=&quot;그림 15) 비즈니스 관점에서 중요한 고객 찾기 진행 단계 &quot; /&gt;&lt;em&gt;그림 15) 비즈니스 관점에서 중요한 고객 찾기 진행 단계&lt;/em&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;비즈니스 관점에서 퍼널 별 목표로 하는 성과 지표가 무엇인지 설정합니다.&lt;/p&gt;

    &lt;p&gt;성과 지표를 먼저 설정하는 이유는 뚜렷한 목표 지점을 통해 우리가 고객에게 원하는 것이 무엇인지 명확하게 생각하고, 개선하기 위한 액션 플랜도 명확한 &lt;strong&gt;성과 지표를 기반&lt;/strong&gt;으로 설정하기 위함입니다.&lt;/p&gt;

    &lt;p&gt;여기서 염두 해야 하는 것은 우리는 퍼널 별 성과 지표가 ‘월 반납 건수 증분’이라는 북극성 지표로 귀결될 수 있도록 해야 한다는 것입니다. (성과 지표는 앞에서 설명했던 투입지표와 동일한 맥락을 가집니다.)&lt;/p&gt;

    &lt;p&gt;하지만 성과 지표만을 목표로 지정하면 이를 위해 할 수 있는 액션은 헤아릴 수 없을 수 없을 정도로 다양하고 많을 것입니다. 이에 선행 지표를 설정하면 액션의 범위를 좁히고 방향성이 옳은지 빠르게 판단할 수 있습니다.&lt;/p&gt;

    &lt;p&gt;선행 지표는 구체적인 액션 플랜 수립이 가능하며 성과 지표와 상관관계에 있는 지표여야 합니다. 아래는 ‘월 반납 건 수 증분’이라는 북극성 지표 증분을 위해 상관관계에 있는 탐색/조회 단계에서의 성과 지표와 성과 지표 증분을 위해 세분화한 선행 지표 예시입니다.&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;/img/important-customer/leading-indicators.png&quot; alt=&quot;그림 16) 북극성 지표, 퍼널 별 성과 지표 이와 상관관계에 있는 선행지표&quot; /&gt;&lt;em&gt;그림 16) 북극성 지표, 퍼널 별 성과 지표 이와 상관관계에 있는 선행지표&lt;/em&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;선행 지표와 성과 지표를 고려해 고객에게 바라는 행동 목표와 해당 목표의 &lt;strong&gt;근본적인 원인을 찾기 위해 5 whys 도구를 이용&lt;/strong&gt;하였습니다.&lt;/p&gt;

    &lt;blockquote&gt;
      &lt;p&gt;💡 &lt;strong&gt;5 whys란?&lt;/strong&gt;  &lt;br /&gt; 
도요타의 Taiichi Ohno가 체계적인 문제 해결을 위해 개발한 도구입니다. 기본적인 형태는 문제에 대해 ‘왜’라고 질문하고, 거기서 나온 답에 대해 다시‘왜’라는 질문을 5번 던짐으로써 문제의 근원을 찾아나가는 것입니다.&lt;/p&gt;
    &lt;/blockquote&gt;

    &lt;p&gt;&lt;img src=&quot;/img/important-customer/5-whys.png&quot; alt=&quot;그림 17) 비즈니스 관점에서 고객에게 바라는 것 5 whys로 파고들기&quot; /&gt;&lt;em&gt;그림 17) 비즈니스 관점에서 고객에게 바라는 것 5 whys로 파고들기&lt;/em&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;5 whys로 구체화한 원인에 집중하여 선행지표와 성과 지표에 긍정적인 영향을 줄 수 있는 액션 플랜을 아이데이션 합니다. 이때 다양한 액션 플랜에 따라 지표가 얼마나 영향을 받을지 가늠해 볼 수 있습니다.&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;/img/important-customer/action-plan-ideation.png&quot; alt=&quot;그림 18) 5 whys로 구체화한 원인과 이를 해결하기 위한 액션 플랜 아이데이션, 결과 목표인 선행 지표 연결&quot; /&gt;&lt;em&gt;그림 18) 5 whys로 구체화한 원인과 이를 해결하기 위한 액션 플랜 아이데이션, 결과 목표인 선행 지표 연결&lt;/em&gt;&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;/img/important-customer/strategy-map.png&quot; alt=&quot;그림 19) 비즈니스 관점에서 도출한 전략 Map&quot; /&gt;&lt;em&gt;그림 19) 비즈니스 관점에서 도출한 전략 Map&lt;/em&gt;&lt;/p&gt;

    &lt;p&gt;비즈니스 관점에서 선행, 성과 지표 설정 및 행동 목표 구체화와 이를 통한 액션 플랜 아이데이션까지 해보며  위와 같은 전략 Map을 그려볼 수 있었습니다.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;하지만 아직까지 장기적인 관점에서 중요한 고객 군은 찾지 못했는데요. 액션 실행의 대상이 되는, 액션을 실행한 후 선행/성과/북극성 지표의 변화와 함께 살펴봐야 하는 중요한 고객은 대체 어떻게 찾을 수 있을까요?&lt;/p&gt;

&lt;p&gt;마지막 챕터에서는 앞에서 그려본 고객 관점 ↔ 비즈니스 관점의 교차점을 이용하여 장기적인 관점에서 중요한 고객을 찾는 과정을 살펴보겠습니다.&lt;/p&gt;

&lt;h2 id=&quot;5-고객--비즈니스-관점-싱크-하기-&quot;&gt;5. 고객 ↔ 비즈니스 관점 싱크 하기 &lt;a name=&quot;sync&quot;&gt;&lt;/a&gt;&lt;/h2&gt;

&lt;h3 id=&quot;51-교차점-찾기&quot;&gt;5.1 교차점 찾기&lt;/h3&gt;

&lt;p&gt;고객 관점에서 장기적으로 중요한 고객과 비즈니스 관점에서 고객에게 바라는 행동 목표를 다시 정리해 보면 다음과 같습니다. 이를 조금 더 풀어서 고객이 원하는 것과 우리가 원하는 것의 맥락이 같은 지를 살펴보았습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/important-customer/finding-crossing-point.png&quot; alt=&quot;그림 20) 두 가지 관점이 왜 중요한지 복습&quot; /&gt;&lt;em&gt;그림 20) 두 가지 관점이 왜 중요한지 복습&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;장기적으로 중요한 고객을 찾아보는 단계에서 고객 관점에서 찾은 ‘뭘 망설일까’ 유형의 특성인 &lt;strong&gt;방문, 탐색/조회를 많이 하지만 예약 횟수가 적다&lt;/strong&gt;를 기반으로 세그먼트에 맞춘 니즈를 다시 고민하고 고객에게 원하는 행동 목표와 대조해 보며, “해당 세그먼트가 정말 장기적으로 중요하다고 볼 수 있을까?”에 대한 질문에 답을 내려볼 수 있었습니다.&lt;/p&gt;

&lt;p&gt;예컨대 비즈니스 관점에서는 ‘빠르게’, ‘원하는’에 방점을 찍어볼 수 있으며, 고객 관점에서도 해당 키워드와 맥락을 같이 하는 니즈가 있음을 확인할 수 있습니다. 비즈니스 관점에서 &lt;strong&gt;‘빠르게’&lt;/strong&gt;에 해당하는 고객 니즈는 &lt;strong&gt;“예약을 하기 위해 다시/여러 번 쏘카 존, 차량, 시간 등을 설정하는 일이 없었으면 좋겠다”, “예약을 위해 빠르게 조회하고 판단하여 선택하고 싶다.”&lt;/strong&gt; 가 있으며, &lt;strong&gt;‘원하는’&lt;/strong&gt;에 해당하는 고객 니즈는 &lt;strong&gt;“내가 원하는 차(신차, 특가 차량, 주유/충전 량이 보장된 또는 사고 이력이 많지 않은)를 빌리고 싶다”&lt;/strong&gt; 가 있습니다.&lt;/p&gt;

&lt;p&gt;따라서 &lt;strong&gt;뭘 망설일까 유형&lt;/strong&gt;이 장기적으로 가장 중요한 고객이라고 볼 수 있습니다.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;비즈니스 관점&lt;/th&gt;
      &lt;th&gt;고객 관점 = ‘뭘 망설일까’ 유형의 니즈&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;빠르게&lt;/td&gt;
      &lt;td&gt;- 다시/여러 번 ‘조건 설정’ 하는 일이 없었으면 좋겠다. &lt;br /&gt; - 예약을 위해 빠르게 조회/선택하고 싶다.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;원하는&lt;/td&gt;
      &lt;td&gt;- 내가 원하는 차량을 빌리고 싶다.  &lt;br /&gt; ㄴ 원하는 : 가격이 저렴한, 경험을 통해 지식이 있는 차량, 청결한, 주유/충전이 되어있는 등&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;em&gt;표 2) 비즈니스 관점 x 고객 관점 싱크 해보기&lt;/em&gt;&lt;/p&gt;

&lt;h3 id=&quot;52-실효성-있는-액션-플랜을-위한-방법-feat-코호트-분석&quot;&gt;5.2 실효성 있는 액션 플랜을 위한 방법 (feat. 코호트 분석)&lt;/h3&gt;

&lt;p&gt;이제 장기적으로 중요한 고객을 세분화하여 해당 고객 군이 정말로 세분화된 기준에 문제를 겪고 있는지 데이터로 살펴보는 과정이 남았습니다.&lt;/p&gt;

&lt;p&gt;이 과정에서 ‘코호트 분석’을 활용함으로써 뾰족한 액션 플랜과 당위성을 함께 얻을 수 있습니다. 코호트(동질 집단)이란 동일 기간 대 공통된 경험을 지닌 고객 집단을 말하며, 코호트 분석이란 이러한 코호트를 특정 주기(일/주/월별)가 경과함에 따라 어떻게 달라지는지 파악하는 것을 의미합니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/important-customer/cohort-graph.png&quot; alt=&quot;그림 21) 코호트 분석 예시 (예약 전환율)&quot; /&gt;&lt;em&gt;그림 21) 코호트 분석 예시 (예약 전환율)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;예를 들어 위의 예약 전환율 코호트 차트를 예시로 다음과 같이 코호트 분석을 진행해 볼 수 있습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;코호트 : 특정 월에 예약을 한 동질 집단&lt;/li&gt;
  &lt;li&gt;코호트 분석 기준 :  예약 전환율 (쏘카 앱 방문 대비 결제까지 완료한 비율)&lt;/li&gt;
  &lt;li&gt;분석을 통해 알 수 있는 것
    &lt;ul&gt;
      &lt;li&gt;A. 2022년 08월에 예약한 사용자들은 시간이 흐름에 따라 어떻게 변할까?
        &lt;ul&gt;
          &lt;li&gt;위 예시 표를 통해선 2022년 8월에 예약을 한 사용자들이 1개월이 경과될 때마다 더욱 많은 비율로 예약을 지속해 나가고 있음을 알 수 있습니다. (8.9% → 9.0% → 10.1%…)&lt;/li&gt;
          &lt;li&gt;하지만 예시표와 다르게 시간이 경과됨에 따라 분석 기준인 예약 전환율이 하락한다면 다른 월에 예약한 사용자들과 어떤 차이가 있었는지 살펴보며 대응할 수 있을 것입니다.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;B. 2022년 08월 및 이후 예약한 사용자들의 예약 전환율에는 어떤 차이가 있을까?
        &lt;ul&gt;
          &lt;li&gt;위 예시 표를 기준으로 본다면 시간이 흐름에 따라 예약하는 서로 다른 사용자들이 점점 증가하고 있음을 알 수 있습니다. (8월 : 8.9%, 9월 9.1%, 10월 : 9.9%…)&lt;/li&gt;
          &lt;li&gt;하지만 만일 예약을 한 사용자들이 점점 줄어들고 있는 경향을 파악한다면 우리가 행한 액션 플랜을 수정하는 등 의사결정을 할 수 있습니다.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;C. 기존 사용자(A)의 예약 전환율과 신규 사용자(C)의 예약 전환율에는 어떤 차이가 있을까?
        &lt;ul&gt;
          &lt;li&gt;위 예시 표에 의하면 2022년 8월, 9월, 10월 시간이 흐름에 따라 예약 전환율이 점차 증가하고 있음을 확인할 수 있습니다.&lt;/li&gt;
          &lt;li&gt;예를 들어 8월에 예약을 한 사용자들(8.9%)이 이용한 앱 버전은 14.0.0이라 가정했을 때 9월에 사용자들(9.4%)이 예약을 위해 이용한 앱 버전은 14.0.1일 경우, 우리가 수행한 액션 플랜이 예약 전환율에 약 0.5% p 정도 증분을 발생시켰다고 해석해 볼 수 있을 것입니다.&lt;/li&gt;
          &lt;li&gt;하지만 쏘카에선 앱 업데이트 외에도 대여 가격&amp;amp;주행요금 인하, 신차 도입, 프로모션, 시즈널리티(휴가철) 등 외부 변수가 예약 전환율에 영향을 미쳤을 수도 있기 때문에 이를 주도면밀히 살펴 해석의 비약을 방지해야 합니다.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;탐색/조회 단계에서 특정 기능에 대한 사용성을 측정할 수도 있음에도 코호트 분석을 선택한 이유는 다음과 같습니다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;장기적으로 중요한 고객인 ‘뭘 망설일까 유형’을 우리가 행하는 액션에 따른 다양한 코호트로 세분화할 수 있습니다.&lt;/li&gt;
  &lt;li&gt;경과에 따라 성과 지표로 설정했던 예약 전환율 현황을 살펴보며 코호트 별 차이를 파악하고 개선이 필요한 타이밍에 즉시 액션을 실행할 수 있습니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이에 다음과 같이 ‘뭘 망설일까 유형’ 세그먼트를 다양한 코호트로 나누고 특정 코호트의 예약 전환율이 하락한다면 적절한 타이밍에 A/B Test로 액션을 실행할 수 있으며 이후 선행/성과 지표를 통해 론칭 논의를 할 수 있습니다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;탐색/조회 퍼널 안에서 ’뭘 망설일까 유형’을 세분화 한 코호트 예시&lt;/strong&gt;&lt;/p&gt;

  &lt;ul&gt;
    &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;경과로 살펴볼 데이터&lt;/code&gt;  성과 지표 중 예약 전환율&lt;/li&gt;
    &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;코호트(예시)&lt;/code&gt;
      &lt;ol&gt;
        &lt;li&gt;Map에서 시간 설정을 가장 먼저 설정한 집단의 예약 전환율 경과&lt;/li&gt;
        &lt;li&gt;차종 필터를 설정한 집단의 예약 전환율 경과&lt;/li&gt;
        &lt;li&gt;쏘카 존 2개 이상을 클릭한 집단의 예약 전환율 경과&lt;/li&gt;
        &lt;li&gt;대여 이력이 있는 차종을 대여 정보 확인 페이지까지 유지한 집단의 예약 전환율 경과&lt;/li&gt;
      &lt;/ol&gt;
    &lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;p&gt;예를 들어 위 코호트 예시 중 &lt;strong&gt;1. Map에서 시간 설정을 가장 먼저 설정한 집단의 예약 전환율 경과&lt;/strong&gt;를 살펴봤을 때 각 월 별 코호트의 예약 전환율이 하락한다면 “시간 설정을 가장 먼저 설정하는 것”에 고객들이 문제를 겪거나 어려움이 있음을 추측해 볼 수 있습니다.&lt;/p&gt;

&lt;p&gt;현황 파악 뒤에는 시간 설정과 예약 전환율과의 상관관계에 대한 추가 분석을 데이터 분석팀에 요청하는 등 문제점을 뚜렷하게 확인한 뒤 디자인, 개발 동료와 논의하여 A/B Test로 개선 액션을 실행해 볼 수 있습니다. 
A/B Test를 통해선 개선 액션을 적용한 실험 군과 그렇지 않은 대조군의 예약 전환율 경향을 파악하여 액션의 영향도를 확인할 수 있습니다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;쏘카 프로덕트 본부는 이렇게 일해요 3 : 커뮤니케이션을 통해 협업합니다.&lt;/code&gt;&lt;/strong&gt; &lt;br /&gt; 
쏘카 프로덕트 본부에는 아이데이션, 논리 검증, 영향도 측정을 위한 데이터 분석 등 다양한 커뮤니케이션 채널과 인프라가 탄탄하게 마련되어 있어 다양한 팀의 동료분들과 목표 달성을 위한 과정을 함께 할 수 있습니다.
쏘카 PM의 실무에 대한 자세한 내용이 궁금하시다면 &lt;a href=&quot;https://tech.socarcorp.kr/product/2022/06/02/reservation-funnel-improvement-with-abtest.html&quot;&gt;[쏘카 PM의 차량 예약 퍼널 단계 개선기(feat. AB TEST]&lt;/a&gt; 글을 참고해 주세요!&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;6-느낀-점-&quot;&gt;6. 느낀 점 &lt;a name=&quot;wrap-up&quot;&gt;&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;과제를 통해 크게 고객 관점, 비즈니스 관점, 다양한 지표 등을 통해 ‘PM 적 사고’를 함양해 보는 과정을 가질 수 있었습니다. 서비스 기획자였던 제가 고민을 하는 과정에서 어려움도 존재했는데요. 어려움을 자유롭게 이야기하고 다양한 관점으로 ‘함께’ 자랄 수 있었던  1on1, 동료 리뷰, 스터디가 있어 과제를 완료하고 이 글을 공유할 수 있게 되어 감사한 마음입니다.&lt;/p&gt;

&lt;p&gt;이 과정을 통해 제가 가장 크게 얻게 된 역량은 제품을 기준으로 전사/프로젝트 목표 맥락 안에서 자유롭게 사고할 수 있는 PM 적 사고라고 스스로 회고하고 있습니다.  현재는 소중한 기회인 과제를 통해 함양하게 된 ‘PM 적 사고’로 아이템의 로드맵과 방향성 설정부터 다양한 동료들과의 적극적인 협업까지 할 수 있는 예약 전환율 프로젝트 팀에서 실무를 펼쳐나가고 있습니다.&lt;/p&gt;

&lt;p&gt;쏘카 PM으로 마주할 실무를 통해 더욱 무르익어 갈 앞날을 기대하며, 혼자가 아닌 함께 성장하고자 하는 예비 PM 동료분이 있다면 주저 말고 함께 할 날을 기대하겠습니다.&lt;/p&gt;</content><author><name>버키</name></author><category term="product" /><category term="product" /><category term="product manager" /><summary type="html">안녕하세요. 쏘카에서 고객용 제품을 담당하는 PM1 팀의 PM(Product Manager) 버키입니다. 저는 쏘카 입사 후 이제 막 수습 기간을 종료한 주니어 PM입니다. 이 글은 서비스 기획자였던 제가 쏘카의 PM으로서 실무에 투입하기 전 수습 과제를 진행하며 알게 된 방법론과 풀어내는 과정에서 배운 사고과정, 쏘카 프로덕트 본부는 어떻게 함께 자라는가?를 공유하기 위한 글입니다.</summary></entry><entry><title type="html">데이터에 신뢰성과 재사용성까지, Analytics Engineering with dbt</title><link href="https://tech.socarcorp.kr/data/2022/07/25/analytics-engineering-with-dbt.html" rel="alternate" type="text/html" title="데이터에 신뢰성과 재사용성까지, Analytics Engineering with dbt" /><published>2022-07-25T00:00:00+00:00</published><updated>2022-07-25T00:00:00+00:00</updated><id>https://tech.socarcorp.kr/data/2022/07/25/analytics-engineering-with-dbt</id><content type="html" xml:base="https://tech.socarcorp.kr/data/2022/07/25/analytics-engineering-with-dbt.html">&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;안녕하세요. 데이터 비즈니스 본부 - 데이터 엔지니어링 그룹의 험프리입니다.&lt;/p&gt;

&lt;p&gt;데이터 엔지니어링 그룹은 데이터 플랫폼 팀, 데이터 웨어하우스팀으로 나누어 쏘카의 구성원들 누구나 쏘카의 데이터를 쉽고 빠르게 조회할수록 최적의 방안을 마련하고 지원하는 일을 수행하고 있습니다. 그중 데이터 플랫폼 팀은 데이터 엔지니어링 그룹 내뿐만 아니라 데이터 비즈니스 본부 내의 엔지니어링 파트에서 서포트에서 필요한 인프라, 데이터 파이프라인 개발, 운영, 모니터링, 데이터 애플리케이션 개발, MLOps 등의 업무를 맡고 있습니다.&lt;/p&gt;

&lt;h2 id=&quot;1-들어가며&quot;&gt;1. 들어가며&lt;/h2&gt;

&lt;p&gt;쏘카에서는 데이터 분석가나 모델러, PM 등 여러 이해관계자가 데이터를 의사 결정에 활용하고 있습니다. 쏘카가 다루는 모빌리티 도메인의 데이터는 특히나 러닝 커브가 높습니다. 때문에 다양한 배경의 구성원들이 더 쉽게 쏘카의 데이터를 활용하기 위해 이미 오래전부터 데이터 마트를 운영하고 있습니다.&lt;/p&gt;

&lt;p&gt;하지만 여느 소프트웨어가 그렇듯 시간이 지남에 따라 비즈니스가 성장하고 새로운 사업들이 추가되면서, 그로부터 만들어지는 데이터를 반영하여 데이터 마트를 유지 보수하는 비용도 증가했습니다. 이미 복잡하게 얽혀있는 데이터에 새로운 데이터를 쌓아올려 비즈니스 이해관계자들이 쉽게 원하는 데이터를 조회할 수 있도록 유지하는 데는 많은 노력이 필요했습니다.&lt;/p&gt;

&lt;p&gt;이 글에서는 쏘카에서 복잡하게 얽혀있던 데이터 마트와 그를 지탱하는 데이터 파이프라인들을 견고하고 재사용 가능하게 만든 유즈케이스를 소개하고, 더 넓은 시각에서 규모를 키워가는 조직에서 데이터와 메타데이터를 관리하는 방법, 그리고 앞으로 나아가야 할 방향에 대해서 이야기하려고 합니다.&lt;/p&gt;

&lt;p&gt;예상 독자는 다음과 같습니다&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;모던 DW를 이용해 데이터를 제공하는 데이터 엔지니어&lt;/li&gt;
  &lt;li&gt;데이터 마트 구성과 모델링 등의 고민을 해본 적 있는 데이터 분석가&lt;/li&gt;
  &lt;li&gt;서비스 데이터를 효과적으로 분석하기 좋은 형태로 만드는 방법을 고민하는 백엔드 엔지니어&lt;/li&gt;
  &lt;li&gt;데이터를 이용해 업무를 하는 모든 직군&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;11-쏘카의-데이터-인프라&quot;&gt;1.1. 쏘카의 데이터 인프라&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/img/analytics-engineering-with-dbt/dbt1.png&quot; alt=&quot;socar data infra&quot; /&gt;&lt;/p&gt;

&lt;p&gt;다양한 원천(Raw) 데이터를 빅쿼리로 모으고, 빅쿼리 내의 SQL로 테이블을 생성하는 기능을 활용해 가공한 테이블들을 만들고, 가공한 데이터들을 모아 집계된 테이블들을 만들어 활용합니다.&lt;/p&gt;

&lt;h3 id=&quot;12-양-날의-검&quot;&gt;1.2. 양 날의 검&lt;/h3&gt;

&lt;p&gt;빅쿼리를 중심으로 만들어진 데이터 인프라 구조는 장단점이 명확했습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;장점
    &lt;ul&gt;
      &lt;li&gt;스토리지 비용이 비교적 저렴합니다.&lt;/li&gt;
      &lt;li&gt;SQL을 통해서 프로그래밍 지식이 없어도 쉽게 데이터를 조회하고, 변형할 수 있습니다.&lt;/li&gt;
      &lt;li&gt;다양한 소스의 데이터를 쉽게 저장하고, 조회할 수 있습니다.&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;초기 빅쿼리 중심으로 데이터 인프라를 만들면서 쏘카는 기존 시장에서 우위를 점하고 있던 Hadoop과 Spark 기반의 인프라에 비해 빠르게 발전할 수 있었습니다. 많은 선수 지식이 필요하고 데이터 조직을 중심으로 중앙 집중적으로 만들어지고 관리되는 기존 데이터 인프라와 달리, 빅쿼리를 중심으로 한 데이터 인프라는 민주적으로(!) 데이터를 만들어내고 관리할 수 있어 관련 지식이 없더라도 쉽게 데이터에 접근하고 활용할 수 있습니다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;단점
    &lt;ul&gt;
      &lt;li&gt;쉽게 넣을 수 있다 보니, 데이터 검증에 대한 고려를 하지 않는 경우가 많습니다.&lt;/li&gt;
      &lt;li&gt;데이터(데이터셋, 테이블) 히스토리와 오너쉽 등을 파악하기 어렵습니다.&lt;/li&gt;
      &lt;li&gt;데이터 간 의존성, 삭제 영향도 또한 파악하기 어렵습니다.&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;&lt;br /&gt;&lt;/p&gt;

    &lt;p&gt;사내 빅쿼리 사용 유저만 해도 전체 300여 명 중 100명이 훨씬 넘는 분들이 빅쿼리를 통해 쏘카의 데이터에 접근하게 되었습니다. 시간이 지나면서 정말 많은 데이터가 빅쿼리에 쌓이게 되었고, 이를 모두 제어하려 하는 일은 여러 조직의 속도를 늦추는 일이 될 수도 있었습니다.&lt;/p&gt;

    &lt;p&gt;같은 데이터를 다루는 테이블도 만드는 사람에 따라 로직이 다를 수 있고 그에 따라 데이터 사용자가 “알아서” 검증을 해야 했고, 이를 개선하기 위한 데이터 마트를 만드는 데이터 엔지니어가 그 검증에 대한 책임을 도맡아야 했습니다. 또한 해당 데이터에 대한 히스토리 파악은 기존 테이블 생성자로부터 직접 전달받거나, 테이블을 생성하는 수 백 줄의 쿼리나 파이썬 코드를 보면서 직접 파악을 해야 했습니다. 때문에 데이터 마트를 추가하는 작업의 난이도가 시간이 갈수록 높아져 갔습니다.&lt;/p&gt;

    &lt;p&gt;테이블을 지우는 일도 신경을 써야 했습니다. 지우려는 테이블이 어떤 곳에 얽혀있는 지도 모르는 채, 테이블을 삭제하면 어떤 사이드 이펙트를 불러올지 몰랐습니다. 혹여나 매우 중요한 데이터 마트 테이블에 엮여있는 테이블들을 삭제한다면, 매출과 같은 중요한 데이터에 이슈가 생길 수도 있습니다.&lt;/p&gt;

    &lt;p&gt;위와 같은 단점들은 시간이 지나면 지날수록 발목을 잡았고, 문제들을 해결하기 위한 비용도 급속도로 커져만 갔습니다. 마치 소프트웨어 엔지니어링에서 이야기하는 “&lt;strong&gt;A big ball of mud&lt;/strong&gt;”처럼요.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/img/analytics-engineering-with-dbt/dbt2.png&quot; alt=&quot;A big ball of mud in Data&quot; /&gt;&lt;em&gt;출처: &lt;a href=&quot;https://deviq.com/antipatterns/big-ball-of-mud/&quot;&gt;Big Ball of Mud - DevIQ&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;

&lt;h3 id=&quot;13-analytics-engineer의-등장&quot;&gt;1.3. Analytics Engineer의 등장&lt;/h3&gt;

&lt;p&gt;위와 같은 문제점들은 저희만 겪고 있는 문제는 아니었습니다.&lt;/p&gt;

&lt;p&gt;Snowflake, Delta Lake 등 최근 부상하고 있는 모던 데이터 웨어하우스를 운영하고 있는 팀들은 비슷한 문제들을 겪고 있었고 각자에 상황에 맞는 방법으로 해결하고 있습니다.&lt;/p&gt;

&lt;p&gt;그러는 와중 저희의 눈에 띈 하나의 큰 흐름은, 데이터를 사용해서 비즈니스적인 의사결정을 도와주는 데이터 분석가와 데이터 파이프라인들을 만드는 데이터 엔지니어 사이에 중간자 적인 역할을 해주는 Analytics Engineer라는 직군이 등장하게 된 것입니다.&lt;/p&gt;

&lt;p&gt;Analytics Engineer의 대표적인 role은 아래와 같습니다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Data Modeling: 데이터 모델링을 통해 유즈케이스에 맞게 데이터를 관리할 수 있도록 모델링 합니다.&lt;/li&gt;
  &lt;li&gt;Data Warehouse Management: 데이터 웨어하우스를 관리해서 사용자들이 쉽게 데이터를 조회하고 히스토리 등을 확인할 수 있게 합니다.&lt;/li&gt;
  &lt;li&gt;Data Orchestration: 스케줄링 도구 등을 사용해서 데이터가 정상적으로 업데이트 되도록 관리합니다.&lt;/li&gt;
  &lt;li&gt;Setting Best Practices: 모델링과 데이터를 관리하는 사내의 Best Practice를 정의하고 구현하도록 돕습니다.&lt;/li&gt;
  &lt;li&gt;Cross-collaboration: 분석가나 엔지니어와 소통하며 비즈니스 요구 사항을 수집하고, 성공적인 분석 결과를 만들어 내고, 모델링에 다른 조직의 요구 사항을 반영합니다. 또한 소프트웨어 엔지니어링의  실천 방법을 분석에서도 유용하게 사용할 수 있도록 돕습니다 (Version Control, Testing, … )&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;해외의 다양한 회사에서 Analytics Engineer를 채용하고 있습니다.&lt;/p&gt;

  &lt;p&gt;&lt;a href=&quot;https://about.gitlab.com/job-families/finance/analytics-engineer/&quot;&gt;https://about.gitlab.com/job-families/finance/analytics-engineer/&lt;/a&gt;
&lt;a href=&quot;https://www.glassdoor.com/Job/analytics-engineer-jobs-SRCH_KO0,18.htm&quot;&gt;https://www.glassdoor.com/Job/analytics-engineer-jobs-SRCH_KO0,18.htm&lt;/a&gt;
&lt;a href=&quot;https://www.glassdoor.com/Job/analytics-engineer-jobs-SRCH_KO0,18.htm&quot;&gt;https://www.glassdoor.com/Job/analytics-engineer-jobs-SRCH_KO0,18.htm&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Analytics Engineering의 등장에서 얻을 수 있는 교훈은 1) &lt;strong&gt;“중요한”&lt;/strong&gt; 데이터들을 오너십을 갖고 관리하고 발전시켜 나가는 시스템의 필요성, 2) 일반적인 조회뿐만 아니라 &lt;strong&gt;재사용&lt;/strong&gt; 가능하게 만드는 노력, 그리고 3) 데이터 간의 의존성 및 메타데이터 관리의 중요성이었습니다.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Data Engineer&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Analytics Engineer&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Data Analyst&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;커스텀 데이터 통합 기능을 만듭니다.&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;클린하고, 정제되고, 분석 가능한 데이터를 제공합니다.&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;데이터 인사이트 관련 (e.g., 왜 유저 이탈이 지난 달에 높았을까?)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;전반적인 파이프라인 오케스트레이션을 관리합니다.&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;소프트웨어 엔지니어링의 베스트 프랙티스를 분석 코드에 적용합니다. (e.g., version control, testing, CI 등)&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;비즈니스 이해 관계자와 협업하여 요구 사항을 파악합니다&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;데이터 플랫폼을 만들고 유지보수 합니다.&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;데이터 문서와 정의 등을 유지보수 합니다.&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;중요한 대시보드를 만들고 유지보수 합니다.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;데이터 웨어하우스의 성능 문제를 최적화합니다.&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;비즈니스 데이터 유저가 시각화 툴을 사용할 수 있도록 교육합니다.&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;데이터를 통해 예측 합니다.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;em&gt;&lt;strong&gt;직군별 비교 (Data Engineer vs Analytics Engineer vs Data Analyst)&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;하지만 어떤 기술이던 그러하듯, 다른 회사에서 작동했던 개념과 기술들이 우리 조직에서도 잘 도입되고 활용되려면 많은 노력과 고려가 필요하다고 생각했습니다. 큰 회사에서처럼 당장 Analytics Engineering만 담당하는 인원을 채용해서 발전시키는 게 현실적으로 어렵기도 하고, 또한 이러한 분야의 발전이 조직에서 필요하다는 컨센서스를 만드는 과정도 시간이 많이 들 수 있는 일이었습니다.&lt;/p&gt;

&lt;h2 id=&quot;2-data-build-tooldbt&quot;&gt;2. data build tool(dbt)&lt;/h2&gt;

&lt;p&gt;dbt는 데이터 엔지니어링의 큰 요소 중 하나인 ETL or ELT (Extract, Transform, Load) 중 &lt;strong&gt;변형(Transform)에 집중합니다&lt;/strong&gt;. 어디서 데이터를 추출해 내고 적재하는지에 대한 관심보다는 “어떻게” 존재하는 데이터를 변형해서, 재사용할지에 대해 고민합니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/analytics-engineering-with-dbt/dbt4.png&quot; alt=&quot;출처: [https://www.getdbt.com/](https://www.getdbt.com/)&quot; /&gt;&lt;/p&gt;

&lt;p&gt;출처: &lt;a href=&quot;https://www.getdbt.com/&quot;&gt;https://www.getdbt.com/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;dbt를 통해 데이터를 검증, 변형한 후 자동화된 문서와 데이터 리니지(계보)를 제공해서 데이터 사용자가 쉽게 원하는 데이터를 찾아서 쓸 수 있게 만들어 줍니다. 쏘카에서 사용하는 빅쿼리뿐만 아니라, Snowflake, Postgres, Redshift, Delta Lake와 같은 다른 데이터 웨어하우스 기술들과도 쉽게 연결해서 사용할 수 있는 integration을 제공합니다.&lt;/p&gt;

&lt;p&gt;가장 매력적인 부분은 대부분의 기능들을 SQL만 알아도 이용할 수 있고, Yaml만 조작해도 수백 GB의 큰 테이블에 대한 테스트, 문서 화 등의 일련의 작업들을 쉽게 할 수 있다는 점이었습니다. 쏘카는 위에서
언급한 것과 같이 조직 내 많은 인원들이 SQL을 사용하고 있어서 더욱 적합하다고 판단했습니다.&lt;/p&gt;

&lt;p&gt;또한 데이터 관련 작업들에서 부가적으로 얻을 수 있는 이점들이 꽤 있다고 생각했습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;쿼리의 버전 관리&lt;/strong&gt;: SQL을 사용하는 많은 분들이 별도의 버전 관리를 하지 않고 있습니다. dbt를 사용하면 SQL 기반 데이터 파이프라인의 배포를 Git의 라이프사이클 안에서 만들어나갈 수 있고, 쿼리에 대한 리뷰 그리고 나아가 데이터에 대한 정보가 흐를 수 있는 문화를 만들어 갈 수 있는 발판이라고 생각했습니다.&lt;/li&gt;
  &lt;li&gt;오너십: ‘주인 없는 데이터’는 분석을 하기에 생각보다 큰 허들입니다. 가져다가 사용하기도, 그렇다고 없애기도 애매하죠. 어떤 로직으로 동작하는지 확인을 하기 위해 SQL을 확인하는 것도 한계가 있을 수 있습니다. dbt를 사용하며 쿼리에 대한 문서화와 히스토리를 작성하는 문화를 만들어가면서 ‘SQL 드리븐 데이터’에서 좀 더 ‘사람 드리븐 데이터’로 옮겨갈 수 있을 거라고 생각했습니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;사실 dbt 말고도 비슷한 문제를 해결하는 기술들이 아시다시피 꽤 많습니다.&lt;/p&gt;

&lt;p&gt;dbt의 대안으로 생각되는 기술들로는 다음과 같은 기술들이 있습니다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;⚠️ 아래 다른 기술과의 비교는 지극히 개인적인 저의 판단입니다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;이름&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;장점&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;단점&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;비고&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;a href=&quot;https://github.com/dataform-co/dataform&quot;&gt;Dataform&lt;/a&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;BigQuery에 집중. &lt;br /&gt; SQL 기반. &lt;br /&gt; SaaS 기반 웹 IDE 무료 제공. &lt;br /&gt; Looker 연동&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Self Hosting 불가 (as opposed to dbt), &lt;br /&gt; 비싼 가격 (당시 월간 유저 당 $95), &lt;br /&gt; Typescript 기반&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;a href=&quot;https://github.com/sodadata/soda-sql&quot;&gt;Soda SQL&lt;/a&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;오픈 소스, &lt;br /&gt; 직관적인 Yaml 활용법 (Sql In Yaml), &lt;br /&gt; Python 기반&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;유저풀이 적음. &lt;br /&gt; Yaml 관련 오퍼레이션이 많아서 더 복잡함.&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;최근에는 Yaml + SQL 기반에서 자체적인 DSL(SodaCL)을 만들어 사용&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;a href=&quot;https://github.com/great-expectations/great_expectations&quot;&gt;Great Expectation&lt;/a&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;데이터 테스팅 및 분포 UI, 테스팅 Preset&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;무겁다. 어렵다.&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;img src=&quot;/img/analytics-engineering-with-dbt/dbt5.png&quot; alt=&quot;dbt-to-be&quot; /&gt;&lt;/p&gt;

&lt;p&gt;dbt는 다른 툴들이 각자 가지고 있는 장점들을 (그만큼 뾰족하지는 않더라도) 전반적으로 시도해 볼 수 있는 툴이고 Analytics Engineering을 빠르게 도입하고 구현하는 데 저희 조직에 가장 알맞은 툴이라고 생각했습니다.&lt;/p&gt;

&lt;p&gt;dbt는 두 가지 방법으로 서비스를 제공하고 있습니다. dbt Cloud와 dbt CLI입니다. 전자는 Team Plan 기준 월간 인당 50불(…)의 비용을 내면서 쓸 수 있고, Airflow와 같은 workflow와 Git Integration, Alerting 등의 다양한 기능들을 제공해 줍니다. 후자는 무료로 dbt의 많은 기능들을 전부 이용할 수 있었지만, 자유도가 높은 만큼 러닝 커브와 세팅을 위한 인프라 및 애플리케이션 배포 작업이 필요합니다.&lt;/p&gt;

&lt;p&gt;저희 조직은 분석가 대비 엔지니어가 꽤 많은 (당시 8명) 상황이었고, 세팅을 위한 역량도 충분히 갖춰져 있는 상황이었고 오히려 분석가들 및 SQL 사용자가 모두가 dbt Cloud를 사용한다면 지불해야 하는 Cost가 더 크다고 생각했습니다. 그래서 dbt CLI를 기반으로 여러 가지 시도를 해보기 시작했습니다.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;⚠️ dbt에 대한 기본적인 사용법은 이 글에서 다루지 않습니다.&lt;/p&gt;

  &lt;p&gt;더 자세한 dbt에 대한 정보는 dbt 공식 문서와 제 개인 블로그를 참고해 주세요.&lt;/p&gt;

  &lt;p&gt;&lt;a href=&quot;https://www.getdbt.com/&quot;&gt;dbt - Transform data in your warehouse&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://www.humphreyahn.dev/blog/efficient-elt-pipelines-with-dbt&quot;&gt;dbt로 ELT 파이프라인 효율적으로 관리하기&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;3-유즈-케이스---soda-store-v2&quot;&gt;3. 유즈 케이스 - SODA Store v2&lt;/h2&gt;

&lt;p&gt;SODA Store는 2020년 부터 유지되어왔던 쏘카의 비즈니스와 맞닿아 있는 지표들을 모아놓은 데이터셋을 부르는 별칭입니다. (SOCAR + Data Store = SODA)&lt;/p&gt;

&lt;p&gt;소다스토어에는 사고 집계 데이터, 예약 당시 차량 상태, 분석을 위한 일간 차량 데이터, 예약 누적 데이터 등 쏘카 내의 여러 개의 MSA에 걸쳐서 나눠져 있는 데이터를 집계해 관리하고 있습니다.&lt;/p&gt;

&lt;p&gt;이 파트에는 조금 더 저 수준에서 어떻게 프로젝트를 만들어 나갔고, 어떤 의사 결정과 문제를 해결했는지에 대해서 자세히 이야기해보려고 합니다.&lt;/p&gt;

&lt;h3 id=&quot;31-프로젝트-시작-전&quot;&gt;3.1. 프로젝트 시작 전&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;분석&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;기존 소다스토어는 에어플로우를 통해 빅쿼리로부터 오직 SQL만을 통해서 데이터 전처리를 진행하고, 전처리 및 변형 과정이 끝난 데이터를 모두 빅쿼리에 적재하는 방식으로 테이블을 적재했습니다.&lt;/p&gt;

&lt;p&gt;이 방법은 매우 편하고 관리 포인트도 적었지만 다음과 같은 한계점이 존재했습니다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;로직을 담은 SQL이 매우 비대했습니다. (≥ 500 Lines)&lt;/li&gt;
  &lt;li&gt;테스트의 부재 및 실패 시 이유를 찾기 어려움&lt;/li&gt;
  &lt;li&gt;흐르지 않는 도메인 지식 및 이슈 트래킹&lt;/li&gt;
  &lt;li&gt;위의 이유들 때문에 새로운 데이터를 추가하거나 기존 데이터 관련 이슈를 트러블 슈팅하기 어려움&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;위와 같은 한계점이 존재함에도 불구하고, 소다 스토어는 총 66만 회 이상의 쿼리에서 참조 되고, 데이터 관련 직군 외의 사업, 운영, 마케팅, 전략 등 다양한 부서에서 고르게 사용되며 비즈니스 의사 결정에 기여하고 있습니다.&lt;/p&gt;

&lt;p&gt;해당 이슈를 해결해야 빠르게 성장하는 쏘카의 비즈니스의 데이터와 관련한 의사 결정에 기여할 수 있도록 할 수 있다고 생각했습니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;목표 설정&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;위와 같은 문제를 해결하기 위해서 &lt;code class=&quot;highlighter-rouge&quot;&gt;Analytics Engineering&lt;/code&gt;이 필요하다는 생각을 하게 되었습니다.&lt;/p&gt;

&lt;p&gt;SODA Store에 &lt;code class=&quot;highlighter-rouge&quot;&gt;Analytics Engineering&lt;/code&gt;을 적용하며 가진 목표는 다음과 같았습니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;SODA Store v2 주요 목표&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;기존 테이블의 사용성 검토 및 정비&lt;/li&gt;
  &lt;li&gt;신규 서비스 및 요구사항에 따른 마트 테이블 추가 작성&lt;/li&gt;
  &lt;li&gt;외부에 분산된 마트 테이블들의 통합 검토&lt;/li&gt;
  &lt;li&gt;지표 데이터 정리&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Analytics Engineering 주요 목표&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;테이블 테스트 추가 및 정합성 검증&lt;/li&gt;
  &lt;li&gt;테이블 모델링 (정규화, 컬럼 필터링 등)&lt;/li&gt;
  &lt;li&gt;데이터 의존 관계 시각화 (데이터 리니지)&lt;/li&gt;
  &lt;li&gt;데이터 문서화&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;계획&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;위 목표를 달성하기 위해 넘어야 했던 가장 큰 허들은 1) dbt라는 툴에 대한 이해, 2) 복잡한 도메인 지식에 대한 심리적 안정감 높이기였습니다.&lt;/p&gt;

&lt;p&gt;때문에 다음과 같이 단계를 나누어서 진행을 하도록 계획했습니다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;프로젝트 구성&lt;/li&gt;
  &lt;li&gt;테이블 모델링 &amp;amp; 테이블 테스트 추가&lt;/li&gt;
  &lt;li&gt;검증&lt;/li&gt;
  &lt;li&gt;배포&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;32-프로젝트-구성&quot;&gt;3.2. 프로젝트 구성&lt;/h3&gt;

&lt;p&gt;소다 스토어의 쿼리는 이미 Airflow를 통해 적재 중인 DAG에 정의가 되어 있습니다.&lt;/p&gt;

&lt;p&gt;프로젝트를 구성할 때는 해당 SQL 파일을 그대로 옮겨와 빠르게 작업을 할 수 있습니다.&lt;/p&gt;

&lt;h4 id=&quot;dbt-레포-셋업&quot;&gt;dbt 레포 셋업&lt;/h4&gt;

&lt;p&gt;소다 스토어 v2를 위한 레포 구성은 일반적인 &lt;code class=&quot;highlighter-rouge&quot;&gt;dbt init&lt;/code&gt; 을 통한 구조와는 살짝 달랐습니다.&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;.../socar-data-soda-store
├── .github &lt;span class=&quot;c&quot;&gt;# Github action 관련 &lt;/span&gt;
├── cli &lt;span class=&quot;c&quot;&gt;# 커스텀 CLI 툴&lt;/span&gt;
├── scripts &lt;span class=&quot;c&quot;&gt;# 배포를 위한 스크립트&lt;/span&gt;
└── soda_store &lt;span class=&quot;c&quot;&gt;# dbt 프로젝트 구성에 필요한 모듈&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;이렇게 커스터마이징을 했던 이유는 소다 스토어의 특성이 있습니다.&lt;/p&gt;

&lt;p&gt;소다 스토어는 데이터 마트로서의 역할도 하지만, SQL 및 로직 자체가 다른 쿼리 사용자가 참고를 많이 하고 있습니다.&lt;/p&gt;

&lt;p&gt;때문에 SQL 문 자체를 다양한 환경에서 사용할 가능성이 있습니다. 예를 들어 BigQuery에서 직접 해당 SQL을 사용하는 것도, 또는 애플리케이션 또는 Airflow 등의 전반적인 Python 환경에서
SQL 문을 import 해서 사용하거나, 아니면 CLI로 사용하는 경우도 생길 수 있을 거라고 생각했습니다.&lt;/p&gt;

&lt;p&gt;때문에 dbt 파일 구조를 공식 문서에서 가이드 하는 대로 하지 않고 일반적인 Python 라이브러리 구조와 같이 가져간다면 패키징과 빌드에 적합한 형태로 만들어갈 수 있고, 쏘카 사내 Pypi 레포 등을 통해서
소다 스토어에서 빅쿼리에 있는 데이터와 로직을 그대로 사용해서 데이터를 추가적으로 정제할 필요 없이 그대로 사용할 수 있다는 이점이 있습니다.&lt;/p&gt;

&lt;p&gt;또한 Profile에 대한 설정(&lt;code class=&quot;highlighter-rouge&quot;&gt;profiles.yml&lt;/code&gt;)을 변경했습니다. dbt에서 profile은 데이터웨어하우스 (e.g., BigQuery, Snowflake, Delta Lake 등)에 대한 설정부터,
개발 및 운영 환경에 대한 정보를 다루는 가장 중요한 설정에 대한 정보가 담겨있는 파일이라고 할 수 있습니다. 때문에 dbt init을 통해 프로젝트를 생성하면 기본적으로 유저의 &lt;code class=&quot;highlighter-rouge&quot;&gt;~/.dbt&lt;/code&gt; 디렉토리에
profiles를 생성하고 dbt CLI가 해당 디렉터리를 바라보도록 설정이 되어있습니다.&lt;/p&gt;

&lt;p&gt;소다 스토어를 구성하면서는 &lt;code class=&quot;highlighter-rouge&quot;&gt;profiles.yml&lt;/code&gt; 을 &lt;code class=&quot;highlighter-rouge&quot;&gt;soda_store&lt;/code&gt; 즉, dbt 디렉토리 안으로 가져왔습니다. 그 이유는 재사용성을 위함이었습니다.&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;jaffle_shop:
  target: dev
  outputs:
    dev:
      &lt;span class=&quot;nb&quot;&gt;type&lt;/span&gt;: postgres
      host: localhost
      user: alice
      password: &amp;lt;password&amp;gt;
      port: 5432
      dbname: jaffle_shop
      schema: dbt_alice
      threads: 4
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;위는 profiles.yml 파일의 예제입니다. 파일을 보시면 직접 host, user, pw 등 데이터웨어하우스에 대한 credential 정보를 직접 입력할 수 있게 됩니다. 작업자가 혼자라면, 위와 같이 관리해도 되지만 공동으로 작업을 하고 빠르게 CI/CD 파이프라인을 통해서 배포하게 되려면 인프라 레벨에서 환경 변수를 통해서 오버라이딩하기 쉽게 만들어주는 과정이 필요하다고 생각했습니다.&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
soda_store:
  target: dev
  outputs:
    dev:
      &lt;span class=&quot;nb&quot;&gt;type&lt;/span&gt;: bigquery
      method: service-account
      project: ...
      dataset: ...
      threads: 1
      timeout_seconds: 300
      priority: interactive
      maximum_bytes_billed: 1000000000000 &lt;span class=&quot;c&quot;&gt;# 1TB&lt;/span&gt;
      keyfile: &lt;span class=&quot;s2&quot;&gt;&quot;{{ env_var('GOOGLE_APPLICATION_CREDENTIALS', '') }}&quot;&lt;/span&gt;
    ci:
      &lt;span class=&quot;nb&quot;&gt;type&lt;/span&gt;: bigquery
      method: service-account
      project: ...
      dataset: ...
      threads: 10
      timeout_seconds: 3000
      priority: interactive
      maximum_bytes_billed: 1000000000000 &lt;span class=&quot;c&quot;&gt;# 1TB&lt;/span&gt;
      keyfile: &lt;span class=&quot;s2&quot;&gt;&quot;{{ env_var('GOOGLE_APPLICATION_CREDENTIALS', '') }}&quot;&lt;/span&gt;
    live:
      &lt;span class=&quot;nb&quot;&gt;type&lt;/span&gt;: bigquery
      method: service-account
      project: ...
      dataset: ...
      threads: 5
      timeout_seconds: 300
      priority: interactive
      keyfile: &lt;span class=&quot;s2&quot;&gt;&quot;{{ env_var('GOOGLE_APPLICATION_CREDENTIALS', '') }}&quot;&lt;/span&gt;   

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;dbt에서는  &lt;code class=&quot;highlighter-rouge&quot;&gt;{{ env_var('ENV_VAR', 'default') }}&lt;/code&gt; 와 같이 Yaml 상에 환경 변수를 런타임에서 치환할 수 있게 하는 편의 기능을 제공할 수 있어, 쿠버네티스 환경에서 Configmap과 Secret을 활용해서 Volume Mount 및 Env를 애플리케이션에 적용해 각기 다른 환경에도 쉽게 배포를 할 수 있도록 만들 수 있습니다.&lt;/p&gt;

&lt;h4 id=&quot;환경별-셋업-dbt-profile--infra&quot;&gt;환경별 셋업 (dbt Profile + Infra)&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;CI(PR Check)&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;CI 환경에서는 PR 단계에서 만든 유저의 변경 사항들을 적용해서 dbt test 및 run 커맨드를 실행합니다. 해당 변경 사항이 기존의 데이터 validation 테스트를 깨뜨리지는 않는지 확인하고, 테스트가 통과하면 머지 할 수 있도록 Branch Protection Rule을 적용했습니다.&lt;/p&gt;

&lt;p&gt;이 부분에서 사실 퍼포먼스를 극적으로 올려줄 수 있는 부분이 있는데 이는 뒷부분 배포에서 다루겠습니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;개발 환경 (dev)&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;개발 환경은 개발 데이터 웨어하우스에 연결해서 운영에 적용하기 전 전체 테이블들을 테스트하고 재구성 해보기 위해 만들었습니다.&lt;/p&gt;

&lt;p&gt;작업 코드 베이스에서 main에 머지 되면 CI/CD (Github Action) 파이프라인을 통해서 자동 실행되고, 실패 시 운영 배포를 할 수 없습니다.&lt;/p&gt;

&lt;p&gt;모든 과정이 에러 없이 통과된다면, 개발 Docker Image를 도커 레지스트리에 푸쉬합니다. 해당 이미지는 Airflow 등의 환경에서 테스트를 하기 위해 사용됩니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;운영 환경 (live)&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;운영 환경에서는 여러 가지 시행착오가 있었습니다. 운영을 위한 dbt 이미지를 만드는 과정은 개발 환경과 다르지 않지만, 해당 이미지를 사용하기 위한 런타임 환경을 만드는 과정이 다양했습니다.&lt;/p&gt;

&lt;p&gt;고려 및 테스트했던 환경은 1) 일반 도커 이미지 실행 2) dbt RPC, 3) Python 웹서버 4) 도커 이미지 실행 + Object Storage 등이 있습니다. 이에 대한 시행착오와 문제 상황은 아래 &lt;strong&gt;3.4 검증&lt;/strong&gt;을 참고 부탁드립니다.&lt;/p&gt;

&lt;p&gt;다음은 기존의 쿼리를 재사용하기 좋은 방법으로 모델링하고, 테스트 가능하게 만드는 과정이 필요했습니다. 기존의 쿼리가 100개 이상의 테이블들을 조인해서 데이터 마트를 만들어내야 했기에 “적절하게” 쿼리를 리팩토링하고 나누는 과정은 매우 어려웠는데요.&lt;/p&gt;

&lt;p&gt;dbt 공식 문서에서는 이 문제를 해결하기 위해 fishtown analytics(dbt labs의 전신)의 모델링 패턴을 소개합니다. (최근엔 공식 문서로 들어갔으며, 다음 링크에서 확인할 수 있습니다)&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://discourse.getdbt.com/t/how-we-structure-our-dbt-projects/355&quot;&gt;How we structure our dbt projects&lt;/a&gt; &lt;br /&gt;
&lt;a href=&quot;https://docs.getdbt.com/guides/best-practices/how-we-structure/1-guide-overview&quot;&gt;How we structure our dbt projects - dbt Docs&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Source&lt;/strong&gt;: 원천 테이블 또는 서드파티 데이터. 소스 테이블 스키마를 따릅니다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Staging Models&lt;/strong&gt;: 데이터 모델링의 가장 작은 단위. 각 모델은 소스 테이블과 1:1 관계를 갖습니다.
    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;Staging Model 규칙&lt;/p&gt;

        &lt;p&gt;Staging Models는 아래와 같은 규칙을 가집니다.&lt;/p&gt;

        &lt;ul&gt;
          &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;stg_&lt;/code&gt; 접두사로 구분한다. (e.g., stg_member__chat)&lt;/li&gt;
          &lt;li&gt;컬럼 네이밍, 타입을 일관적인 방법으로 정리되어 있어야 한다.&lt;/li&gt;
          &lt;li&gt;데이터 클렌징이 완료되어 있어야 한다.&lt;/li&gt;
          &lt;li&gt;PK가 유니크하고 Non-null 이어야 한다.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Staging Model 예제&lt;/p&gt;

        &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  ├── dbt_project.yml
  └── models
      ├── marts
      └── staging
          ├── braintree
          └── stripe
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;

        &lt;ul&gt;
          &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;stg_&amp;lt;source&amp;gt;__&amp;lt;object&amp;gt;&lt;/code&gt;&lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;보통 View로 Materialize 된다 (↔ Table)&lt;/p&gt;

            &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  ├── dbt_project.yml
  └── models
      ├── marts
      └── staging
          └── braintree
              ├── src_braintree.yml
              ├── stg_braintree.yml
              ├── stg_braintree__customers.sql
              └── stg_braintree__payments.sql
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;            &lt;/div&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;1 Staging Model, 1 Source Definition&lt;/p&gt;

            &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  ├── dbt_project.yml
  └── models
      ├── marts
      └── staging
          └── braintree
              ├── base
              |   ├── base.yml
              |   ├── base_braintree__failed_payments.sql
              |   └── base_braintree__successful_payments.sql
              ├── src_braintree.yml
              ├── stg_braintree.yml
              ├── stg_braintree__customers.sql
              └── stg_braintree__payments.sql
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;            &lt;/div&gt;
          &lt;/li&gt;
          &lt;li&gt;Staging Base 모델로 공통 로직 모듈화 시키기도 합니다.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Mart Models&lt;/strong&gt;: 비즈니스와 맞닿아 있는 데이터들을 다루는 모델
    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;Mart Model 예제&lt;/p&gt;

        &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  ├── dbt_project.yml
  └── models
      ├── marts
      |   ├── core
      |   ├── finance
      |   ├── marketing
      |   └── product
      └── staging
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;

        &lt;p&gt;기본적인 Mart 모델은 위와 같이 비즈니스 또는 조직의 구조와 닮아있습니다.&lt;/p&gt;

        &lt;p&gt;Mart 모델은 Fact와 Dimension 모델로 구성됩니다.&lt;/p&gt;

        &lt;ul&gt;
          &lt;li&gt;fct_&amp;lt;verb&amp;gt;: 길고 좁은 테이블 (컬럼이 적고, 로우가 많은), 현실의 프로세스들을 나타내 줘야함. e.g., Sessions, Transactions, Orders, Stories,
votes&lt;/li&gt;
          &lt;li&gt;dim_&amp;lt;noun&amp;gt;: 짧고 넓은 테이블 (컬럼이 많고, 로우가 적은), 각 Row가 사람, 장소, 사물 등. 변경가능하지만 변경 주기가 긴 것들이 온다. e.g., 고객, 상품, 빌딩, 직원 등&lt;/li&gt;
        &lt;/ul&gt;

        &lt;p&gt;Mart 모델에서 유용한 패턴&lt;/p&gt;

        &lt;ul&gt;
          &lt;li&gt;쿼리 퍼포먼스를 위해 Fact와 Dimension 테이블들은 Table로 Materialize 합니다.&lt;/li&gt;
          &lt;li&gt;중간 변환 과정의 테이블들을 Mart 모델 안에서 남겨둡니다.&lt;/li&gt;
          &lt;li&gt;각 모델의 테스트 Yaml을 추가합니다.&lt;/li&gt;
          &lt;li&gt;MD(Markdown) 파일로 문서화합니다.&lt;/li&gt;
        &lt;/ul&gt;

        &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  ├── dbt_project.yml
  └── models
      ├── marts
      │   ├── core
      │   │   ├── core.md
      │   │   ├── core.yml
      │   │   ├── dim_customers.sql
      │   │   ├── fct_orders.sql
      │   │   └── intermediate
      │   │       ├── customer_orders__grouped.sql
      │   │       ├── customer_payments__grouped.sql
      │   │       ├── intermediate.yml
      │   │       └── order_payments__joined.sql
      │   ├── finance
      │   ├── marketing
      │   └── product
      └── staging
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;

        &lt;p&gt;&lt;img src=&quot;/img/analytics-engineering-with-dbt/dbt7.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Gitlab에서는 위와 같은 Fishtown Analytics의 모델링 패턴을 참고해서 팀 고유의 모델링 패턴들을 만들어 나가고 있습니다. (참고 링크 :  &lt;a href=&quot;https://about.gitlab.com/handbook/business-technology/data-team/platform/dbt-guide/#model-structure&quot;&gt;dbt Guide&lt;/a&gt;, 놀랍게도 SQL을 포함한 모든 소스 코드가 Public입니다)&lt;/p&gt;

&lt;p&gt;쏘카에서도 위 패턴을 좀 더 활용해 독자적인 모델링 패턴을 사용했습니다.&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;models/
	|- mart
	|- ods &lt;span class=&quot;c&quot;&gt;# NEW!&lt;/span&gt;
	|- staging
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;ODS는 엔터프라이즈 데이터웨어하우스(EDW)에서 사용되는 개념으로, 임시로 운영계 데이터를 보관하는 장소입니다. Mart에 레이어에 본격적으로 마트 테이블들을 생성하기 전에, ODS에 메인 로직들을 저장해 두고 Mart에서는 해당 ODS 레이어의 모델을 레퍼런스 해서 사용합니다.&lt;/p&gt;

&lt;p&gt;ODS 레이어를 추가하게 된 가장 큰 이유 중 하나는, 소다 스토어의 경우에는 기존에 존재하는 데이터(v1)와 값을 비교를 하기 위해서입니다. ODS에서는 메인 로직들을 담아두고, (대부분의 케이스에서) View로 모델을 생성합니다. 그 덕분에 Mart에서는 ODS 모델을 레퍼런스 해서 Table로 Materialize를 시키면, 해당 작업이 시작한 시점 기준으로 테이블들을 만들 수 있어 기존에 존재하는 v1 데이터와 적재
시점을 동일하게 만들어 데이터를 비교할 수 있습니다.&lt;/p&gt;

&lt;p&gt;또한 가독성을 위해서도 필요했습니다. Staging에서는 원천 테이블에 대한 가공, Mart에서는 Staging에 있는 모델들을 조합해서 비즈니스 지표에 가까운 테이블을 만들어 낸다면, Mart에 로직이 대부분 집약되어서 부수 테이블이 많이 만들어져서 결국 Mart 테이블들의 데이터들을 이해하기 어려워졌습니다. ODS에 메인 로직들을 분산해서 저장해 두고, Mart는 최대한 &lt;code class=&quot;highlighter-rouge&quot;&gt;SELECT ... FROM ... WHERE&lt;/code&gt;
로 표현해서 비즈니스 지표들을 찍어낼 수 있다고 판단했습니다.&lt;/p&gt;

&lt;p&gt;해당 부분은 모든 dbt 프로젝트에 적용하기보다는 기존 쿼리 및 데이터 비교를 위한 작업이라면 참고해 볼 수 있을 패턴이라고 생각합니다.&lt;/p&gt;

&lt;h3 id=&quot;33-검증&quot;&gt;3.3. 검증&lt;/h3&gt;

&lt;p&gt;소다 스토어에서 검증해야 하는 것은 명확했습니다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;기존 데이터와 “정확히” 일치해야 한다.&lt;/li&gt;
  &lt;li&gt;기존 데이터에서 논리적 및 통계적인 오류가 없어야 한다.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;위 요구 사항은 모두 dbt의 테스트 기능을 활용해서 해결했습니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;기존 데이터와 “정확히” 일치해야 한다.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;기존 데이터를 dbt 코드 베이스에 Source 테이블로 만들어서 검증하는 방법도 있었지만, 매번 기존 테이블을 가져와서 새로운 테이블로 만드는 건 비효율적이라고 생각했습니다. 때문에 dbt 코드에 포함하지 않고 Macro를 통해서 쿼리를 이용해서 아래와 같이 검증하도록 만들었습니다.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;

&lt;span class=&quot;err&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;compare_v1_and_v2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;set&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v1_soda_store_dataset_ref&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'v1_table'&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;{{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v1_soda_store_dataset_ref&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;}}&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;{{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model_name&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;}}&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;except&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;distinct&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;{{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;target&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;project&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;}}&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;{{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;target&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;}}&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_ods&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ods_&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;{{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model_name&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;}}&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;union&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;all&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;{{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;target&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;project&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;}}&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;{{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;target&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;}}&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_ods&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ods_&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;{{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model_name&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;}}&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;except&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;distinct&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;{{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v1_soda_store_dataset_ref&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;}}&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;{{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model_name&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;}}&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;err&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;endtest&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;}&lt;/span&gt;


&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;na&quot;&gt;version&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;models&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;mart_model&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;tests&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;compare_v1_and_v2&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;model_name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;table_from_v1&quot;&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;columns&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;column1&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;description&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;컬럼1&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;기존 데이터에서 논리적 및 통계적인 오류가 없어야 한다&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;이 부분은 dbt에서 기본으로 제공하는 Generic Tests (unique, not_null, accepted_values, relationships) 뿐만 아니라 여러 dbt 패키지들을 사용했습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/dbt-labs/dbt-utils&quot;&gt;dbt-labs/dbt-utils&lt;/a&gt;: dbt 공식으로 제공하는 여러 가지 매크로들이 내장되어 있습니다. 매크로를 위한 쿼리를 추가적으로 작성할 필요 없이 테이블에 대한 검증 (e.g., &lt;code class=&quot;highlighter-rouge&quot;&gt;unique_combination_of_columns&lt;/code&gt;)과 select 문에서 사용할 Column Renaming 매크로 또한 제공합니다.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/calogica/dbt-expectations&quot;&gt;calogica/dbt_expectations&lt;/a&gt;: 위에서 언급했던 Great Expectation에서 제공하는 다양한 검증 preset들을 매크로로 구현해둔 패키지입니다. 테이블 row 또는 column 별 통계 값에 대한 검증이나 String Matching, Distribution Function 등 GE 대비 dbt의 단점들을 보완해 줄 수 있을 만큼 많은 매크로들이 존재합니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;예를 들어 다음과 같은 테스트를 추가해 보겠습니다.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;version&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sources&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;your&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;database&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;database&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;your&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;schema&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;tables&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;your&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;table&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;description&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'your table'&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;tests&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dbt_expectations&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;expect_compound_columns_to_be_unique&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;n&quot;&gt;column_list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;&quot;col1&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;&quot;col2&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;&quot;col3&quot;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;dbt run을 통해서 아래와 같은 SQL로 변환됩니다.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;validation_errors&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;col1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
           &lt;span class=&quot;n&quot;&gt;col2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
           &lt;span class=&quot;n&quot;&gt;col3&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;`your-database`&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;`your-schema`&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;`your-table`&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;where&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;group&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;col1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;col2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;col3&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;having&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;validation_errors&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;#&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;HERE&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;dbt로 만들어진 테스트들은 마지막 SELECT 문에서 0개 이상의 로우가 리턴되면 Fail, 아닌 경우에는 Pass 하도록 기본 설정되어 있습니다. 자세한 설명은 dbt test 공식 문서를 참고해 주세요.&lt;/p&gt;

&lt;p&gt;위와 같은 패키지를 통해 쉽게 테스트를 Yaml만 수정해서 추가할 수 있었고, 덕분에 기존 파이프라인에 안정성을 더할 수 있습니다.&lt;/p&gt;

&lt;h3 id=&quot;34-배포&quot;&gt;3.4. 배포&lt;/h3&gt;

&lt;p&gt;데이터 엔지니어링 그룹의 대부분의 애플리케이션들을 GitOps Principle에 따라서 배포가 됩니다. 따라서 dbt 기반 레포도 마찬가지의 절차를 따라서 구성했습니다. 다만 일반 파이썬 애플리케이션과 달리 배포 전 고려해야 하는 사항들이 꽤 존재합니다.&lt;/p&gt;

&lt;p&gt;배포는 다음과 같은 절차로 이루어집니다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;PR 생성&lt;/li&gt;
  &lt;li&gt;CI Test&lt;/li&gt;
  &lt;li&gt;메인 브랜치 머지&lt;/li&gt;
  &lt;li&gt;dev 환경 Update&lt;/li&gt;
  &lt;li&gt;Release / 운영(live) 환경 Update&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;소다 스토어 dbt 레포에 테이블을 추가하기 위해 PR을 생성하면 Github Action을 통해 PR의 변경 사항을 감지하고, 정상적으로 SQL 파싱 되고 테스트를 통과하는지 테스트합니다. 아래와 같은 Github Action Workflow를 구성했습니다.&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;Check PR&lt;/span&gt;

&lt;span class=&quot;na&quot;&gt;on&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;pull_request&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;branches&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pi&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;main&lt;/span&gt; &lt;span class=&quot;pi&quot;&gt;]&lt;/span&gt;

&lt;span class=&quot;na&quot;&gt;jobs&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;check_pr&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;runs-on&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;ubuntu-latest&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;steps&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;uses&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;actions/checkout@v2&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;...&lt;/span&gt;
    &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;Incremental CI&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pi&quot;&gt;|&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;bash scripts/ci.sh incremental&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;env&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;GCLOUD_SERVICE_KEY&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;lt;SERVICE_ACCOUNT_JSON_PATH&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;특별한 부분은 없고, Incremental CI라는 파트가 궁금하실 텐데요. 이 부분은 Slim CI를 다루는 아래 파트에서 이야기하겠습니다. Incremental CI를 통해서 변경이 된 부분만 감지해서, 필요한 부분만 생성할 수 있습니다.&lt;/p&gt;

&lt;p&gt;CI 테스트가 통과된 PR만 main 브랜치로 머지 할 수 있도록 Branch Brotection Rule을 설정해서 main을 언제나 배포가 가능한 형태로 유지하고 있습니다.&lt;/p&gt;

&lt;p&gt;이렇게 PR 테스트를 하고 main 브랜치로 머지되고 나면, 개발 환경에 배포를 하기 위해 dbt의 개발 Target에 모든 파이프라인을 run 합니다. (Full CI)&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
&lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;Dev Publish&lt;/span&gt;

&lt;span class=&quot;na&quot;&gt;on&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;push&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;branches&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pi&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;main&lt;/span&gt; &lt;span class=&quot;pi&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;jobs&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;dev_publish&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;runs-on&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;ubuntu-latest&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;if&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;!startsWith(github.ref,&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'refs/tags/v')&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;!startsWith(github.event.head_commit.message,&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'bump:')&quot;&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;steps&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;uses&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;actions/checkout@v2&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;...&lt;/span&gt;
    &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;Full CI&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pi&quot;&gt;|&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;bash scripts/ci.sh full&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;...&lt;/span&gt;
  &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;GitOps Update Dev&lt;/span&gt;
      &lt;span class=&quot;s&quot;&gt;id&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;gitops-update-dev&lt;/span&gt;
      &lt;span class=&quot;s&quot;&gt;continue-on-error&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;true&lt;/span&gt;
      &lt;span class=&quot;s&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pi&quot;&gt;|&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;git clone https://github.com/baloise/gitopscli.git&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;pip3 install gitopscli/&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;gitopscli deploy --git-provider-url &quot;https://github.com&quot; \&lt;/span&gt;
                         &lt;span class=&quot;s&quot;&gt;--username $GITHUB_USERNAME \&lt;/span&gt;
                         &lt;span class=&quot;s&quot;&gt;--password $GITHUB_PASSWORD \&lt;/span&gt;
                         &lt;span class=&quot;s&quot;&gt;--organisation $GITHUB_ORGANIZATION \&lt;/span&gt;
                         &lt;span class=&quot;s&quot;&gt;--repository-name $GITHUB_REPOSITORY_NAME \&lt;/span&gt;
                         &lt;span class=&quot;s&quot;&gt;--file $VALUES_FILE \&lt;/span&gt;
                         &lt;span class=&quot;s&quot;&gt;--values &quot;{app.container.image.tag: v${GITHUB_SHA::7}&quot; \&lt;/span&gt;
                         &lt;span class=&quot;s&quot;&gt;--git-user &quot;&amp;lt;your-git-user&amp;gt;&quot; \&lt;/span&gt;
                         &lt;span class=&quot;s&quot;&gt;--git-email &quot;&amp;lt;your-git-user-email&amp;gt;&quot; \&lt;/span&gt;
                         &lt;span class=&quot;s&quot;&gt;--commit-message &quot;&amp;lt;your-commit-message&amp;gt;&quot; \&lt;/span&gt;
                         &lt;span class=&quot;s&quot;&gt;--create-pr \&lt;/span&gt;
                         &lt;span class=&quot;s&quot;&gt;--auto-merge \&lt;/span&gt;
                         &lt;span class=&quot;s&quot;&gt;--merge-method=&quot;squash&quot;&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;env&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;GITHUB_USERNAME&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;${{ secrets.GH_USERNAME }}&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;GITHUB_PASSWORD&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;${{ secrets.GH_PASSWORD }}&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;GITHUB_ORGANIZATION&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;${{ secrets.GH_ORGANIZATION }}&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;GITHUB_REPOSITORY_NAME&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;${{ secrets.GH_REPOSITORY_NAME }}&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;VALUES_FILE&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;lt;your-values.yaml&amp;gt;&quot;&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;이 단계가 통과되면, 개발 환경 데이터웨어하우스에 dbt로 메인 로직을 전부 테스트한 상황이 되고, 운영 배포로 Airflow를 통해서 주기적으로 배포할 수 있는 환경이 됩니다.&lt;/p&gt;

&lt;p&gt;또한, dbt에서 제공하는 Lineage 웹페이지를 Helm Chart로 구성해 운영하고 있기 때문에 변경 사항을 helm chart 레포에도 전달해 줘야 합니다. 때문에 GitOps CLI라는 라이브러리를 사용해서 해당 레포에 &lt;code class=&quot;highlighter-rouge&quot;&gt;values.yaml&lt;/code&gt;에 정의되어 있는 개발 Container Image Tag를 변경해 줍니다.&lt;/p&gt;

&lt;p&gt;마지막으로 운영 환경을 위해 Release를 하는 단계만 남았습니다. 운영은 개발 환경 업데이트 보다 쉽습니다. Full CI를 통해서 전체 파이프라인을 재실행할 필요가 없기 때문입니다. 운영에서는 전체 재실행을 하지 않는 이유는 Airflow를 통해서 실행되는 운영 dbt 도커 이미지의 결과와 충돌할 수 있기 때문입니다. 같은 로직을 개발 환경에서는 실행하고 통과했다는 전제하에 운영 이미지를 Release하는 파이프라인에서는 Docker Build, Push, Config Repo Update, Github Release 생성 정도만 하고 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Slim CI&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://miro.medium.com/max/1400/1*OnGT6eelEiLpu2q7bE0OEA.jpeg&quot; alt=&quot;Setup a Slim CI for dbt with BigQuery and Docker&quot; /&gt;
&lt;em&gt;출처: &lt;a href=&quot;Setup a Slim CI for dbt with BigQuery and Docker&quot;&gt;Setup a Slim CI for dbt with BigQuery and Docker&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Slim CI는 쉽게 말해서 dbt의 실행 결과를 캐싱해서 필요한 부분만 재실행할 수 있도록 하는 테크닉입니다. dbt Cloud에서는 쉽게 사용할 수 있도록 설정이 되어있지만, dbt CLI 유저라면 직접 구현을 해줘야하는 부분입니다.&lt;/p&gt;

&lt;p&gt;간단한 원리를 설명하자면, dbt run을 했을 때 dbt는 Local State를 &lt;code class=&quot;highlighter-rouge&quot;&gt;manifest.json&lt;/code&gt;에 저장을 해둡니다. 이 &lt;code class=&quot;highlighter-rouge&quot;&gt;manifest.json&lt;/code&gt;이 정상적으로 저장된 정보를 불러올 수 있으면 Graph Selector(&lt;code class=&quot;highlighter-rouge&quot;&gt;state:modified+&lt;/code&gt;)로 변경된 사항들만 run을 할 수 있습니다.&lt;/p&gt;

&lt;p&gt;하지만 어려운 부분은 저희 조직의 데이터 파이프라인의 대부분은 Docker를 통해서 로직을 실행하고, 따로 볼륨을 관리하고 있지 않아서 dbt 런타임에서 실행하고 컨테이너 내부에 저장된 &lt;code class=&quot;highlighter-rouge&quot;&gt;manifest.json&lt;/code&gt;을 다시 불러오기 힘든 환경이라는 점이었습니다.&lt;/p&gt;

&lt;p&gt;처음에는 Kubernetes Persistent Volume을 사용해서 영속하는 걸 생각했지만, 그렇게 됐을 때는 dbt 런타임을 계속해서 띄워두고 여러 소스에서 해당 dbt Pod에 요청을 하는 형태가 되어야 했습니다. 해당 Pod 관리 코스트 측면에서 안 좋을 거라고 생각을 했습니다.&lt;/p&gt;

&lt;p&gt;다른 방법은 dbt rpc를 이용하는 방법이었습니다. &lt;a href=&quot;https://en.wikipedia.org/wiki/Remote_procedure_call&quot;&gt;Remote Procedure Call (RPC)&lt;/a&gt; 방식으로 dbt 서버에 요청을 보내서 작업을 수행하게 하는 인터페이스를 dbt CLI에서는 제공을 하고 있습니다 (&lt;a href=&quot;https://github.com/dbt-labs/dbt-rpc&quot;&gt;Github Repo&lt;/a&gt;). 하지만 이 방식은 현재 Deprecated된 상태로, dbt Server라는 기능으로 대체되어 2022년 이후에 완전히 지원을 중단할 예정입니다. 때문에 지속 가능하지 않은 방법이라고 생각해서 이 방법도 (시도는 했으나) 선택하지 않았습니다.&lt;br /&gt;
최종적으로 선택한 방법은 CI/CD 파이프라인을 최대한 이용해서 도커 이미지에 &lt;code class=&quot;highlighter-rouge&quot;&gt;manifest.json&lt;/code&gt;을 포함시키는 방법이었습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/analytics-engineering-with-dbt/dbt%20ci.png&quot; alt=&quot;dbt ci&quot; /&gt;&lt;/p&gt;

&lt;p&gt;동작시키기 위해서는 두 개의 Dockerfile이 필요합니다. 
1) &lt;code class=&quot;highlighter-rouge&quot;&gt;Dockerfile.full.ci&lt;/code&gt;
2) &lt;code class=&quot;highlighter-rouge&quot;&gt;Dockerfile.incremental.ci&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;과정은 다음과 같습니다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;(on PR create) → Incremental CI에서 Full CI 이미지 기반으로 도커 이미지를 빌드하고 레지스트리에 저장합니다.&lt;br /&gt;
 1-1. Full CI 이미지의 &lt;code class=&quot;highlighter-rouge&quot;&gt;manifest.json&lt;/code&gt; 파일이 있으면, 아래와 같은 코드로 현재 코드의 변경 사항만 dbt run을 적용할 수 있습니다.&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; ```bash
 #!/bin/bash
 ...
    
 dbt run --target=ci -s &quot;state:modified+1 1+exposure:*,+state:modified+&quot; --defer --state &amp;lt;your-state-directory&amp;gt; -x --full-refresh
 dbt test --target=ci -s &quot;state:modified+1 1+exposure:*,+state:modified+&quot;  --defer --state &amp;lt;your-state-directory&amp;gt; -x
 ```
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;p&gt;1-2. 이 시점에 빌드를 하고 있는 컨테이너 안에는 이전 Full CI가 실행될 때의 코드 + 현재 PR에서의 변경 사항이 합쳐진 &lt;code class=&quot;highlighter-rouge&quot;&gt;manifest.json&lt;/code&gt; 이 저장됩니다.&lt;br /&gt;
 1-3. 해당 이미지를 빌드 완료 후 Push 합니다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;(on main branch merge) → Full CI에서 개발(dev) 환경으로 전체 dbt 모델들을 실행하고, 도커 이미지를 만든 뒤 결과물을 레지스트리에 저장합니다. (실패 시, 운영 배포할 수
없습니다.)&lt;/li&gt;
  &lt;li&gt;(on release) → 운영(live) 환경으로 dbt 모델들을 실행하지 않고, 이미지만 빌드하고 푸시 합니다.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;위와 같은 방식으로 최대 12분 정도 걸리던 PR Check 파이프라인을 1분 내외로 단축시켰습니다. 저희 유즈케이스처럼 테이블이 많은 경우 (100+) 퍼포먼스를 크게 향상시킬 수 있는 예제 같습니다.&lt;/p&gt;

&lt;p&gt;굳이 도커 기반으로 푸는 것 말고도 다양한 방법으로도 이런 문제를 해결해볼 수 있을 거라고 생각합니다.&lt;/p&gt;

&lt;h3 id=&quot;35-결과&quot;&gt;3.5. 결과&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Seamless Change&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/analytics-engineering-with-dbt/dbt8.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;v1 데이터와 v2 데이터가 정확하게 일치하는 것을 확인하고, v1 로직을 v2로 100% 교체해 데이터 사용자분들이 어떤 쿼리 수정이 없이도, 더 신뢰할 수 있고 더 많은 마트 테이블들을 사용하실 수 있게 매끄럽게 교체 작업이 이루어졌습니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Data Lineage Graph&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/analytics-engineering-with-dbt/dbt9.png&quot; alt=&quot;소다 스토어 v2 Data Lineage ~~(흐린 눈)~~&quot; /&gt;&lt;em&gt;소다 스토어 v2 Data Lineage &lt;del&gt;(흐린 눈)&lt;/del&gt;&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;dbt로 이관 후, 소다 스토어를 구성하기 위해 필요한 수많은 테이블들, 그리고 의존관계가 어떻게 흐르는지를 확인할 수 있는 방법이 생겼습니다. 이로 인해 유사시에 어떤 테이블의 오류가 다른 마트 테이블들에 영향을 주는지 시각적으로 알 수 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;New SODA Store DAG&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/analytics-engineering-with-dbt/dbt_10.png&quot; alt=&quot;Airflow DAG (부제: 일했다 dbt)&quot; /&gt;&lt;br /&gt;
&lt;img src=&quot;/img/analytics-engineering-with-dbt/dbt_11.png&quot; alt=&quot;&quot; /&gt;&lt;em&gt;Airflow DAG (부제: 일했다 dbt)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;소다 스토어 v2가 2022년 4월 마무리되고 3개월 뒤인 7월까지 에러를 한 번도 낸 적이 없어 아쉬웠습니다. 다행히(?) 이 글을 쓰고 있는 와중에 해당 테이블에 새로운 서비스 관련 데이터가 추가 되어 한 컬럼에 기존에 정의되지 않았던 값이 들어오자 dbt가 제 역할을 해주었습니다.&lt;/p&gt;

&lt;h2 id=&quot;4-그-밖에-시도했던-것들&quot;&gt;4. 그 밖에 시도했던 것들&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Sqlfluff Linting&lt;/strong&gt;: 초반에 SQLFluff를 이용해서 사용자들의 쿼리 스타일을 모두 통일하려고 했습니다. 하지만 아직 dbt Integration이 생긴지 얼마 지나지 않아서인지 CI 단계에서 설정해둔 파이프라인이 깨지는 일이 많았습니다. 현재에는 Github Action에서 빼놓은 상태입니다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;dbt Custom Cli Tool&lt;/strong&gt;: dbt CLI도 많은 기능을 제공하지만, 저희의 유즈케이스에서는 기존에 있는 테이블 dbt 코드 베이스로 이관을 해야 하고, 써줘야 하는 코드가 매우 많았습니다 (e.g. schema.yaml, source.yaml의 테이블과 column, description 등). 때문에 dbt CLI를 래핑 해서 빅쿼리에 저장되어 있는 메타데이터 정보를 dbt에서 사용하는 Yaml로 만들어주는 툴이나, 기존 쓰인 SQL을 dbt에서 사용하는 Jinja SQL로 변환하는 기능 등 저희의 입맛에 맞게 커스텀 툴을 만들어서 사용했습니다. (혹시나 궁금해하시는 분들이 있다면 추후에 오픈소스화하겠습니다)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Airflow Task Dependency Tree&lt;/strong&gt;: Astronomer의 &lt;a href=&quot;https://www.astronomer.io/blog/airflow-dbt-1/&quot;&gt;이 글&lt;/a&gt;처럼 dbt model을 run → test 하는 과정 하나하나를 전부 Airflow Task로 만들려는 시도를 했습니다. dbt Lineage 그래프처럼 Airflow를 통해서도 시각적으로 볼 수 있을 거라고 기대했지만, 아마 다들 예상하시다시피, Task가 너무 많아서 다양한 문제들이 발생했습니다. 때문에 현재와 같이 하나의 Mart를 생성하는 Task들로 구성하게 되었습니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;5-알면-좋았던-것들&quot;&gt;5. 알면 좋았던 것들&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;모델링보다 테스트를 먼저&lt;/strong&gt;&lt;br /&gt;
모델링 보다 Source - Staging - ODS - Mart에 이르는 레이어에 대한 테스트가 선행되었다면 뒤에 있었을 안 맞는 데이터들을 맞추는 시간이 덜 들지 않았을까… 코드처럼 TDD를 했으면 더 시간이 덜 들었을 거 같습니다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;공동 작업을 위한 환경 및 배포 파이프라인 구성&lt;/strong&gt;&lt;br /&gt;
일반적인 애플리케이션들이 그러하듯, dbt 기반 Data Pipeline 또한 배포 파이프라인을 먼저 구성해두고 즉각적으로 변경 사항들이 피드백 루프를 만들도록 구성했으면 커뮤니케이션 코스트가 덜 들 수 있지 않았을까 싶습니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;6-개선해야-하는-점들&quot;&gt;6. 개선해야 하는 점들&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;현재 특정 유즈케이스에서만 동작하도록 설정을 해뒀습니다. 더 범용적으로 dbt를 사용할 수 있도록 확장성 있게 레포를 구성하는 게 필요합니다.&lt;/li&gt;
  &lt;li&gt;지속적으로 Analytics Engineering과 관련 기술을 습득하기 위해서는 많은 노력이 필요합니다. 앞으로 어떻게 이 구조를 유지할지 고민이 더 필요할 듯합니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;7-나아가서&quot;&gt;7. 나아가서&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Metric Store&lt;/strong&gt;&lt;br /&gt;
dbt를 활용한 Analytics Engineering이 시작되자, 최신 트렌드인 &lt;a href=&quot;https://medium.com/@thekensta/making-sense-of-metric-stores-c85faba231a&quot;&gt;Metric Store&lt;/a&gt;도 도입을 하려고 하는 움직임들이 생겨났습니다.&lt;br /&gt;
dbt도 메트릭 스토어로서의 기능도 제공을 하고 있지만, 아직 초기 단계이다 보니 적극적으로 도입하고 있지 않은 상황입니다. 반복적인 업무를 해야 하는 데이터 분석가 또는 사이언티스트 분들의 작업을 간소화할 수 있고 나아가 자동화할 수 있는 부분이라고 생각합니다.&lt;br /&gt;
관련해서 dbt-core의 이슈에서 창업 멤버인 Drew Banin이 해당 기능을 제안한 &lt;a href=&quot;https://github.com/dbt-labs/dbt-core/issues/4071&quot;&gt;이슈 문서&lt;/a&gt;가 매우 인상적이었습니다. 한번 살펴보시는 걸 추천드립니다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Data Service (In House)&lt;/strong&gt;&lt;br /&gt;
이 모든 걸 아우르는 반복적 업무들을 개선하기 위한 자체 인하우스 데이터 서비스를 개발하고 불필요한 일련의 과정들을 내재화 시키는 것이 필요하다고 생각합니다.&lt;br /&gt;
dbt 기반 SQL 작성과 테이블 의존관계 확인, 간단한 구성으로 Metric으로 만들어서 재사용할 수 있는 기능 등을 생각하고 있습니다.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;8-마치며&quot;&gt;8. 마치며&lt;/h2&gt;

&lt;p&gt;dbt와 Analytics Engineering에 대한 제 의견을 종합하자면,&lt;/p&gt;

&lt;p&gt;&lt;em&gt;이런 장점이 있어요&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;분석가들의 업무를 개발자 처럼&lt;/strong&gt;: 일회성 또는 요청 기반의 분석가들의 업무가 Git 중심, CI 파이프라인을 활용한 지속적 테스팅, 지속적 배포 등의 도구를 사용해 더욱 생산성을 높힐 수 있습니다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;높아지는 데이터의 재사용성&lt;/strong&gt;: dbt라는 기술을 통해 데이터 웨어하우스의 기능을 극대화 시킬 수 있습니다. 단순 테이블만 적재하고 쿼리하던 구조에서 벗어나 팩트/디멘션 테이블을 고민하고, View, Materialized View 등의 데이터 웨어하우스 기능들을 활용하거나, 데이터 리니지 그래프를 보며 기존 데이터를 어떻게 더 활용할 지, 또한 데이터 웨어하우스의 모델링에 대한 고민을 시작하게 되었습니다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;견고해지는 데이터 파이프라인&lt;/strong&gt;: 데이터 테스팅, 문서화, 오너십 등의 기능들 그리고 위에 언급한 이점들 덕분에 기존 SQL 기반 데이터 파이프라인을 더욱 견고하게 만들 수 있습니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;em&gt;이런 어려움들이 있어요&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;배포 및 버저닝&lt;/strong&gt;: 분석가로만 구성된 팀에서는 시작하기 어려울 거 같습니다. 지속적인 배포와 버저닝 전략 등 전통적인 소프트웨어 엔지니어 팀에서 할 고민들과 팀의 해법이 정리되어야 제대로 사용하실 수 있다는 생각입니다. 개발 조직의 도움을 받거나 시간을 좀 더 들여서 팀의 입맛에 맞게 사용하는 기간을 더 두시길 추천합니다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;러닝 커브&lt;/strong&gt;: 초기 러닝 커브가 꽤 높은 툴이라고 생각합니다. 기본 기능만 사용하게 되신다면 문제가 없을 수 있으나, 운영 환경에서 중요한 데이터를 다뤄야할 때 난관에 봉착할 수 있습니다. 국내 사용자가 (아직은) 많지 않으므로 공식 문서와 dbt slack 커뮤니티 등을 이용해서 답을 찾아 나가야 합니다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;개발 문화&lt;/strong&gt;: 결국 dbt에서 가장 중요한 건 Analytics Engineering이 조직의 문화와 현재 상황에 잘 맞는 가? 라는 질문이라고 생각합니다. 분석가와 데이터를 다루는 누구나 반복되는 업무와 밀려들어오는 요청으로 인해 재사용성과 테스트 등의 우선순위가 떨어질 수 있습니다. dbt를 도입하는 것은 많은 문제를 해결할 수 있으나, 은총알은 아니기에 많은 고민이 필요한 영역이라고 생각합니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;dbt라는 기술이 최근 데이터 엔지니어링 트렌드가 되어가고 있는 거 같습니다. 하지만 (어떤 기술이 그러하듯,) 이 기술을 실제로 적용하고 규모가 있는 조직에서 사용하기 위해서는 생각보다 정말 많은 고려를 해야 하고 노력이 필요하다는 점을 다시 한번 느끼게 되었습니다. 물론 비용을 지불해서 dbt Cloud를 통해서 이런 과정들을 간소화할 수 있지만, 기술들을 도입하기 전에 마일스톤들을 잘 만들어 두는 것이 필요하다고 생각합니다.&lt;/p&gt;

&lt;p&gt;특정 기술을 도입한다고 해서 Analytics Engineering이 해결하려고 하는 모던 데이터 인프라의 문제점들을 해소시켜주지는 않는다고 생각합니다. 하지만 이러한 움직임들이 모여서 큰 흐름을 만들어 내리라고 믿습니다.&lt;/p&gt;

&lt;p&gt;이 글을 있게 해준 소다 스토어 파티 플래시, 녹스, 디니, 토마스, 그리고 모든 데이터 비즈니스 본부 분들 감사드립니다.&lt;/p&gt;

&lt;p&gt;긴 글 읽어주셔서 감사합니다.&lt;/p&gt;</content><author><name>험프리</name></author><category term="data" /><category term="data engineering" /><category term="analytics engineering" /><summary type="html"></summary></entry><entry><title type="html">쏘카 예약을 효율적으로 - 수학적 모델링을 활용한 쏘카 예약 테트리스</title><link href="https://tech.socarcorp.kr/data/2022/06/10/reservation-tetris.html" rel="alternate" type="text/html" title="쏘카 예약을 효율적으로 - 수학적 모델링을 활용한 쏘카 예약 테트리스" /><published>2022-06-10T00:00:00+00:00</published><updated>2022-06-10T00:00:00+00:00</updated><id>https://tech.socarcorp.kr/data/2022/06/10/reservation-tetris</id><content type="html" xml:base="https://tech.socarcorp.kr/data/2022/06/10/reservation-tetris.html">&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;안녕하세요, 쏘카 데이터 비즈니스 본부의 캐롯, 카일입니다.&lt;/p&gt;

&lt;p&gt;쏘카에서 차량을 예약하기 위해 쏘카 앱을 탐색하다 보면 하나의 쏘카존에서 아반떼, 레이, 코나 등 다양한 차량들이 눈에 들어옵니다. 하나의 존에 차량이 1대만 있을 수도 있고, 같은 차종의 차량이 여러 대가 있을 수 있습니다. 이때, 하나의 존에 같은 종류의 차량이 여러 개가 있다면, 어떤 차량이 어떤 과정을 거쳐 나에게 배정되는지 궁금하신 적 없으신가요?&lt;/p&gt;

&lt;p&gt;이번 글에서는 그 과정에 있는 &lt;strong&gt;예약 테트리스 프로젝트&lt;/strong&gt;를 다룹니다.&lt;/p&gt;

&lt;p&gt;프로젝트를 시작하게 된 계기부터, 선형 최적화 모델을 실제 서비스에 적용하기 위해 구축한 인프라 구조까지 프로젝트의 전반적인 내용을 자세하게 다루었으니 이 글을 읽고 최적화가 모빌리티 산업에서 어떻게 적용되는지 이해할 수 있는 시간이 되길 바랍니다.&lt;/p&gt;

&lt;p&gt;예상 독자는 다음과 같습니다&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;쏘카의 예약 과정의 뒷부분이 궁금하신 분&lt;/li&gt;
  &lt;li&gt;모빌리티 산업에서 최적화(Optimization) 프로젝트가 어떻게 동작하는지 궁금하신 분&lt;/li&gt;
  &lt;li&gt;데이터 기반의 오퍼레이션을 만드는 과정이 궁금하신 분&lt;/li&gt;
  &lt;li&gt;프로젝트 과정에서 어떻게 아키텍처를 설계했는지 궁금하신 분&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;목차&quot;&gt;목차&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;#1-예약-테트리스-프로젝트-소개&quot;&gt;예약 테트리스 프로젝트 소개&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#2-예약-테트리스-최적화-모델링&quot;&gt;예약 테트리스 최적화 모델링&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#3-예약-테트리스-모델-배포&quot;&gt;예약 테트리스 모델 배포&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#4-예약-테트리스-적용-성과&quot;&gt;예약 테트리스 적용 성과&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#5-마무리&quot;&gt;마무리&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;1-예약-테트리스-프로젝트-소개-&quot;&gt;1. 예약 테트리스 프로젝트 소개 &lt;a name=&quot;1-예약-테트리스-프로젝트-소개&quot;&gt;&lt;/a&gt;&lt;/h2&gt;

&lt;h3 id=&quot;11-프로젝트-이름의-유래&quot;&gt;1.1 프로젝트 이름의 유래&lt;/h3&gt;

&lt;p&gt;프로젝트를 설명하기에 앞서, ‘예약 테트리스’ 이름의 유래를 공유드리겠습니다. 테트리스는 위에서 내려오는 블록을 빈 공간에 맞춰 차곡차곡 쌓아 꽉 찬 한 줄 한 줄을 만들어 포인트를 얻는 퍼즐 게임입니다.&lt;/p&gt;

&lt;p&gt;이번 프로젝트는 하나의 쏘카존에 있는 여러 차량(같은 차종의 차량)이 있는 상황에서 예약과 차량을 배정(매칭)하는 프로젝트입니다. &lt;strong&gt;들어오는 예약을 차량의 빈 공간에 차곡차곡 정리하는 과정&lt;/strong&gt;이 마치 테트리스 게임과 비슷하다고 생각했기에 예약 테트리스라는 프로젝트 이름을 붙였습니다.&lt;/p&gt;

&lt;p&gt;쏘카에선 예약에 차량을 어떻게 배정하는지가 매우 중요합니다. &lt;strong&gt;예약에 차량을 어떻게 배정하냐에 따라 얼마나 많은 고객이 쏘카를 이용할 수 있는지가 결정되기 때문&lt;/strong&gt;입니다. 차량이 사용되지 않는 시간이 적을수록(=고객의 차량의 점유 시간이 길수록) 운영 효율이 좋아지기 때문에 예약에 차량을 어떻게 배정하는지에 따라 비즈니스에 영향을 줍니다. 즉, 비즈니스 임팩트에 영향을 줄 수 있는 문제입니다.&lt;/p&gt;

&lt;p&gt;한 쏘카존에 같은 종류의 차량이 두 대 있는 경우를 예시로 추가 설명드리겠습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/reservation-tetris/example-reserve-fail.png&quot; alt=&quot;&quot; width=&quot;100%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;A와 B라는 서로 다른 두 고객이 각각 08시 ~ 12시와 20시 ~ 24시 총 두 건의 예약을 한 상태에서, 0시부터 24시까지 24시간 동안 이용하고 싶어 하는 C라는 고객이 같은 존에서 같은 차량을 대여하고 싶어 하는 상황을 생각해 봅시다.&lt;/p&gt;

&lt;p&gt;이때 만약 A와 B에게 서로 다른 차량이 배정된 상태라면 C는 이용할 수 있는 차량이 없을 것입니다.&lt;/p&gt;

&lt;p&gt;두 차량 모두 C의 예약을 받을 수 있을 만큼의 충분한 여유 공간이 없기 때문입니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/reservation-tetris/example-reserve-success.png&quot; alt=&quot;&quot; width=&quot;100%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;하지만 만약 A와 B의 예약에 같은 차량을 배정했다면 두 사람의 예약에 배정되지 않은 하나의 차량이 남아 C는 수월하게 쏘카를 이용할 수 있게 됩니다.&lt;/p&gt;

&lt;p&gt;이처럼 예약의 상황마다 더 적절한 차량을 배정해 주면 더 많은 차량을 준비하지 않아도 더 많은 고객들이 쏘카의 서비스를 이용할 수 있도록 할 수 있고 운영 효율이 좋아지게 됩니다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;12-예약-테트리스의-목적&quot;&gt;1.2 예약 테트리스의 목적&lt;/h3&gt;

&lt;p&gt;예약 테트리스 프로젝트가 도입되기 이전에도 예약을 차량에 배정하는 효율화 작업은 이루어지고 있었습니다. 단, 지금과 다른 점이 있다면 &lt;strong&gt;이 모든 작업이 쏘카 직원분들의 손으로 진행되고 있었습니다.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;앞서 설명한 문제 수준의 난이도라면 사람 손으로도 쉽게 처리할 수 있겠지만, 쏘카는 15,000대 이상의 차량과 4,000개의 쏘카존을 보유하고 있습니다. 이런 상황에서 발생하는 예약이 매우 많기 때문에 사람이 직접 진행하기 어렵고, 진행한다고 해도 매우 많은 시간이 소요됩니다.&lt;/p&gt;

&lt;p&gt;만약 같은 종류의 차량이 두 대뿐이라고 해도 쏘카는 최대 90일 전부터 예약을 할 수 있다는 점을 생각하면 사람이 직접 최적의 차량 배정을 하기가 쉽지 않습니다. 즉, &lt;strong&gt;어제 수정한 배정 결과가 내일이 되면 새로운 예약이 추가되어 더 이상 최적이 아닐 수 있습니다.&lt;/strong&gt; 쏘카에서 차량이 가장 많은 제주공항 존의 경우는 예약 테트리스 서비스가 배포되기 전까진 하루에 최대 4시간 정도 시간을 사용하며 고생하고 있었습니다.&lt;/p&gt;

&lt;p&gt;차량 배정 프로세스를 자동화하면 쏘카의 직원분들이 업무 시간을 더 효율적으로 사용할 수 있고, 사람의 머리로 도출하기 어려운 조합을 자동으로 산출해 최적화된 차량 배정으로 서비스를 운영할 수 있게 됩니다. &lt;strong&gt;즉, 예약 테트리스 프로젝트는 업무 효율과 차량 운영 효율 두 마리 토끼를 모두 잡기 위한 프로젝트입니다.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;해결하려는 목적을 정리하면 다음과 같습니다&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;쏘카의 운영 효율 개선&lt;/li&gt;
  &lt;li&gt;차량 배정 최적화 과정을 자동화해 내부 운영 리소스 효율화(업무 효율 개선)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;2-예약-테트리스-최적화-모델링-&quot;&gt;2. 예약 테트리스 최적화 모델링 &lt;a name=&quot;2-예약-테트리스-최적화-모델링&quot;&gt;&lt;/a&gt;&lt;/h2&gt;

&lt;h3 id=&quot;21-최적화-문제optimization-problem의-접근법&quot;&gt;2.1 최적화 문제(Optimization Problem)의 접근법&lt;/h3&gt;

&lt;p&gt;최적화 문제(Optimization Problem)는 어떤 목적 함수(Objective Function)의 함숫값을 최대화 또는 최소화하는 변수의 해 값을 찾는 유형의 문제를 뜻합니다. 최적화 문제를 푸는 방법은 다양하게 있는데, 다음과 같이 정리할 수 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/reservation-tetris/optimization-methods.png&quot; alt=&quot;&quot; width=&quot;100%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;최적화 문제를 푸는 방법 중 첫 번째는 알고리즘을 사용하는 것이고, 두 번째는 해 찾기 도구인 솔버(Solver)를 활용하는 것입니다.&lt;/p&gt;

&lt;p&gt;알고리즘으로 최적화 문제를 접근하는 방법도 두 가지로 나눌 수 있는데 먼저 &lt;strong&gt;해당 문제에 특정된 알고리즘을 사용 또는 개발&lt;/strong&gt;하는 방법이 있습니다. 특정 문제를 풀기 위한 알고리즘의 대표적 예시로는 최단거리 경로를 구하는 &lt;a href=&quot;https://ko.wikipedia.org/wiki/%EB%8D%B0%EC%9D%B4%ED%81%AC%EC%8A%A4%ED%8A%B8%EB%9D%BC_%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98&quot;&gt;다익스트라 알고리즘 (Dijkstra’s Algorithm)&lt;/a&gt; 을 들 수 있습니다. 문제에 딱 맞는 알고리즘을 개발하면 알고리즘으로 도출된 해가 최적임을 보장할 수 있다는 큰 장점이 존재합니다. 하지만 그런 알고리즘을 개발하는 데까지 시간과 노력이 매우 많이 필요하기 때문에 단점 또한 명확합니다.&lt;/p&gt;

&lt;p&gt;최적화 문제를 알고리즘으로 접근하는 방식의 두 번째 갈래로는 &lt;strong&gt;휴리스틱 알고리즘&lt;/strong&gt;이 있습니다.&lt;/p&gt;

&lt;p&gt;휴리스틱 알고리즘은 정확한 최적해를 효율적으로 찾을 수 있는 방법이 없을 때 해의 최적성을 희생해 더 빠르고 효율적으로 해를 찾는 알고리즘을 의미하고, 유전 알고리즘(Genetic Algorithm), 개미 집단 알고리즘(Ant Colony Optimization Algorithm) 등이 잘 알려진 예시입니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;문제 유형과 관계없이 쉽고 빠르게 근사 최적해를 구할 수 있다는 이점이 있지만 휴리스틱적 접근은 계산보다는 탐색에 더 가깝기 때문에 찾은 해가 최적임을 보장할 수 없다는 단점&lt;/strong&gt;이 있습니다.&lt;/p&gt;

&lt;p&gt;알고리즘을 직접 구현하지 않고 &lt;strong&gt;Solver를 활용하여 모델링을 통해 최적화 문제를 푸는 방법&lt;/strong&gt;도 존재합니다.&lt;/p&gt;

&lt;p&gt;Solver는 수학적으로 표현된 최적화 문제의 해를 구하는 최적해 탐색 도구로 &lt;a href=&quot;https://www.gurobi.com/&quot;&gt;Gurobi&lt;/a&gt;, &lt;a href=&quot;https://www.ibm.com/kr-ko/analytics/cplex-optimizer&quot;&gt;CPLEX&lt;/a&gt; 등이 상업적 Solver와 &lt;a href=&quot;http://www.pyomo.org/&quot;&gt;Pyomo&lt;/a&gt;, &lt;a href=&quot;https://developers.google.com/optimization&quot;&gt;OR-Tools&lt;/a&gt; 등의 오픈 소스 Solver 등이 있습니다.&lt;/p&gt;

&lt;p&gt;Solver로 최적화 문제를 풀기 위해서는 문제를 수식으로 모델링 해야 하는데 이 과정을 &lt;a href=&quot;https://en.wikipedia.org/wiki/Mathematical_model&quot;&gt;수학적 모델링(Mathematical Programming)&lt;/a&gt;이라고 부릅니다.&lt;/p&gt;

&lt;p&gt;문제의 성격이 선형 또는 비선형인지에 따라 &lt;a href=&quot;https://en.wikipedia.org/wiki/Linear_programming&quot;&gt;선형 계획법(Linear Programming)&lt;/a&gt;과 &lt;a href=&quot;https://en.wikipedia.org/wiki/Nonlinear_programming&quot;&gt;비선형 계획법(Nonlinear Programming)&lt;/a&gt;으로 나뉘고, 구하고자 하는 해가 정수로 한정되는 경우는 &lt;a href=&quot;https://en.wikipedia.org/wiki/Integer_programming&quot;&gt;정수 계획법(Integer Programming)&lt;/a&gt;으로 정의할 수 있습니다.&lt;/p&gt;

&lt;p&gt;수학적 모델링을 통해 수식화된 문제를 풀기 위해 Solver를 사용하면 매우 빠른 속도로 최적해 또는 최적해에 매우 근접한 해를 도출할 수 있다는 매우 큰 장점이 존재합니다. 
하지만 문제가 복잡할수록 시간이나 컴퓨팅 파워 같은 연산을 위한 리소스가 많이 요구되어 비용적인 측면을 고려해야 한다는 단점이 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;예약 테트리스 프로젝트에서는 Solver를 사용하여 최적화 문제를 해결하고 있습니다.&lt;/strong&gt; 직접 서비스에 사용하는 서비스인만큼 최대한 최적에 가까운 해를 도출하는 것이 필요했고, 알고리즘을 직접 개발하는 것 대비 훨씬 짧은 시간 안에 좋은 결과를 도출할 수 있었기 때문입니다. 연산에 필요한 컴퓨팅 파워는 후술할 GCP(Google Cloud Platform)의 힘을 빌려 단점으로 꼽히는 리소스 측면도 충분히 해결할 수 있었기 때문에 최적화 문제의 접근법 중 가장 적합한 방법론이라고 판단했습니다.&lt;/p&gt;

&lt;h3 id=&quot;22-정수-계획법integer-programming&quot;&gt;2.2 정수 계획법(Integer Programming)&lt;/h3&gt;

&lt;p&gt;예약 테트리스 프로젝트는 차량 배정 최적화 모델링을 위해 &lt;strong&gt;정수 계획법&lt;/strong&gt;을 사용합니다.&lt;/p&gt;

&lt;p&gt;구체적인 모델을 다루기 전 먼저 정수 계획법이 무엇인지 짚고 넘어가겠습니다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Integer_programming&quot;&gt;정수 계획법(Integer Programming)&lt;/a&gt;은 주로 선형 제약조건으로 표현된 해 공간에서 조합 최적화(Combinatorial Optimization) 문제를 푸는 최적화 기법입니다.&lt;/p&gt;

&lt;p&gt;생소한 단어들이 많아 처음 접하는 개념처럼 느낄 수도 있지만 다음과 유사한 일차 부등식 문제를 풀어본 경험이 있다면 낯설지 않다고 느낄 것입니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;“0보다 큰 정수 x와 y가 아래와 같은 조건을 만족할 때, k 값을 최대화하는 x, y를 찾으면?”&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/img/reservation-tetris/cp-example.png&quot; alt=&quot;&quot; width=&quot;100%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이런 유형의 문제가 바로 정수 계획법을 사용할 수 있는 간단한 예라고 할 수 있습니다.&lt;/p&gt;

&lt;p&gt;우리에게 익숙한 이 문제를 최적화 모델의 3요소라 할 수 있는 &lt;strong&gt;제약조건, 결정 변수, 목적 함수&lt;/strong&gt;로 설명하겠습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;제약조건(Constraints)
    &lt;ul&gt;
      &lt;li&gt;특정 제약을 거는 조건입니다. 예를 들어 x는 0 보다 큰 값이다, -x와 y를 더하면 2보다 작다입니다.&lt;/li&gt;
      &lt;li&gt;x, y 축과 부등식으로 표현된 두 직선이 x와 y가 가질 수 있는 값을 한정하는 &lt;strong&gt;제약조건&lt;/strong&gt;이 됩니다&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;결정 변수(Decision Variable)
    &lt;ul&gt;
      &lt;li&gt;우리가 알고자 하는 변수인 x, y는 k 값을 결정하는 &lt;strong&gt;결정 변수&lt;/strong&gt;로 정의할 수 있습니다&lt;/li&gt;
      &lt;li&gt;모든 제약조건을 만족하는 결정 변수 값의 집합을 &lt;strong&gt;해 공간(Solution Space)&lt;/strong&gt;라고 합니다&lt;/li&gt;
      &lt;li&gt;해 공간이 정수로만 이루어져 있기 때문에 정수 계획법을 사용하게 됩니다&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;목적 함수(Objective Function)
    &lt;ul&gt;
      &lt;li&gt;최대화하고자 하는 값 k는 이 문제의 목적이 되는 함수로 &lt;strong&gt;목적 함수&lt;/strong&gt;라고 부릅니다&lt;/li&gt;
      &lt;li&gt;목적 함수가 결정 변수에 대해 선형 관계를 가지면 선형 계획법, 제곱 등의 비선형 관계를 가지면 비선형 계획법이 됩니다&lt;/li&gt;
      &lt;li&gt;이 문제는 k가 x와 y에 대해 일차식의 형식을 띄고 있기 때문에 &lt;strong&gt;정수 선형 계획법(Integer Linear Programming)&lt;/strong&gt;의 예시로 볼 수 있습니다&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;위 문제에서 각 요소들을 표시하자면 다음처럼 표현할 수 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/reservation-tetris/cp-example-explained.png&quot; alt=&quot;&quot; width=&quot;100%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;23-최적화-지표-정의하기--어떤-상태가-더-최적일까&quot;&gt;2.3 최적화 지표 정의하기 : 어떤 상태가 더 ‘최적’일까?&lt;/h3&gt;

&lt;p&gt;예약 테트리스 모델링에서 가장 어려운 부분은 &lt;strong&gt;어떤 차량 배정 상태가 더 “최적”인지를 수치적으로 판단할 수 있는 지표를 정의&lt;/strong&gt;하는 것이었습니다.&lt;/p&gt;

&lt;p&gt;모델 성능과 최적화 정도 사이에서 고민한 끝에, &lt;strong&gt;가상 예약&lt;/strong&gt;이라는 개념을 도입해 지표를 만들었습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;실제 예약: 실제로 고객이 이용 중이거나 이용 예정인 예약&lt;/li&gt;
  &lt;li&gt;가상 예약: 실제 예약이 들어올 수 있는 여유 공간을 나타낸 가상의 예약&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;완벽한 최적해는 아니더라도 가상의 예약 건이 가장 많이 들어올 수 있도록 예약에 차량을 배정하는 모델을 작성하기로 했습니다.&lt;/p&gt;

&lt;p&gt;즉, &lt;strong&gt;가상 예약 건의 예약 가능성이 클수록 더 최적이라고 판단&lt;/strong&gt;한 것입니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/reservation-tetris/example-possibility-0.png&quot; alt=&quot;&quot; width=&quot;100%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/reservation-tetris/example-possibility-1.png&quot; alt=&quot;&quot; width=&quot;100%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;앞서 들었던 예시로 설명하자면, A와 B의 예약을 서로 다른 차량에 배정한다면 예약 가능한 하루 단위의 가상 예약건수는 0이 되지만, 두 예약을 같은 차량에 배정한다면 1이 되기 때문에 후자의 경우를 더 최적이라고 판단할 수 있습니다.&lt;/p&gt;

&lt;p&gt;예약이 어떤 차량에 배정되었는지가 중요하고, 다른 예약과의 선후 관계는 변수 단위에서 고려하지 않아도 되기 때문에 모델의 최적해 도출 속도에서 강점을 가지는 접근법이었습니다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;24-최적화-모델-정의하기&quot;&gt;2.4 최적화 모델 정의하기&lt;/h3&gt;

&lt;p&gt;예약 테트리스의 최적화 모델은 다음과 같이 정의됩니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;결정 변수: 실제 또는 가상의 예약에 차량의 배정 여부(0 또는 1)&lt;/li&gt;
  &lt;li&gt;목적 함수: 예약 가능한 가상 예약건수의 최대화&lt;/li&gt;
  &lt;li&gt;제약조건
    &lt;ul&gt;
      &lt;li&gt;모든 예약은 단 하나의 차량에 배정되어야 한다&lt;/li&gt;
      &lt;li&gt;차량이 고정되어야 하는 예약은 배정된 차량이 변경되면 안 된다&lt;/li&gt;
      &lt;li&gt;임의의 서로 다른 두 개의 실제 예약은 같은 차량에 배정된 경우 서로 겹칠 수 없다&lt;/li&gt;
      &lt;li&gt;임의의 실제 예약과 가상 예약은 같은 차량에 배정된 경우 서로 겹칠 수 없다&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이를 수식으로 표현하면 다음과 같이 작성할 수 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/reservation-tetris/formulation.png&quot; alt=&quot;&quot; width=&quot;100%&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;25-최적화-모델-구현하기--google-or-tools&quot;&gt;2.5 최적화 모델 구현하기 : Google OR-Tools&lt;/h3&gt;

&lt;p&gt;수식화한 모델을 코드로 구현하고 최적해를 찾기 위해서는 Solver가 필요합니다.&lt;/p&gt;

&lt;p&gt;예약 테트리스의 최적화 모델은 구글의 오픈소스 Solver인 &lt;a href=&quot;https://developers.google.com/optimization&quot;&gt;Google OR-Tools&lt;/a&gt;의 파이썬 패키지로 구현하였습니다.&lt;/p&gt;

&lt;p&gt;Google OR-Tools가 지원하는 Solver 중 조합 최적화 문제를 위한 &lt;a href=&quot;https://developers.google.com/optimization/cp/cp_solver&quot;&gt;CP-SAT&lt;/a&gt; Solver는 무료로 사용할 수 있는 오픈소스임에도 &lt;a href=&quot;https://www.minizinc.org/challenge2021/results2021.html&quot;&gt;뛰어난 성능&lt;/a&gt;을 가지고 있고, 사용자의 입맛에 맞는 커스텀 설정들을 지원하기 때문에 이번 프로젝트에 적합하다고 판단했습니다.&lt;/p&gt;

&lt;p&gt;제약조건을 수식화하는 것도 직관적이기 때문에 개발 난이도도 높지 않은 편입니다. 최적화 문제를 푸는 분이 계시다면 Google Or-Tools Solver를 추천드립니다.&lt;/p&gt;

&lt;p&gt;앞에서 예시로 가져온 문제를 CP-SAT Solver로 푸는 파이썬 코드를 보면 실제 수식과의 괴리감이 크게 없는 것을 확인할 수 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/reservation-tetris/python-code-example.png&quot; alt=&quot;&quot; width=&quot;100%&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;3-예약-테트리스-모델-배포-&quot;&gt;3. 예약 테트리스 모델 배포 &lt;a name=&quot;3-예약-테트리스-모델-배포&quot;&gt;&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;최적화 모델링을 통해 생성된 모델을 실제 서비스에 배포하기 위해선 여러 작업이 필요합니다. 우선 쏘카 서비스 서버에서 최적화 요청을 해야 하고, 최적화 결과를 서비스 서버에 전달해 데이터베이스에 반영해야 합니다.&lt;/p&gt;

&lt;p&gt;이를 위해 쏘카의 서비스 엔지니어링 본부와 협업을 진행했습니다&lt;/p&gt;

&lt;p&gt;이 프로젝트의 요구 조건은 다음과 같습니다&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;1) Solver를 실행할 서버 환경이 필요하며, 빠르게 결과를 반환해야 합니다&lt;/li&gt;
  &lt;li&gt;2) 쏘카 서비스 서버와 최적화 서버의 데이터 요청 프로토콜이 필요합니다&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;31-최적화-서버--병렬-처리&quot;&gt;3.1 최적화 서버 &amp;amp; 병렬 처리&lt;/h3&gt;
&lt;p&gt;Solver는 실행할 서버 환경을 “최적화 서버”로 지칭하고, 쏘카 서비스의 서버는 “쏘카 서비스 서버”로 지칭하겠습니다.&lt;/p&gt;

&lt;p&gt;Solver는 CPU 연산으로 진행되며, 저희 프로젝트에선 최대 90일 치의 데이터를 가지고 최적화를 수행해야 합니다. 이 과정에서 많은 데이터를 빠르게 처리해야 합니다. 배정 가능한 경우의 수를 따지면 &lt;code class=&quot;highlighter-rouge&quot;&gt;존 x 차종 별 예약건수(최대 90일) x 차량 대수&lt;/code&gt;가 됩니다. 쏘카는 약 4,000개의 존을 가지고 있고 15,000대가 넘는 차량을 보유하고 있습니다. 위 최적화를 실행하기 위해 많은 컴퓨팅 파워가 필요합니다.&lt;/p&gt;

&lt;p&gt;쏘카 서비스 서버에서 최적화 서버에 최적화 요청을 하고, 최적화 연산이 실행되는 동안 새로운 예약이 들어온다면 그 최적화는 다시 실행해야 합니다. 따라서 저희는 더 빠르게 최적화할 수 있는 방법을 고민했습니다.&lt;/p&gt;

&lt;p&gt;Solver 자체의 성능 개선을 하는 방법과 최적화를 병렬로 실행하는 작업을 모두 할 수 있다고 판단했고, Solver 자체의 성능은 최적화에서 연산을 줄이기 위한 트릭을 사용해 줄였습니다. 그 후엔 &lt;a href=&quot;https://github.com/ray-project/ray&quot;&gt;Ray&lt;/a&gt;를 사용해 최적화 작업을 병렬로 실행했습니다.&lt;/p&gt;

&lt;p&gt;Ray는 다음과 같이 데코레이터를 사용해 간단하게 병렬 처리를 실행할 수 있는 라이브러리입니다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;ray&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;ray&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;init&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;o&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ray&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;remote&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;futures&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;remote&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ray&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;futures&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;위에서 말씀드린 것처럼 연산을 실행하기 위해 많은 컴퓨팅 파워가 필요하기 때문에, CPU 성능이 좋은 인스턴스를 선택해 사용하고 있습니다. 더 자세히 말씀드리면 Google Cloud Platform의 vCPU n2d-highcpu-224 인스턴스를 사용하고 있습니다. CPU 224개를 사용한다고? 생각하실 수 있지만 선점형(Preemtible) 인스턴스를 사용할 경우 US 기준 1시간에 1.69 달러로 저렴합니다. GCP의 선점형 인스턴스는 AWS의 스팟 인스턴스와 유사한 서비스입니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/reservation-tetris/preemtible-price.png&quot; alt=&quot;img&quot; width=&quot;100%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;단, 선점형 인스턴스는 사용하던 도중 구글 클라우드 측에서 회수할 수 있는 단점을 가지고 있습니다. 이런 경우를 대비해 만약 선점형 인스턴스가 종료된다면 새로운 최적화 서버를 띄우는 방식으로 구현했습니다. 이 과정에서 &lt;a href=&quot;https://cloud.google.com/compute/docs/shutdownscript?hl=ko&quot;&gt;Shutdown Script&lt;/a&gt;를 사용했습니다.&lt;/p&gt;

&lt;p&gt;최적화 요청을 모두 처리하면, 최적화 서버를 자동으로 종료하도록 설정해 낭비될 수 있는 비용을 미리 절감했습니다.&lt;/p&gt;

&lt;h3 id=&quot;32-쏘카-서비스-서버와-최적화-서버의-데이터-프로토콜&quot;&gt;3.2 쏘카 서비스 서버와 최적화 서버의 데이터 프로토콜&lt;/h3&gt;
&lt;p&gt;데이터 프로토콜을 정의하기 전에 &lt;strong&gt;“예약이 하나 생성될 때마다 실시간으로 실행돼야 하는가?”&lt;/strong&gt;에 대해 고민했습니다. 예약이 새로 생성될 때마다 최적화를 실행해서 결과를 반영하는 방식도 존재했고, 많은 예약을 배치로 정리하는 방식도 존재했습니다. 예약이 들어올 때마다 기존 예약을 바꾸는 것을 실험해 본 결과 일희일비하는 모습을 보이기도 했고, 쏘카 매니저분들이 운영하실 때 혼란을 가중할 수 있다 판단했습니다.&lt;/p&gt;

&lt;p&gt;실제로 현업에 계신 분에게 여쭤보니, 예약이 들어올 때마다 할 필요는 없고 성수기 기준 1시간에 1번씩 실행하면 괜찮다고 이야기 들었습니다. &lt;strong&gt;한번 최적화를 잘 해두면, 1시간 후엔 바꿀 부분이 많이 없기 때문에 매번 할 필요가 없다는 현업의 이야기를 들었습니다.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;위 내용을 토대로 예약을 일정 간격으로 정리하는 방식(Batch)으로 결정했습니다. 단, 쏘카 서비스 서버에서 최적화 요청 빈도는 추후에 변경될 수 있기에 이런 변경 가능성도 고려했습니다.&lt;/p&gt;

&lt;p&gt;그와 동시에 데이터를 어떻게 주고받을지에 대한 논의도 진행했습니다. 최적화를 하기 위해 데이터가 존재해야 하는데, 데이터가 저장되는 데이터 웨어하우스인 BigQuery는 실시간으로 데이터가 저장되지 않고, ETL 파이프라인을 통해 1시간에 1번씩 저장됩니다. 추후에 최적화 요청 빈도가 변할 수 있기에 데이터 웨어하우스의 데이터를 사용하지 않고 별도의 메시지(Message)로 데이터를 주고받기로 했습니다.&lt;/p&gt;

&lt;p&gt;메시지 프로토콜은 서버와 데이터 조직이 나뉘는 쏘카에서 적합했으며, 서버에선 메시지를 Push 하고, 최적화 서버에선 메시지를 받아와(Pull) 연산을 진행한 후 다시 서버 쪽에게 최적화 결과를 반환하는 구조로 진행됩니다.&lt;/p&gt;

&lt;p&gt;API 형태로 진행하는 방법도 고민했으나, 최적화 작업의 특성상 연산 시간이 오래 소요될 수 있기 때문에 메시지 형태로 작업하기로 협의했습니다.&lt;/p&gt;

&lt;p&gt;메시지 시스템은 대표적으로 Apache Kafka, AWS SQS, GCP Pub/Sub 등을 활용할 수 있습니다.&lt;/p&gt;

&lt;p&gt;이 프로젝트를 위해 Kafka를 띄우기엔 관리의 리소스가 더 크다고 판단했고 클라우드의 매니지드 시스템인 AWS SQS와 GCP Pub/Sub을 고려했습니다.&lt;/p&gt;

&lt;p&gt;AWS SQS와 GCP Pub/Sub의 큰 차이는 메시지를 저장하는 기간(리텐션)의 차이와 메시지의 Payload 사이즈 등이 있습니다. AWS SQS는 최대 Payload Size가 256KB, GCP Pub/Sub은 최대 10MB입니다. 저희는 90일간의 예약 내역과 차종의 데이터를 담아 메시지를 보내기 때문에 256KB보단 10MB가 안정적이라 판단했고, 따라서 GCP Pub/Sub을 사용하기로 결정했습니다&lt;/p&gt;

&lt;p&gt;혹시 메시지 시스템에서 생소하신 분들을 위해 간단하게 아시면 좋은 내용을 정리하면 다음과 같습니다&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Pub/Sub 구조
    &lt;ul&gt;
      &lt;li&gt;서비스 간의 비동기 통신을 위해 사용되는 통신 모델입니다. Pub/Sub 구조에서 사용되는 몇 가지 중요한 개념을 짚고 넘어가면 다음과 같습니다&lt;/li&gt;
      &lt;li&gt;Topic
        &lt;ul&gt;
          &lt;li&gt;Publisher가 발행하는 메시지를 Subscriber에게 전송하는 창구 같은 개념입니다&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Publisher/Producer
        &lt;ul&gt;
          &lt;li&gt;메시지를 생성해 Topic으로 발행하는 서비스입니다&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Subscriber/Consumer
        &lt;ul&gt;
          &lt;li&gt;Topic을 구독해 메시지를 받는 주체입니다&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Push와 Pull
        &lt;ul&gt;
          &lt;li&gt;Subscriber가 메시지를 전달받는 방식의 종류에는 Push와 Pull 두 가지가 있습니다.&lt;/li&gt;
          &lt;li&gt;Push: Pub/Sub 시스템이 Subscriber에서 메시지를 밀어 넣는(Push) 방법&lt;/li&gt;
          &lt;li&gt;Pull: Subscriber가 직접 서비스로부터 메시지를 당겨오는(Pull) 방법&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;메시지를 받은 후, Google Cloud Platform의 Dataflow로 데이터를 처리했습니다. 이 과정에서 Apache Spark를 사용할 수 있었지만, Pub/Sub과 Dataflow의 결합이 편리하므로 Dataflow를 사용했습니다.&lt;/p&gt;

&lt;p&gt;최종 인프라는 다음과 같습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/reservation-tetris/architecture.png&quot; alt=&quot;img&quot; width=&quot;100%&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;쏘카 서비스 서버에서 최적화 요청을 하기 전에, 최적화 서버를 띄우는 메시지를 보냅니다&lt;/li&gt;
  &lt;li&gt;그 과정에서 최적화 서버가 띄워지고, 쏘카 서비스 서버는 Pub/Sub에 최적화가 필요한 예약과 차종 데이터를 보냅니다(Push)&lt;/li&gt;
  &lt;li&gt;최적화 서버에선 메시지를 받고(Pull) Ray로 최적화를 병렬로 실행합니다&lt;/li&gt;
  &lt;li&gt;최적화 결과를 쏘카 서비스 서버에게 보냅니다(Push)&lt;/li&gt;
  &lt;li&gt;쏘카 서비스 서버에선 최적화 결과를 데이터베이스에 반영하고 성공 여부를 다시 최적화 결과 Pub/Sub에 보냅니다(Push)&lt;/li&gt;
  &lt;li&gt;실행된 최적화 서버는 서버의 CPU, Memory 사용량이 특정 조건이 될 경우(예 : 일정 시간 이상 CPU Usage가 5% 이하인 경우) 최적화 서버를 종료합니다&lt;/li&gt;
  &lt;li&gt;위 과정에서 선점형 인스턴스가 구글에게 회수된다면, Shutdown Script가 다시 최적화 서버를 실행시킵니다&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;4-예약-테트리스-적용-성과-&quot;&gt;4. 예약 테트리스 적용 성과 &lt;a name=&quot;4-예약-테트리스-적용-성과&quot;&gt;&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;프로젝트 소개 단에서도 언급했다시피, 예약마다 어떤 차량을 배정해 주는지에 따라 같은 대수의 차량에서도 얼마나 많은 고객이 쏘카를 이용할 수 있는지가 달라집니다.&lt;/p&gt;

&lt;p&gt;예약 테트리스 프로젝트로 실제 운영 효율이 얼마나 더 좋아졌는지는 &lt;strong&gt;사용한 차량 대비 차량이 얼마나 점유되었는지&lt;/strong&gt;를 확인해 보면 됩니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;사용한 차량&lt;/strong&gt; = 전체 운영 중인 차량 중 예약에 사용된 차량의 비율 = &lt;strong&gt;차량 사용 비율&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;차량의 점유 정도&lt;/strong&gt; = 판매 가능한 모든 차량의 시간 중 예약으로 점유된 시간의 비율 = &lt;strong&gt;가동률&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;위 개념은 카셰어링 비즈니스를 처음 접한다면 다소 생소한 개념으로 느껴질 수 있기 때문에 위에서 들었던 예시로 설명해 보겠습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/reservation-tetris/metric-example-1.png&quot; alt=&quot;img&quot; width=&quot;100%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;총 두 대의 차량이 있을 때, 앞선 두 개의 예약에 각각 다른 차량을 배정하여 세 번째 예약이 예약 실패되었다면 차량 사용 비율은 1.0, 가동률은 0.25가 됩니다.&lt;/p&gt;

&lt;p&gt;반면 두 개의 예약에 같은 차량을 배정하여 세 번째 예약이 무사히 예약되었다면 차량 사용 비율은 동일하게 1.0이지만 가동률은 0.75로 더 많은 예약을 수용할 수 있었음을 뜻합니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/reservation-tetris/metric-example-2.png&quot; alt=&quot;img&quot; width=&quot;100%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;동일한 예시에 차량을 한 대 추가하여 앞선 두 개의 예약에 각자 다른 차량을 배정해도 세 번째 예약을 받을 수 있었던 경우도 살펴보겠습니다.&lt;/p&gt;

&lt;p&gt;세 개의 예약에 각각 다른 차량을 배정한 경우에는 운영 중인 모든 차량을 사용했기 때문에 차량 사용 비율은 1.0이 되고, 가동률은 0.5가 됩니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;하지만 같은 차량을 배정할 수 있는 예약을 잘 정리한다면 3대의 차량 중 2대만을 사용해도 충분하기 때문에 가동률은 0.5로 동일하지만 차량 사용 비율은 0.67로 더 낮게 운영할 수 있습니다.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;이렇게 차량 사용 비율과 가동률을 비교하면 예약 테트리스 프로젝트를 통해 같은 대수의 차량으로 더 많은 예약을 수용하게 되었는지, 또는 같은 예약량이 더 적은 차량 대수로도 수용할 수 있게 되었는지 판단할 수 있습니다.&lt;/p&gt;

&lt;p&gt;이제 실제 일별 차량 사용 비율 대비 가동률을 적용 전후로 확인해 보면 다음과 같습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/reservation-tetris/result-graph-2.png&quot; alt=&quot;img&quot; width=&quot;100%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;그래프에서 볼 수 있듯이 적용 후의 추세선이 전과 비교해 더 높은 것을 확인할 수 있습니다.&lt;/p&gt;

&lt;p&gt;이는 동일한 차량 사용 비율 관점에서 보면 같은 대수의 차량을 공급하여 더 많은 예약을 수용할 수 있다는 것을, 동일한 가동률 관점에서는 더 적은 비용으로 동일한 매출을 만들어낼 수 있음을 의미합니다.&lt;/p&gt;

&lt;p&gt;결론적으로 예약 테트리스 프로젝트를 통해서 &lt;strong&gt;평균적인 차량 사용 비율 대비 약 4%가량의 가동률 증분&lt;/strong&gt;을 만들어낼 수 있었습니다.&lt;/p&gt;

&lt;p&gt;또한 차량 사용 비율이 더 낮을수록 두 추세 선의 차이가 더 두드러지는 것을 볼 수 있는데 이는 최적화를 할 수 있는 여지와 관련이 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;최적화를 하기 위해서는 최적화를 할 수 있는 여지가 충분히 있어야 합니다. 이미 모든 차량에 예약이 빽빽하게 차있는 경우라면 최적화를 할 수 있는 여유가 부족해 예약 테트리스의 효과가 두드러지기 어렵습니다.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;하지만 &lt;strong&gt;반대로 예약이 많지 않은 경우라면 배정할 수 있는 차량의 경우의 수가 많은 만큼 최적화할 여유 공간이 남아있어 예약 테트리스를 적용했을 때 그 결과가 더 두드러지게 나타나게 됩니다.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/reservation-tetris/result-graph-explained.png&quot; alt=&quot;img&quot; width=&quot;100%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;예약 테트리스 프로젝트는 단순히 매출과 가동 관점에서만 성과가 있던 것은 아니었습니다.&lt;/p&gt;

&lt;p&gt;매일 직접 예약을 정리하던 업무가 모두 자동화되었기 때문에 각 지역사업팀에서는 업무시간을 훨씬 더 효율적으로 쓸 수 있게 되었습니다.&lt;/p&gt;

&lt;p&gt;특히 팬데믹 이후 여행 수요가 몰려 성수기 수준으로 예약이 밀려들어오는 상황인 제주사업팀에서 예약 테트리스가 큰 도움이 되고 있다는 소식을 들었을 때는 일을 하며 뿌듯함을 느꼈던 순간 중 하나입니다 :)&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/reservation-tetris/reaction.png&quot; alt=&quot;img&quot; width=&quot;100%&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;5-마무리-&quot;&gt;5. 마무리 &lt;a name=&quot;5-마무리&quot;&gt;&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;실시간으로 서비스에 적용되는 최적화 프로젝트는 실제 케이스가 많지 않아,  시행착오도 있었지만 함께 작업하며 서포트해 주신 많은 분들 덕분에 성공적으로 프로젝트를 마무리할 수 있었다고 생각합니다. 쏘카 예약 테트리스는 2020년에 완성한 프로젝트로 현재까지 이상 없이 동작하고 있습니다.&lt;/p&gt;

&lt;p&gt;예약 테트리스 프로젝트에서 서버 개발 쪽을 맡아주신 맷과 브루스, 프로젝트가 진행되는 동안 여러 부서를 오가며 디테일하게 챙겨주신 주디, 그리고 적극적으로 피드백 주신 제주사업팀과 기타 지역사업팀에게 감사드리고 싶습니다.&lt;/p&gt;</content><author><name>carrot, kyle</name></author><category term="data" /><category term="data" /><category term="optimization" /><summary type="html"></summary></entry><entry><title type="html">쏘카 PM의 차량 예약 퍼널 단계 개선기(feat. AB TEST)</title><link href="https://tech.socarcorp.kr/product/2022/06/02/reservation-funnel-improvement-with-abtest.html" rel="alternate" type="text/html" title="쏘카 PM의 차량 예약 퍼널 단계 개선기(feat. AB TEST)" /><published>2022-06-02T00:00:00+00:00</published><updated>2022-06-02T00:00:00+00:00</updated><id>https://tech.socarcorp.kr/product/2022/06/02/reservation-funnel-improvement-with-abtest</id><content type="html" xml:base="https://tech.socarcorp.kr/product/2022/06/02/reservation-funnel-improvement-with-abtest.html">&lt;p&gt;안녕하세요, 쏘카에서 PM(Product Manager)으로 일하는 루시아입니다. 이 글은 쏘카 PM이 쏘카에서 어떤 생각을 가지며 일하는지를 알 수 있는 내용을 담은 글입니다. 제품과 관련된 AB TEST 사례를 공유해 PM분들이 데이터 기반 사고 과정을 얻길 희망해 글을 작성했습니다.&lt;/p&gt;

&lt;p&gt;구체적으로 더 말씀드리면 쏘카 부름 서비스의 성장 방법을 찾기 위해 신규 부름 UX의 AB TEST를 진행했던 경험을 작성했습니다. 제가 PM으로서 사용자의 마음을 들여다보고, 문제를 해결 방법을 도출한 과정을 공유합니다.&lt;/p&gt;

&lt;p&gt;글의 목차는 다음과 같습니다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;#user-recognition&quot;&gt;우리 사용자들은 부름 서비스를 알고 있을까요?&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#user-recognition-enhancement&quot;&gt;부름을 어떻게 전달하면 사용자들이 알아볼까요?&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#brand-new-d2d&quot;&gt;부름을 새로운 모습으로 소개합니다.&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#wrap-up&quot;&gt;느낀 점&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;다음에 해당하신다면 글을 끝까지 읽어보시는 것을 추천드립니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;PM, PO가 일하는 방식이 궁금한 분&lt;/li&gt;
  &lt;li&gt;PM, PO가 문제를 어떻게 해결하는지 궁금하신 분&lt;/li&gt;
  &lt;li&gt;사용자의 생각을 통해 서비스 성장점을 찾는 방법을 고민 중인 분&lt;/li&gt;
  &lt;li&gt;기획자에서 더 나아가 제품의 성장 어젠다를 발굴하는 역할에 흥미가 있는 분&lt;/li&gt;
  &lt;li&gt;AB TEST를 사용해 제품을 개선한 AB TEST 예시가 궁금하신 분&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;쏘카 PM은 앱/웹/인터널 프로덕트 등 회사 내의 여러 제품을 관리하는 역할을 합니다. 저희들은 문제 분석과 어젠다 발굴의 주체일 때도, 제품 기획자일 때도 있습니다. 실제로 경험해 보면 굉장히 동적이고 다면적인 일입니다. 이전에 마리가 작성해 주신 글인 &lt;a href=&quot;https://tech.socarcorp.kr/product/2022/02/23/growing-up-together-with-the-pm-team.html&quot;&gt;쏘카 PM(Product Manager)은 어떻게 성장하나요?&lt;/a&gt;을 읽어보시면, 저희 그룹의 분위기를 더 느끼실 수 있습니다.&lt;/p&gt;

&lt;p&gt;저는 평소에 프로젝트 안에서 매우 다양한 문제와 만나고 있습니다. 그리고 문제의 원인을 찾기 위해 노력합니다. 물론, 문제의 원인을 파악하는 과정이 쉽지는 않습니다. 위로 보고 아래로 보고 다양한 관점을 토대로 파악하려고 합니다. 쏘카 PM들은 사업, 운영, 프로덕트의 동료들과 셜록 홈스 뺨치는 주도면밀한 관찰을 해야 합니다. 이렇게 머리를 쥐어짠 🤯 끝에는, 문제 해결 방법을 도출합니다. 즉 가설을 설정하게 됩니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/reservation-funnel-improvement-with-abtest/Frame_17.jpg&quot; alt=&quot;Frame 17&quot; /&gt;&lt;/p&gt;

&lt;p&gt;가설을 설정하는 과정에서 다음과 같은 고민을 할 수 있습니다&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;선택한 가설과 가설에 기반한 문제 해결 방법이 맞는지를 어떻게 사전에 판단할 수 있을까요?&lt;/li&gt;
  &lt;li&gt;새로운 기능(또는 새로운 UX)을 사용자들은 과연 좋아할까요?&lt;/li&gt;
  &lt;li&gt;새로운 기능을 배포한 후, 지표는 잘 나올까요?&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;가설을 도출한 후에는 그 가설이 올바른 문제 해결 방법인지 확신을 얻는 과정이 필요합니다. 이렇게 확신을 얻기 위해 쏘카 PM은 AB TEST를 사용합니다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;AB TEST란?&lt;/p&gt;

  &lt;p&gt;가설이 실제로 들어맞는지를 확인하기 위해 실험군/대조군(A, B 혹은 그 이상)으로 사용자 그룹을 구분해 서로 다른 버전의 기능이나 페이지를 사용자에게 보여주고, 결과를 평가하는 실험입니다. 새로운 기능에 대해 미리 성공 여부를 예측하기 어려운 경우, 사용자 전체에 배포하기 전에 적은 규모의 그룹에게서 미리 반응을 확인할 수 있습니다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;1--우리-사용자들은-부름-서비스를-알고-있을까요&quot;&gt;1.  우리 사용자들은 부름 서비스를 알고 있을까요?&lt;a name=&quot;user-recognition&quot;&gt;&lt;/a&gt;&lt;/h2&gt;

&lt;h3 id=&quot;11-큰-문제-이해하기&quot;&gt;1.1. 큰 문제 이해하기&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/img/reservation-funnel-improvement-with-abtest/Frame_12.jpg&quot; alt=&quot;Frame 12&quot; /&gt;&lt;em&gt;부름 서비스는 내가 지정한 위치로 차를 부르는 서비스입니다.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;먼저 쏘카의 부름 서비스란 내가 지정한 위치로 차를 “부르는” 서비스입니다. 사용자는 차를 대여할 위치와, 반납할 위치를 자유롭게 설정할 수 있습니다. (쏘카존에 직접 방문해서 차를 픽업하고 그 자리에 차를 반납하는 ‘쏘카 왕복’과 다릅니다)&lt;/p&gt;

&lt;p&gt;어느 날, 부름 서비스의 BO(Business Owner - 사업기획을 담당하는 분들) 분들이 미팅을 요청합니다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;“올해 부름은 예약량을 늘려야 해요. 지난 1년여간 예약량 지표가 정체되어 있었습니다. 전사적으로 볼 때 올해는 예약량 부스팅 반드시 필요하고요. 그나저나 부름 참 좋은데… 말로 표현을 못 하겠네…”&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;“예약량 지표 정체”라는 문제 상황은 명확합니다. 하지만 아직까지 사용자가 서비스를 잘 쓰지 않는 이유를 명확히 잡아내기 어려운 상태입니다. 문제를 조금 더 뾰족하게 만들어보기로 합니다. PM, BO가 머리를 맞대고 고민을 시작했습니다.&lt;/p&gt;

&lt;h3 id=&quot;12-현재-상황-파악하기&quot;&gt;1.2. 현재 상황 파악하기&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;사용자들은 우리 앱을 보며 어떤 생각을 하고 있을까요?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;과연 우리가 생각하는 것처럼 부름 서비스가 좋아서 고개를 끄덕여 주었을까요? 현재 사용자들이 보고 있는 우리는 어떤 모습일까요? 서비스 현황을 확인합니다. 먼저 왕복, 부름 서비스가 각각 무엇인지 확인해 봅니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/reservation-funnel-improvement-with-abtest/round_trip.png&quot; alt=&quot;왕복&quot; /&gt;&lt;em&gt;왕복 서비스&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;왕복 서비스&lt;/strong&gt;는 정해진 “쏘카존”에 차량들이 주차되어 있고, 사용자가 직접 &lt;strong&gt;쏘카존까지 이동하여&lt;/strong&gt; 예약한 차를 픽업합니다. 쏘카에서 제공 중인 가장 일반적인 차량 대여 서비스입니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/reservation-funnel-improvement-with-abtest/d2d.png&quot; alt=&quot;부름&quot; /&gt;&lt;em&gt;부름 서비스&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;부름&lt;/strong&gt; 서비스는 반대로 사용자가 집 앞으로 차를 부르고, 차량이 지정한 &lt;strong&gt;장소로 호출됩니다.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;앱의 UX&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;그런데 현재 부름은 왕복과 Flow, UX를 거의 똑같이 공유하고 있습니다.&lt;/strong&gt; 왕복이 아닌 부름 상품을 원하는 사용자에게 이것이 최고의 경험일까요? 여기서부터 뒤집어서 생각해 보기로 했습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/reservation-funnel-improvement-with-abtest/Frame_11.jpg&quot; alt=&quot;Frame 11&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;13-해결할-문제-뾰족하게-짚기&quot;&gt;1.3. 해결할 문제 뾰족하게 짚기&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;PM : ”이 문제를 해결하는 우리들은, 쏘카 전체가 아닌, 1인칭 부름 사용자 중심으로 생각하도록 시선을 바꾸어야 해요! 부름 사용자들이 특히 어려워하는 것을 찾아 해결해 주어야 해요.”&lt;/li&gt;
  &lt;li&gt;BO : ”왜요? 무슨 차이가 있어서요?”&lt;/li&gt;
  &lt;li&gt;PM : 현재 “여기로 쏘카 부르기”라고 적힌 &lt;code class=&quot;highlighter-rouge&quot;&gt;부름 PIN&lt;/code&gt; 을 통해서 뿐 아니라, &lt;code class=&quot;highlighter-rouge&quot;&gt;쏘카존&lt;/code&gt; 버튼을 통해서도 동일한 ‘부름’ 차량을 예약할 수 있는데요, 결제 CTA 버튼이 있는 ‘결제정보 확인’ 페이지까지의 도달 전환율이 다음과 같이 차이를 보였습니다. (비율로 표현하면 쏘카존 20% : 부름 PIN 70% 입니다)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/img/reservation-funnel-improvement-with-abtest/Frame_13.jpg&quot; alt=&quot;Frame 13&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;BO : 똑같은 상품을 팔고 있는데도, 출발점에 따라서 결과가 다르다고요?&lt;/li&gt;
  &lt;li&gt;PM : 네. 출발점이 부름 PIN인 경우, “여기로 쏘카 부르기”라고 말해주었기 때문에 사용자도 &lt;strong&gt;[부름 차량을 빌려야지]라고 명확히 결심한 상황&lt;/strong&gt;이라고 생각할 수 있을 것 같아요. 부름에 대한 이해, 결제 결심이 반영된 것 아닐까요?&lt;/li&gt;
  &lt;li&gt;BO : 흥미롭네요. 그러면 부름 사용자만의 특징을 같이 좀 더 살펴봐요.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;14-파고들기&quot;&gt;1.4. 파고들기&lt;/h3&gt;

&lt;h4 id=&quot;141-사용자-segment-확인&quot;&gt;1.4.1. 사용자 Segment 확인&lt;/h4&gt;

&lt;p&gt;차량 예약 데이터를 확인했을 때, 부름 사용자는 왕복과 &lt;strong&gt;나이, 대여 시간에 차이&lt;/strong&gt;를 보인다는 점을 발견했습니다. (아래 데이터는 일정 기간 동안의 평균치입니다.)&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/reservation-funnel-improvement-with-abtest/segments.jpg&quot; alt=&quot;segments&quot; /&gt;
그리고 실제 부름을 애용하는 사용자들에게 전화 인터뷰(In-depth interview)를 진행했습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;차에 실어야 할 짐이 있거나, 승차할 동행이 많은 경우, 야간에 대여를 시작하는 경우 등 특정한 TPO에 차를 부름으로 불러서 이용한다&lt;/strong&gt;는 패턴이 있었습니다.&lt;/li&gt;
  &lt;li&gt;사용자들은 위의 상황에서는 &lt;strong&gt;명확하게 부름을 쓰러 앱에 들어오며, 쏘카존까지 걸어가지 않아도 되는 부름 서비스의 장점을 느꼈다&lt;/strong&gt;는 이야기를 자세히 들을 수 있었습니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;역시 부름은 ‘사용자’가 달랐다는 점을 확인했습니다.&lt;/strong&gt; 사용자의 목소리를 들어본 뒤, 타깃에 맞춘 제품이 필요하다는 생각을 굳히게 됩니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/reservation-funnel-improvement-with-abtest/user-stock.png&quot; alt=&quot;user&quot; /&gt;&lt;em&gt;차에 살어야 할 짐이 많은 경우 등 특정 TPO에 부름 서비스를 이용했습니다. by &lt;a href=&quot;https://unsplash.com/@rocinante_11&quot;&gt;Mick Haupt&lt;/a&gt; on Unsplash&lt;/em&gt;&lt;/p&gt;

&lt;h4 id=&quot;142-사용성-테스트&quot;&gt;1.4.2. 사용성 테스트&lt;/h4&gt;

&lt;p&gt;사용자들이 보여주고 있던 예약 데이터의 결과와 더불어 제품에서도 사용자들이 허들로 느끼고 있는 명확한 UX를 짚어내기 위해,  &lt;strong&gt;앱 사용성 테스트를 진행&lt;/strong&gt;했습니다. 디자이너, PM, BO 모두 뛰어들어, 사용자들이 어떻게 기존 앱을 사용하는지, 무슨 생각을 하는지 꼼꼼히 수집했습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/reservation-funnel-improvement-with-abtest/Frame_15.jpg&quot; alt=&quot;Frame 15&quot; /&gt;&lt;em&gt;앱 사용성 테스트 과정&lt;/em&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;부름 서비스를 한 번도 안 써본 사람들과 어느 정도 익숙한 사람들로 &lt;strong&gt;그룹을 분리해 진행&lt;/strong&gt;했습니다.&lt;/li&gt;
  &lt;li&gt;부름을 한 번도 이용해 보지 않은 사용자들에게서는 &lt;strong&gt;처음에 둘러보기는 했으나 이해하기 어려워 사용하지 않았다&lt;/strong&gt;는 피드백을 다수 들었습니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;더욱이 사용자들이 제품 기획 의도와 다르게 받아들이고 있는 UI 화면들을 발견했습니다&lt;/strong&gt;.  그동안 부름을 써보지 않은 사용자들이 무엇을 불안해하고 있었는지 구체적으로 근거를 찾아낼 수 있었습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/reservation-funnel-improvement-with-abtest/Frame_14.jpg&quot; alt=&quot;Frame 14&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;사용자의 목소리는 생각의 전환점이었습니다.&lt;/strong&gt; 이제 팀원들은 부름 사용자들은 왕복과는 다른 니즈가 있다는 점에 동의했습니다. 그리고 부름 사용자들만이 느꼈던 아쉬운 점, 불편했던 경험을 귀로 생생하게 들으며 깜짝 놀랐습니다. 사용자의 시각은 예상과 다르며, 책상 앞에 가만히 앉아서는 느낄 수 없다는 것을 새삼 깨달을 수 있었습니다.&lt;/p&gt;

&lt;p&gt;이런 불편에 공감하고 해결해야, 사용자들이 쏘카 서비스에 매력을 느끼고 계속 이용하게 될 것입니다. 후행적인 사업 지표에 골몰하는 것이 아닌,  먼저 사용자들의 생각 속에 깊이 빠져들어 본다면, &lt;strong&gt;자연스럽게 예약량은 늘어나게 될 거라 기대합니다.&lt;/strong&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;2-부름을-어떻게-전달하면-사용자들이-알아볼까요&quot;&gt;2. 부름을 어떻게 전달하면 사용자들이 알아볼까요?&lt;a name=&quot;user-recognition-enhancement&quot;&gt;&lt;/a&gt;&lt;/h2&gt;

&lt;h3 id=&quot;21-가설-도출하기&quot;&gt;2.1. 가설 도출하기&lt;/h3&gt;

&lt;h4 id=&quot;211-문제-정리&quot;&gt;2.1.1. 문제 정리&lt;/h4&gt;

&lt;p&gt;수집한 정보를 바탕으로 팀원들은 문제와 해결 방법을 다음과 같이 정리했습니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;문제&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;사용자는 앱에서 부름이 정확히 무슨 서비스이고, 무슨 장점이 있어서 예약해야 하는지 알기 힘들다.&lt;/li&gt;
  &lt;li&gt;부름을 한 번도 써보지 않은 상태에서는 차를 내가 지정한 장소로 부를 때 드는 걱정들이 어떻게 해결되는지, 쏘카가 어떤 방지책을 제공하는지 알기 힘들다.&lt;/li&gt;
  &lt;li&gt;한 번도 부름을 써보지 않은 사용자의 고통이 부름 이용 경험자 보다 크게 나타난다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;해결 방법&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;예약량 확대를 위해서는 사용자에게 부름만의 매력을 직관적으로 전달하면서(=PMF 찾기)&lt;/li&gt;
  &lt;li&gt;불안감을 낮출 수 있는 예약 경험을 주어야 한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;PMF(Product/Market Fit)이란, 타깃을 만족시키는 제품을 가능성 있는 시장에 제공하는 상태입니다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&quot;212-가설-설정&quot;&gt;2.1.2. 가설 설정&lt;/h4&gt;

&lt;p&gt;다음과 같은 &lt;strong&gt;가설을 설정했습니다.&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;가설 : 지금처럼 왕복과 똑같은 Flow가 아닌 &lt;strong&gt;[부름 사용자] 관점에서 설계한 부름 전용 예약 Flow를 제공한다면,&lt;/strong&gt; 결제 전환율의 차이와 기분 좋은 예약 경험 두 가지를 확인할 수 있을 것이다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;차량을 예약할 때 내 바로 앞으로 차를 부르고 싶은 사용자 마음의 흐름에 맞추어 독립적인 부름 서비스 전용 &lt;strong&gt;‘신규 예약 페이지’를 새로 구현&lt;/strong&gt;해보자는 아이디어입니다.&lt;/p&gt;

&lt;h3 id=&quot;22-프로덕트-제작-실험-출시하기&quot;&gt;2.2. 프로덕트 제작, 실험 출시하기&lt;/h3&gt;

&lt;h4 id=&quot;221-부름-신규-예약-페이지-프로토타입-제작&quot;&gt;2.2.1. 부름 ‘신규 예약 페이지’ 프로토타입 제작&lt;/h4&gt;

&lt;p&gt;가설에서 제안한 &lt;strong&gt;[부름 사용자] 관점에서 설계한 부름 전용 ‘신규 예약 페이지’&lt;/strong&gt;를 고민하기 시작합니다. 디자이너와 PM이 사용성 테스트에서 수집한 인사이트들을 바탕으로  와이어 프레임을 새롭게 스케치했습니다. 그리고 가벼운 프로토타입으로 만들어 주변 동료들에게 직접 써보게 하고, 이를 통해 우리가 생각한 UX가 기존 사용자의 문제를 해결하는지 확인하며 스케치를 진행했습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/reservation-funnel-improvement-with-abtest/prototype-1.png&quot; alt=&quot;prototype-1&quot; /&gt;&lt;em&gt;와이어프레임 스케치&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/reservation-funnel-improvement-with-abtest/prototype-before.jpg&quot; alt=&quot;prototype-before&quot; /&gt; &lt;em&gt;UX 변경 전, 기존 사용자 관점의 문제&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/reservation-funnel-improvement-with-abtest/prototype-after.jpg&quot; alt=&quot;prototype-after&quot; /&gt;&lt;em&gt;프로토타입 구상&lt;/em&gt;&lt;/p&gt;

&lt;h4 id=&quot;222-실행-방법-고르기&quot;&gt;2.2.2. 실행 방법 고르기&lt;/h4&gt;

&lt;p&gt;그런데 여기에서 위 도입부에 이야기했던 &lt;strong&gt;[올바른 문제해결 방법인지 확신이 필요한]&lt;/strong&gt; 문제가 대두됩니다. 새로운 예약 Flow를 적용해 보려는 생각을 부름의 사업, 운영팀에 공유했을 때 이런 우려점이 있었습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;갑자기 예약 과정을 다 바꿔버려도 될까요?&lt;/li&gt;
  &lt;li&gt;기존 사용자들이 적응을 못하고 이탈하면 어떡하죠? 이 UX를 사용자들이 좋아할 거라 어떻게 확신할 수 있어요?&lt;/li&gt;
  &lt;li&gt;사용자 테스트를 대규모로 하면 시간이 너무 많이 들지 않을까요?&lt;/li&gt;
  &lt;li&gt;혹시나 잘못되면 원래 유지되던 예약률은 방어할 수 있을까요?&lt;/li&gt;
  &lt;li&gt;배포했다가 지표가 잘못되면 롤백 할 수 있을까요?&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;223-ab-test-적용&quot;&gt;2.2.3. AB TEST 적용&lt;/h4&gt;

&lt;p&gt;위와 같은 우려를 보완하기 위해, &lt;strong&gt;AB TEST&lt;/strong&gt;를 통해 제품 및 사업 지표가 달성되는지를 확인한 뒤, 전체 배포 여부를 결정하기로 합니다.
PM과 데이터 사이언스팀은 아래와 같이 AB TEST 실험을 설정하고, 사업 팀과 목표 및 관찰 지표를 정했습니다.&lt;/p&gt;

&lt;p&gt;쏘카에는 데이터 기반으로 실험하기 위한 인프라가 마련되어 있어서 수월하게 실험 계획을 짤 수 있었습니다. 데이터 분석 직군이 아니더라도, PM들이 AB TEST 실험을 프로젝트에 사용할 수 있도록 여러 교육과 가이드가 준비돼 있습니다. ❤️&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;실험 기간&lt;/th&gt;
      &lt;th&gt;2022년 1월 24일 ~ 2월 4일 (11일간)&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;실험군 정의&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;- 지도에 들어온 뒤, 부름 PIN을 클릭 시, 신규 부름 예약 페이지를 보여준다. &lt;br /&gt;- &lt;strong&gt;즉, 부름용 ‘신규 예약 페이지’를 통해 예약하는 그룹&lt;/strong&gt; &lt;br /&gt;- 전체 앱 접속자의 5%&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;대조군 정의&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;- 지도에 들어온 뒤, 부름 PIN을 클릭 시, 기존 차량 리스트를 보여준다.&lt;br /&gt;- &lt;strong&gt;즉, 기존과 동일한 화면 통해 예약하는 그룹&lt;/strong&gt; &lt;br /&gt;- 전체 앱 접속자의 5%&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;목표 설정&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;- 부름용 ‘신규 예약 페이지’를 통해 예약하는 그룹은 전환율이 더 높을 것이다. &lt;br /&gt;- 실험군은 대조군 대비 22% 이상을 목표로 한다. (통계적 유의미성을 띄는 규모 + BO의 매출 기대치 반영)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;관찰 지표 설정&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;- 예약 페이지 입장 후, [결제 확인] 페이지에 도달한 방문 전환율 &lt;br /&gt;- [결제 확인] 페이지에서 [차량 예약]한 예약 전환율 &lt;br /&gt;- 예약 페이지 입장 후, [차량 예약]한 예약 전환율&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;strong&gt;배포 비율&lt;/strong&gt;은 먼저 1월 24일 전체 사용자의 5%로 시작한 뒤 2월 4일 실험 결과를 통해 1차 결론을 냅니다.&lt;br /&gt;더 많은 모수에서 같은 결과가 나오는지 확신을 갖기 위해 4월 24일까지 10%, 50%로 단계별로 늘려가며 사업지표와 CS 센터에 악영향이 없는지를 모니터링했습니다.&lt;br /&gt;전체 예약 과정을 바꾸었기 때문에 단편적인 UI 성과 측정만이 목표는 아니었고, 사업과 운영에도 영향이 없는지도 중요한 품질 판단 요소였습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/reservation-funnel-improvement-with-abtest/Frame_21.jpg&quot; alt=&quot;Frame 21&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;224-개발-착수하기&quot;&gt;2.2.4. 개발 착수하기&lt;/h4&gt;

&lt;p&gt;💡 BO가 고민하던 아젠다인 &lt;code class=&quot;highlighter-rouge&quot;&gt;부름의 예약 성장시킬 아이디어 찾기&lt;/code&gt;부터, 드디어 &lt;strong&gt;“부름 전용 신규 예약 페이지를 개발하고, AB TEST로 출시하여 실험군과 대조군 차이 발견하기”&lt;/strong&gt; 라는 &lt;code class=&quot;highlighter-rouge&quot;&gt;프로덕트 제작 목표&lt;/code&gt;까지 도착했습니다. 이에 맞추어 다음 과정이 진행됩니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;디자이너와 UX Writer의 아이디어가 UX 설계에 뿜어져 나옵니다. 🔥&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;특히 사용자들이 부름에 대해서 이해가 되지 않았던 부분을 해결하기 위해서, 문장 하나하나에 특히 신경을 많이 써주셨어요.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;iOS, Android, Server 팀, QA 팀은 새로운 프로덕트를 설계하고 개발합니다. 🔥&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;부름 예약만을 위한 독립 페이지를 만드는 만큼, 기존 예약 페이지를 활용하면서도 새로운 플로우를 많이 설계해야 해서 꼼꼼하게 봐야 하는 작업이었어요.&lt;/p&gt;

&lt;h3 id=&quot;23-결과를-확인하자&quot;&gt;2.3. 결과를 확인하자&lt;/h3&gt;

&lt;p&gt;치열했던 개발 기간이 흐르고..  드디어 실험이 담긴 버전을 출시!!! 🚀🚀🚀 몇 주간 두근두근 하며 사용자들의 반응을 모니터링 했습니다.&lt;/p&gt;

&lt;h4 id=&quot;231-실험-결과&quot;&gt;2.3.1. 실험 결과&lt;/h4&gt;

&lt;p&gt;(총 기간 : 2022-01-24~ 2022-04-24)&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;지표&lt;/td&gt;
      &lt;td&gt;기존 그룹과 신규 그룹의 차이&lt;/td&gt;
      &lt;td&gt;설명&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;예약 페이지 입장 후,&lt;strong&gt;[결제 확인] 페이지에 도달한 방문 전환율&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;-6% p&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;- 기존과는 달리 첫 페이지에서 부름에 서비스에 대해서 명확하게 설명했기 때문 &lt;br /&gt; - 결제 직전 페이지에는 결국, 진짜 부름에 관심 있는 사용자만 남음.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;[결제 확인] 페이지에서 &lt;strong&gt;[차량 예약]한 예약 전환율&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;+21.8% p&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;- 앞에서와 같이, &lt;strong&gt;부름에 대해서 관심 있는 사용자만 남아 결제 가능성은 높아짐&lt;/strong&gt; &lt;br /&gt;- 부름을 원하는 사용자에게 지금보다 더 많이 노출된다면 예약량은 많아질 수 있음&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;예약 페이지 입장 후, &lt;strong&gt;[차량 예약]한 예약 전환율&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;없음&lt;/td&gt;
      &lt;td&gt;- 싱품이나 가격 조건이 똑같을 때 둘 사이에 큰 차이는 발견하지 못함 &lt;br /&gt;- 다만 신규 UX를 전체 배포했을 때 사업지표에 리스크는 없다고 판단&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h4 id=&quot;232-후속-사용성-테스트-결과&quot;&gt;2.3.2. 후속 사용성 테스트 결과&lt;/h4&gt;

&lt;p&gt;더불어, 처음에 문제 확인을 위해 진행했던 기존 UX에 대한 사용성 테스트를 새로운 UX를 가지고 다시 진행해 보았습니다. 새로 개발한 &lt;code class=&quot;highlighter-rouge&quot;&gt;부름홈&lt;/code&gt;을 보여주면서, 기존과 동일한 질문을, 새로운 사람들에게 던져보았습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/reservation-funnel-improvement-with-abtest/Frame_18.jpg&quot; alt=&quot;Frame 18&quot; /&gt;&lt;/p&gt;

&lt;p&gt;부름 사용자의 가장 큰 페인 포인트였던 “서비스를 이해하기 어렵다”라는 문제가 크게 해결되었다는 걸 확인할 수 있었습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/reservation-funnel-improvement-with-abtest/Frame_23.jpg&quot; alt=&quot;Frame 23&quot; /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;3-부름을-새로운-모습으로-소개합니다&quot;&gt;3. 부름을 새로운 모습으로 소개합니다.&lt;a name=&quot;brand-new-d2d&quot;&gt;&lt;/a&gt;&lt;/h2&gt;

&lt;h3 id=&quot;31-액션-플랜-실행하기&quot;&gt;3.1. 액션 플랜 실행하기&lt;/h3&gt;

&lt;h4 id=&quot;311-배포&quot;&gt;3.1.1. 배포&lt;/h4&gt;

&lt;p&gt;결제 가능성과 UX 이해도를 높인 파워풀한 새로운 [부름 홈]은 더 많은 사용자에게 배포해도 되는 제품으로 결론을 내렸습니다. 50% 배포 후 사업지표 및 CS 지표에 이슈 없는걸 확인한 뒤 4월 25일을 기준으로 100% 사용자에게 모두 배포할 수 있었습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/reservation-funnel-improvement-with-abtest/Frame_16.jpg&quot; alt=&quot;Frame 16&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;312-tpo-재정의&quot;&gt;3.1.2. TPO 재정의&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;/img/reservation-funnel-improvement-with-abtest/tpo.png&quot; alt=&quot;tpo.png&quot; /&gt;&lt;em&gt;부름의 TPO를 반영하는 새로운 메인화면&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;부름 서비스는 사용자들에게 &lt;code class=&quot;highlighter-rouge&quot;&gt;왕복과 다른 TPO로 설명될 수 있다&lt;/code&gt;는 것을 확인한 프로젝트인 만큼 새로 출시될 메인화면에서 “여기로 부르기”라는 버튼으로 부름을 나타내는 입구를 신설하기로 했습니다. 이제 사용자들이 기존 왕복 예약과 부름 서비스를 분리해서 이해할 수 있게 되었습니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;2022년 5월 업데이트 한 새로운 쏘카 앱 메인 페이지에서, 
새로운 부름 서비스를 더 편리하게 이용해 주세요!&lt;/strong&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;4-느낀-점&quot;&gt;4. 느낀 점&lt;a name=&quot;wrap-up&quot;&gt;&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;맨 처음 ‘부름 서비스를 성장시키자’는 목표를 들었을 때 들었던 일차원적인 생각은, 여기서 더 어떻게?였습니다. 😂&lt;/p&gt;

&lt;p&gt;약 3년 전 쏘카의 신규 사업에 대한 치열한 고민을 통해 탄생했던 부름 서비스는 론칭 후 운영되며 나름대로 좋은 성적을 유지하고 있었습니다.&lt;/p&gt;

&lt;p&gt;PM으로서 저 자신이 어떤 태도로 임해야 하는지 고민이 됐습니다. 그리고 생각의 함정에 빠질 뻔한 순간도 있었습니다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;“부름처럼 큰 서비스를? 그동안 담당자도 아니었던 내가 어떤 시사점을 더할 수 있을까? 부름의 A to Z를 다 파악하고 나서야 개선점이 눈에 보인다면 공부하는 데 한참 걸릴 텐데.”&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;만약 제가 주어진 목표를 쉽게 해결하는 방법에 집중했다면, 단순히 ‘안 보이던 안내 문구를 더 잘 보이게’라던가, ‘상품 가격을 내려볼까’ 같은 무책임하고 지속 불가능한 안을 선택했을 것 같습니다. 하지만 이번 프로젝트에서는 &lt;strong&gt;“무엇을 해결할 것인가”&lt;/strong&gt;를 찾는 부분에서 사용자의 도움을 많이 받았습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;사용자는 무엇이 마음에 안 들어서 부름을 쓰러 들어왔다가 이탈할까?&lt;/li&gt;
  &lt;li&gt;반면 부름을 계속 써오던 사용자들은, 추가 비용을 지불하며 부름을 왜 쓸까?&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;두 가지 질문에 대해 &lt;strong&gt;사용자들의 입에서 직접 대답을 들었고&lt;/strong&gt; 또한 사용자의 모습을 관찰하는 과정에서 &lt;strong&gt;뜻밖의 단서&lt;/strong&gt;들을 찾을 수 있었습니다. 운영자 관점에서 단순히 예약이 더 많이 들어왔으면 좋겠다는 생각에 집중했다면 사용자가 무슨 생각을 하는지 파헤쳐 보자는 선택을 하지 않았을 것 같습니다.&lt;/p&gt;

&lt;p&gt;저도 프로젝트의 처음부터 끝까지 ‘사용자’를 중심에 놓고 온전히 집중해 본 경험은 흔치 않았습니다. 돌이켜보니 정말 배운 게 많은, 잘 한 선택이었다 생각합니다. 문제는 현재 진행형으로 해결하고 있지만 성장점을 찾아야 하는 PM에게는 이 방향성을 알게 된 것만으로도 큰 수확이었습니다.&lt;/p&gt;

&lt;p&gt;더욱이 프로덕트 Funnel 데이터 집계 결과와 AB TEST를 통해 얻은 비교 근거들을 가설 검증 과정에서 사용했던 부분 또한 큰 도움이 되었습니다. 저는 데이터 분석 전문가나 지표를 바탕으로 사업전략을 짜는 직무는 아닙니다.  그러나 쏘카에서 그런 데이터에 접근할 수 있고, 쿼리 하여 읽을 수 있고, 관찰한 바를 토대로 문제를 추정할 수 있게 열린 환경이었기에 가능했습니다. (결론적으로 저는 쏘카라는 회사를 좀 더 좋아하게 됐어요. ㅎㅎ)&lt;/p&gt;

&lt;p&gt;제가 준비한 글은 여기까지입니다. 긴 글 읽어주셔서 감사합니다.&lt;/p&gt;</content><author><name>루시아</name></author><category term="product" /><category term="product" /><category term="pm" /><category term="data" /><summary type="html">안녕하세요, 쏘카에서 PM(Product Manager)으로 일하는 루시아입니다. 이 글은 쏘카 PM이 쏘카에서 어떤 생각을 가지며 일하는지를 알 수 있는 내용을 담은 글입니다. 제품과 관련된 AB TEST 사례를 공유해 PM분들이 데이터 기반 사고 과정을 얻길 희망해 글을 작성했습니다.</summary></entry></feed>